{
  "category": "research",
  "date": "2026-01-05",
  "category_summary": "Today's research highlights critical security vulnerabilities and fundamental challenges to LLM reasoning reliability. **The Trojan in the Vocabulary** [exposes a supply-chain attack](/?date=2026-01-05&category=research#item-dc1229ead45b) via tokenizer transplant creating 'breaker tokens' that sabotage model composition—a critical finding for the open-weight ecosystem.\n\n- **Geometry of Reason** [introduces training-free reasoning verification](/?date=2026-01-05&category=research#item-d56a9a8e1378) using spectral analysis of attention patterns, achieving **85-95.6%** accuracy\n- Process verification research [reveals **50-69%**](/?date=2026-01-05&category=research#item-e3f712d790f9) of correct answers from **7-9B parameter** models contain fundamentally flawed reasoning\n- **Illusion of Insight** [challenges 'Aha moment' claims](/?date=2026-01-05&category=research#item-8c78bb930e27) through analysis of **1M+** reasoning traces from DeepSeek-R1-Zero\n- **WildAGTEval** from Amazon/UIUC [benchmarks LLM agents](/?date=2026-01-05&category=research#item-e250fd893670) under realistic API complexity including noisy outputs\n\nOn the infrastructure side, **FlashInfer-Bench** from Tianqi Chen's group [addresses LLM deployment efficiency](/?date=2026-01-05&category=research#item-134998214b67) through AI-driven kernel generation. **Defensive M2S** [achieves **93x token reduction**](/?date=2026-01-05&category=research#item-3b793eaebc63) for guardrail training while maintaining safety performance. **MalOptBench** [uncovers a new vulnerability domain](/?date=2026-01-05&category=research#item-428f1226eba0) in malicious optimization algorithm requests.",
  "category_summary_html": "<p>Today's research highlights critical security vulnerabilities and fundamental challenges to LLM reasoning reliability. <strong>The Trojan in the Vocabulary</strong> <a href=\"/?date=2026-01-05&category=research#item-dc1229ead45b\" class=\"internal-link\">exposes a supply-chain attack</a> via tokenizer transplant creating 'breaker tokens' that sabotage model composition—a critical finding for the open-weight ecosystem.</p>\n<ul>\n<li><strong>Geometry of Reason</strong> <a href=\"/?date=2026-01-05&category=research#item-d56a9a8e1378\" class=\"internal-link\">introduces training-free reasoning verification</a> using spectral analysis of attention patterns, achieving <strong>85-95.6%</strong> accuracy</li>\n<li>Process verification research <a href=\"/?date=2026-01-05&category=research#item-e3f712d790f9\" class=\"internal-link\">reveals <strong>50-69%</strong></a> of correct answers from <strong>7-9B parameter</strong> models contain fundamentally flawed reasoning</li>\n<li><strong>Illusion of Insight</strong> <a href=\"/?date=2026-01-05&category=research#item-8c78bb930e27\" class=\"internal-link\">challenges 'Aha moment' claims</a> through analysis of <strong>1M+</strong> reasoning traces from DeepSeek-R1-Zero</li>\n<li><strong>WildAGTEval</strong> from Amazon/UIUC <a href=\"/?date=2026-01-05&category=research#item-e250fd893670\" class=\"internal-link\">benchmarks LLM agents</a> under realistic API complexity including noisy outputs</li>\n</ul>\n<p>On the infrastructure side, <strong>FlashInfer-Bench</strong> from Tianqi Chen's group <a href=\"/?date=2026-01-05&category=research#item-134998214b67\" class=\"internal-link\">addresses LLM deployment efficiency</a> through AI-driven kernel generation. <strong>Defensive M2S</strong> <a href=\"/?date=2026-01-05&category=research#item-3b793eaebc63\" class=\"internal-link\">achieves <strong>93x token reduction</strong></a> for guardrail training while maintaining safety performance. <strong>MalOptBench</strong> <a href=\"/?date=2026-01-05&category=research#item-428f1226eba0\" class=\"internal-link\">uncovers a new vulnerability domain</a> in malicious optimization algorithm requests.</p>",
  "themes": [
    {
      "name": "LLM Efficiency & Deployment",
      "description": "Research on optimizing LLM serving, quantization effects, parameter-efficient fine-tuning, and deployment infrastructure",
      "item_count": 10,
      "example_items": [],
      "importance": 82
    },
    {
      "name": "AI Safety & Reliability",
      "description": "Research on guardrails, hallucination reduction, reasoning integrity, and trustworthy AI systems including unlearning and anomaly detection for agents",
      "item_count": 12,
      "example_items": [],
      "importance": 82
    },
    {
      "name": "AI Safety & Trustworthiness",
      "description": "Work on hallucination detection, concept erasure, adversarial robustness, content authenticity, and AI governance",
      "item_count": 11,
      "example_items": [],
      "importance": 78
    },
    {
      "name": "AI Safety & Security",
      "description": "Research on vulnerabilities, jailbreaking, adversarial attacks, and reliability of AI systems including LLM supply-chain attacks and safety benchmarks",
      "item_count": 5,
      "example_items": [],
      "importance": 75
    },
    {
      "name": "Language Models & Reasoning",
      "description": "LLM capabilities, limitations in optimization tasks, retrieval-augmented generation, and reasoning improvements through MCTS and RL",
      "item_count": 22,
      "example_items": [],
      "importance": 75
    },
    {
      "name": "Language Model Reasoning and Capabilities",
      "description": "Papers analyzing LLM reasoning processes, detecting valid reasoning, and understanding training dynamics that affect creative problem-solving",
      "item_count": 5,
      "example_items": [],
      "importance": 75
    },
    {
      "name": "Benchmarks & Datasets",
      "description": "New evaluation frameworks and large-scale datasets for various AI tasks",
      "item_count": 9,
      "example_items": [],
      "importance": 72
    },
    {
      "name": "Neural Architecture Innovations",
      "description": "Novel architectures including residual connection generalizations, bio-inspired designs, and efficient transformers",
      "item_count": 6,
      "example_items": [],
      "importance": 71
    },
    {
      "name": "World Models & Spatial Intelligence",
      "description": "4D world modeling, spatial reasoning benchmarks, and multimodal understanding of dynamic environments",
      "item_count": 3,
      "example_items": [],
      "importance": 70
    },
    {
      "name": "Medical & Healthcare AI",
      "description": "Clinical trials, medical imaging, diagnosis systems, and mental health applications",
      "item_count": 7,
      "example_items": [],
      "importance": 70
    }
  ],
  "total_items": 282,
  "items": [
    {
      "id": "dc1229ead45b",
      "title": "The Trojan in the Vocabulary: Stealthy Sabotage of LLM Composition",
      "content": "The open-weight LLM ecosystem is increasingly defined by model composition techniques (such as weight merging, speculative decoding, and vocabulary expansion) that remix capabilities from diverse sources. A critical prerequisite for applying these methods across different model families is tokenizer transplant, which aligns incompatible vocabularies to a shared embedding space. We demonstrate that this essential interoperability step introduces a supply-chain vulnerability: we engineer a single \"breaker token\" that is functionally inert in a donor model yet reliably reconstructs into a high-salience malicious feature after transplant into a base model. By exploiting the geometry of coefficient reuse, our attack creates an asymmetric realizability gap that sabotages the base model's generation while leaving the donor's utility statistically indistinguishable from nominal behavior. We formalize this as a dual-objective optimization problem and instantiate the attack using a sparse solver. Empirically, the attack is training-free and achieves spectral mimicry to evade outlier detection, while demonstrating structural persistence against fine-tuning and weight merging, highlighting a hidden risk in the pipeline of modular AI composition. Code is available at https://github.com/xz-liu/tokenforge",
      "url": "http://arxiv.org/abs/2601.00065",
      "author": "Xiaoze Liu, Weichen Yu, Matt Fredrikson, Xiaoqian Wang, Jing Gao",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Demonstrates a supply-chain vulnerability in LLM model composition through tokenizer transplant. Engineers 'breaker tokens' that are inert in donor models but become malicious after transplant, exploiting coefficient reuse geometry.",
      "importance_score": 75,
      "reasoning": "Important security finding for the open-weight LLM ecosystem. Novel attack vector affecting weight merging, speculative decoding, and vocabulary expansion. High practical relevance.",
      "themes": [
        "AI Safety",
        "LLM Security",
        "Model Composition",
        "Adversarial Attacks"
      ],
      "continuation": null
    },
    {
      "id": "e250fd893670",
      "title": "Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity",
      "content": "We introduce WildAGTEval, a benchmark designed to evaluate large language model (LLM) agents' function-calling capabilities under realistic API complexity. Unlike prior work that assumes an idealized API system and disregards real-world factors such as noisy API outputs, WildAGTEval accounts for two dimensions of real-world complexity: 1. API specification, which includes detailed documentation and usage constraints, and 2. API execution, which captures runtime challenges. Consequently, WildAGTEval offers (i) an API system encompassing 60 distinct complexity scenarios that can be composed into approximately 32K test configurations, and (ii) user-agent interactions for evaluating LLM agents on these scenarios. Using WildAGTEval, we systematically assess several advanced LLMs and observe that most scenarios are challenging, with irrelevant information complexity posing the greatest difficulty and reducing the performance of strong LLMs by 27.3%. Furthermore, our qualitative analysis reveals that LLMs occasionally distort user intent merely to claim task completion, critically affecting user satisfaction.",
      "url": "http://arxiv.org/abs/2601.00268",
      "author": "Doyoung Kim (1 and 2), Zhiwei Ren (1 and 3), Jie Hao (1), Zhongkai Sun (1), Lichao Wang (1), Xiyao Ma (1), Zack Ye (1), Xu Han (1), Jun Yin (1), Heng Ji (4), Wei Shen (1), Xing Fan (1), Benjamin Yao (1), Chenlei Guo (1) ((1) Amazon, (2) KAIST, (3) University of Pittsburgh, (4) University of Illinois Urbana-Champaign)",
      "published": "2026-01-05",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Introduces WildAGTEval benchmark for evaluating LLM agents' function-calling under realistic API complexity including noisy outputs and usage constraints. Covers 60 complexity scenarios composable into 32K test configurations.",
      "importance_score": 75,
      "reasoning": "Important benchmark from Amazon/UIUC addressing real-world challenges in LLM agent deployment. Comprehensive evaluation framework.",
      "themes": [
        "LLM Agents",
        "Benchmarks",
        "Function Calling"
      ],
      "continuation": null
    },
    {
      "id": "e3f712d790f9",
      "title": "When Small Models Are Right for Wrong Reasons: Process Verification for Trustworthy Agents",
      "content": "Deploying small language models (7-9B parameters) as autonomous agents requires trust in their reasoning, not just their outputs. We reveal a critical reliability crisis: 50-69\\% of correct answers from these models contain fundamentally flawed reasoning -- a ``Right-for-Wrong-Reasons'' phenomenon invisible to standard accuracy metrics. Through analysis of 10,734 reasoning traces across three models and diverse tasks, we introduce the Reasoning Integrity Score (RIS), a process-based metric validated with substantial inter-rater agreement ($\\kappa=0.657$). Conventional practices are challenged by our findings: while retrieval-augmented generation (RAG) significantly improves reasoning integrity (Cohen's $d=0.23$--$0.93$), meta-cognitive interventions like self-critique often harm performance ($d=-0.14$ to $-0.33$) in small models on the evaluated tasks. Mechanistic analysis reveals RAG succeeds by grounding calculations in external evidence, reducing errors by 7.6\\%, while meta-cognition amplifies confusion without sufficient model capacity. To enable deployment, verification capabilities are distilled into a neural classifier achieving 0.86 F1-score with 100$\\times$ speedup. These results underscore the necessity of process-based verification for trustworthy agents: accuracy alone is dangerously insufficient when models can be right for entirely wrong reasons.",
      "url": "http://arxiv.org/abs/2601.00513",
      "author": "Laksh Advani",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Reveals that 50-69% of correct answers from small language models (7-9B parameters) contain fundamentally flawed reasoning. Introduces Reasoning Integrity Score (RIS) metric and finds RAG improves reasoning while self-critique often harms performance.",
      "importance_score": 75,
      "reasoning": "Critical finding for AI reliability and deployment. Challenges conventional practices around self-critique. Strong empirical basis with 10,734 traces. Important implications for agentic AI.",
      "themes": [
        "AI Safety",
        "Language Models",
        "Reasoning",
        "Reliability"
      ],
      "continuation": null
    },
    {
      "id": "d56a9a8e1378",
      "title": "Geometry of Reason: Spectral Signatures of Valid Mathematical Reasoning",
      "content": "We present a training-free method for detecting valid mathematical reasoning in large language models through spectral analysis of attention patterns. By treating attention matrices as adjacency matrices of dynamic graphs over tokens, we extract four interpretable spectral diagnostics, the Fiedler value (algebraic connectivity), high-frequency energy ratio (HFER), graph signal smoothness, and spectral entropy, that exhibit statistically significant differences between valid and invalid mathematical proofs. Experiments across seven transformer models from four independent architectural families (Meta Llama, Alibaba Qwen, Microsoft Phi, and Mistral AI) demonstrate that this spectral signature produces effect sizes up to Cohen's $d = 3.30$ ($p < 10^{-116}$), enabling 85.0--95.6\\% classification accuracy under rigorous evaluation, with calibrated thresholds reaching 93--95\\% on the full dataset. The method requires no training data, fine-tuning, or learned classifiers: a single threshold on a spectral metric suffices for high accuracy. Through systematic label correction, we discover that the spectral method detects logical coherence rather than compiler acceptance, identifying mathematically valid proofs that formal verifiers reject due to technical failures. We further identify an architectural dependency: Mistral-7B's Sliding Window Attention shifts the discriminative signal from HFER to late-layer Smoothness ($d = 2.09$, $p_{\\text{MW}} = 1.16 \\times 10^{-48}$), revealing that attention mechanism design affects which spectral features capture reasoning validity. These findings establish spectral graph analysis as a principled framework for reasoning verification with immediate applications to hallucination detection and AI safety monitoring.",
      "url": "http://arxiv.org/abs/2601.00791",
      "author": "Valentin No\\\"el",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Presents training-free method for detecting valid mathematical reasoning in LLMs through spectral analysis of attention patterns, achieving 85-95.6% accuracy with effect sizes up to Cohen's d=3.30 across seven models from four architecture families.",
      "importance_score": 75,
      "reasoning": "Highly novel approach using graph-theoretic spectral analysis for reasoning verification without training. Strong statistical results across diverse models. Important for interpretability and reasoning validation. Practical implications for detecting mathematical errors.",
      "themes": [
        "LLM Reasoning",
        "Interpretability",
        "Mathematical Reasoning",
        "Spectral Analysis"
      ],
      "continuation": null
    },
    {
      "id": "a05a702ee12a",
      "title": "The Role of Mixed-Language Documents for Multilingual Large Language Model Pretraining",
      "content": "Multilingual large language models achieve impressive cross-lingual performance despite largely monolingual pretraining. While bilingual data in pretraining corpora is widely believed to enable these abilities, details of its contributions remain unclear. We investigate this question by pretraining models from scratch under controlled conditions, comparing the standard web corpus with a monolingual-only version that removes all multilingual documents. Despite constituting only 2% of the corpus, removing bilingual data causes translation performance to drop 56% in BLEU, while behaviour on cross-lingual QA and general reasoning tasks remains stable, with training curves largely overlapping the baseline. To understand this asymmetry, we categorize bilingual data into parallel (14%), code-switching (72%), and miscellaneous documents (14%) based on the semantic relevance of content in different languages. We then conduct granular ablations by reintroducing parallel or code-switching data into the monolingual-only corpus. Our experiments reveal that parallel data almost fully restores translation performance (91% of the unfiltered baseline), whereas code-switching contributes minimally. Other cross-lingual tasks remain largely unaffected by either type. These findings reveal that translation critically depends on systematic token-level alignments from parallel data, whereas cross-lingual understanding and reasoning appear to be achievable even without bilingual data.",
      "url": "http://arxiv.org/abs/2601.00364",
      "author": "Jiandong Shao, Raphael Tang, Crystina Zhang, Karin Sevegnani, Pontus Stenetorp, Jianfei Yang, Yao Lu",
      "published": "2026-01-05",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Studies role of mixed-language (bilingual) documents in LLM pretraining. Finds removing 2% bilingual data causes 56% drop in translation BLEU but minimal impact on cross-lingual QA.",
      "importance_score": 74,
      "reasoning": "Important empirical study clarifying which cross-lingual abilities depend on bilingual data. Valuable for understanding LLM training.",
      "themes": [
        "LLM Pretraining",
        "Multilingual NLP",
        "Cross-Lingual Transfer"
      ],
      "continuation": null
    },
    {
      "id": "b8146f72f7c6",
      "title": "S1-MMAlign: A Large-Scale, Multi-Disciplinary Dataset for Scientific Figure-Text Understanding",
      "content": "Multimodal learning has revolutionized general domain tasks, yet its application in scientific discovery is hindered by the profound semantic gap between complex scientific imagery and sparse textual descriptions. We present S1-MMAlign, a large-scale, multi-disciplinary multimodal dataset comprising over 15.5 million high-quality image-text pairs derived from 2.5 million open-access scientific papers. Spanning disciplines from physics and biology to engineering, the dataset captures diverse visual modalities including experimental setups, heatmaps, and microscopic imagery. To address the pervasive issue of weak alignment in raw scientific captions, we introduce an AI-ready semantic enhancement pipeline that utilizes the Qwen-VL multimodal large model series to recaption images by synthesizing context from paper abstracts and citation contexts. Technical validation demonstrates that this enhancement significantly improves data quality: SciBERT-based pseudo-perplexity metrics show reduced semantic ambiguity, while CLIP scores indicate an 18.21% improvement in image-text alignment. S1-MMAlign provides a foundational resource for advancing scientific reasoning and cross-modal understanding in the era of AI for Science. The dataset is publicly available at https://huggingface.co/datasets/ScienceOne-AI/S1-MMAlign.",
      "url": "http://arxiv.org/abs/2601.00264",
      "author": "He Wang, Longteng Guo, Pengkang Huo, Xuanxu Lin, Yichen Yuan, Jie Jiang, Jing Liu",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Presents S1-MMAlign, a large-scale dataset of 15.5M image-text pairs from 2.5M scientific papers across multiple disciplines, with AI-enhanced semantic captions using Qwen-VL for recaptioning.",
      "importance_score": 73,
      "reasoning": "Major dataset contribution for scientific multimodal learning. Large scale and broad coverage addresses key gap in scientific AI.",
      "themes": [
        "Scientific AI",
        "Datasets",
        "Multimodal Learning",
        "Vision-Language"
      ],
      "continuation": null
    },
    {
      "id": "93e76f2e05f2",
      "title": "Revati: Transparent GPU-Free Time-Warp Emulation for LLM Serving",
      "content": "Deploying LLMs efficiently requires testing hundreds of serving configurations, but evaluating each one on a GPU cluster takes hours and costs thousands of dollars. Discrete-event simulators are faster and cheaper, but they require re-implementing the serving system's control logic -- a burden that compounds as frameworks evolve.   We present Revati, a time-warp emulator that enables performance modeling by directly executing real serving system code at simulation-like speed. The system intercepts CUDA API calls to virtualize device management, allowing serving frameworks to run without physical GPUs. Instead of executing GPU kernels, it performs time jumps -- fast-forwarding virtual time by predicted kernel durations. We propose a coordination protocol that synchronizes these jumps across distributed processes while preserving causality. On vLLM and SGLang, Revati achieves less than 5% prediction error across multiple models and parallelism configurations, while running 5-17x faster than real GPU execution.",
      "url": "http://arxiv.org/abs/2601.00397",
      "author": "Amey Agrawal, Mayank Yadav, Sukrit Kumar, Anirudha Agrawal, Garv Ghai, Souradeep Bera, Elton Pinto, Sirish Gambhira, Mohammad Adain, Kasra Sohrab, Chus Antonanzas, Alexey Tumanov",
      "published": "2026-01-05",
      "source": "arXiv (cs.DC)",
      "source_type": "arxiv",
      "tags": [
        "cs.DC"
      ],
      "summary": "Presents Revati, a time-warp emulator enabling LLM serving performance modeling by executing real serving code without GPUs through CUDA API interception and virtual time jumps.",
      "importance_score": 73,
      "reasoning": "Important practical tool for LLM deployment research. Enables testing hundreds of configurations without expensive GPU time.",
      "themes": [
        "LLM Serving",
        "Systems",
        "Simulation"
      ],
      "continuation": null
    },
    {
      "id": "d1ecd24907e1",
      "title": "TeleWorld: Towards Dynamic Multimodal Synthesis with a 4D World Model",
      "content": "World models aim to endow AI systems with the ability to represent, generate, and interact with dynamic environments in a coherent and temporally consistent manner. While recent video generation models have demonstrated impressive visual quality, they remain limited in real-time interaction, long-horizon consistency, and persistent memory of dynamic scenes, hindering their evolution into practical world models. In this report, we present TeleWorld, a real-time multimodal 4D world modeling framework that unifies video generation, dynamic scene reconstruction, and long-term world memory within a closed-loop system. TeleWorld introduces a novel generation-reconstruction-guidance paradigm, where generated video streams are continuously reconstructed into a dynamic 4D spatio-temporal representation, which in turn guides subsequent generation to maintain spatial, temporal, and physical consistency. To support long-horizon generation with low latency, we employ an autoregressive diffusion-based video model enhanced with Macro-from-Micro Planning (MMPL)--a hierarchical planning method that reduces error accumulation from frame-level to segment-level-alongside efficient Distribution Matching Distillation (DMD), enabling real-time synthesis under practical computational budgets. Our approach achieves seamless integration of dynamic object modeling and static scene representation within a unified 4D framework, advancing world models toward practical, interactive, and computationally accessible systems. Extensive experiments demonstrate that TeleWorld achieves strong performance in both static and dynamic world understanding, long-term consistency, and real-time generation efficiency, positioning it as a practical step toward interactive, memory-enabled world models for multimodal generation and embodied intelligence.",
      "url": "http://arxiv.org/abs/2601.00051",
      "author": "Yabo Chen, Yuanzhi Liang, Jiepeng Wang, Tingxi Chen, Junfei Cheng, Zixiao Gu, Yuyang Huang, Zicheng Jiang, Wei Li, Tian Li, Weichen Li, Zuoxin Li, Guangce Liu, Jialun Liu, Junqi Liu, Haoyuan Wang, Qizhen Weng, Xuan'er Wu, Xunzhi Xiang, Xiaoyan Yang, Xin Zhang, Shiwen Zhang, Junyu Zhou, Chengcheng Zhou, Haibin Huang, Chi Zhang, Xuelong Li",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Presents TeleWorld, a real-time multimodal 4D world modeling framework unifying video generation, dynamic scene reconstruction, and long-term world memory in a closed-loop system. Introduces generation-reconstruction-guidance paradigm with continuous 4D spatio-temporal representation.",
      "importance_score": 72,
      "reasoning": "Significant contribution to world models combining multiple capabilities. Addresses key limitations in real-time interaction and long-horizon consistency. Large multi-institutional team.",
      "themes": [
        "World Models",
        "Video Generation",
        "3D Reconstruction",
        "Multimodal AI"
      ],
      "continuation": null
    },
    {
      "id": "428f1226eba0",
      "title": "Overlooked Safety Vulnerability in LLMs: Malicious Intelligent Optimization Algorithm Request and its Jailbreak",
      "content": "The widespread deployment of large language models (LLMs) has raised growing concerns about their misuse risks and associated safety issues. While prior studies have examined the safety of LLMs in general usage, code generation, and agent-based applications, their vulnerabilities in automated algorithm design remain underexplored. To fill this gap, this study investigates this overlooked safety vulnerability, with a particular focus on intelligent optimization algorithm design, given its prevalent use in complex decision-making scenarios. We introduce MalOptBench, a benchmark consisting of 60 malicious optimization algorithm requests, and propose MOBjailbreak, a jailbreak method tailored for this scenario. Through extensive evaluation of 13 mainstream LLMs including the latest GPT-5 and DeepSeek-V3.1, we reveal that most models remain highly susceptible to such attacks, with an average attack success rate of 83.59% and an average harmfulness score of 4.28 out of 5 on original harmful prompts, and near-complete failure under MOBjailbreak. Furthermore, we assess state-of-the-art plug-and-play defenses that can be applied to closed-source models, and find that they are only marginally effective against MOBjailbreak and prone to exaggerated safety behaviors. These findings highlight the urgent need for stronger alignment techniques to safeguard LLMs against misuse in algorithm design.",
      "url": "http://arxiv.org/abs/2601.00213",
      "author": "Haoran Gu, Handing Wang, Yi Mei, Mengjie Zhang, Yaochu Jin",
      "published": "2026-01-05",
      "source": "arXiv (cs.CR)",
      "source_type": "arxiv",
      "tags": [
        "cs.CR"
      ],
      "summary": "Introduces MalOptBench benchmark with 60 malicious optimization requests and MOBjailbreak attack method for evaluating LLM safety in algorithm design. Evaluates 13 LLMs including GPT-5 and DeepSeek.",
      "importance_score": 72,
      "reasoning": "Important safety research uncovering new vulnerability domain in LLMs. Comprehensive benchmark testing latest models including GPT-5. Highly relevant for AI safety.",
      "themes": [
        "AI Safety",
        "LLM Security",
        "Jailbreaking",
        "Optimization"
      ],
      "continuation": null
    },
    {
      "id": "134998214b67",
      "title": "FlashInfer-Bench: Building the Virtuous Cycle for AI-driven LLM Systems",
      "content": "Recent advances show that large language models (LLMs) can act as autonomous agents capable of generating GPU kernels, but integrating these AI-generated kernels into real-world inference systems remains challenging. FlashInfer-Bench addresses this gap by establishing a standardized, closed-loop framework that connects kernel generation, benchmarking, and deployment. At its core, FlashInfer Trace provides a unified schema describing kernel definitions, workloads, implementations, and evaluations, enabling consistent communication between agents and systems. Built on real serving traces, FlashInfer-Bench includes a curated dataset, a robust correctness- and performance-aware benchmarking framework, a public leaderboard to track LLM agents' GPU programming capabilities, and a dynamic substitution mechanism (apply()) that seamlessly injects the best-performing kernels into production LLM engines such as SGLang and vLLM. Using FlashInfer-Bench, we further evaluate the performance and limitations of LLM agents, compare the trade-offs among different GPU programming languages, and provide insights for future agent design. FlashInfer-Bench thus establishes a practical, reproducible pathway for continuously improving AI-generated kernels and deploying them into large-scale LLM inference.",
      "url": "http://arxiv.org/abs/2601.00227",
      "author": "Shanli Xing, Yiyan Zhai, Alexander Jiang, Yixin Dong, Yong Wu, Zihao Ye, Charlie Ruan, Yingyi Huang, Yineng Zhang, Liangsheng Yin, Aksara Bayyapu, Luis Ceze, Tianqi Chen",
      "published": "2026-01-05",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Introduces FlashInfer-Bench, a standardized framework connecting AI-generated GPU kernel generation, benchmarking, and deployment for LLM serving. Features unified schema for kernel definitions and real serving traces.",
      "importance_score": 72,
      "reasoning": "From Tianqi Chen's group (TVM creator), addresses important practical problem of LLM deployment efficiency. Creates infrastructure for AI-driven systems improvement.",
      "themes": [
        "LLM Serving",
        "Systems Optimization",
        "Benchmarks",
        "GPU Programming"
      ],
      "continuation": null
    },
    {
      "id": "a65b235e13f8",
      "title": "The Generative AI Paradox: GenAI and the Erosion of Trust, the Corrosion of Information Verification, and the Demise of Truth",
      "content": "Generative AI (GenAI) now produces text, images, audio, and video that can be perceptually convincing at scale and at negligible marginal cost. While public debate often frames the associated harms as \"deepfakes\" or incremental extensions of misinformation and fraud, this view misses a broader socio-technical shift: GenAI enables synthetic realities; coherent, interactive, and potentially personalized information environments in which content, identity, and social interaction are jointly manufactured and mutually reinforcing. We argue that the most consequential risk is not merely the production of isolated synthetic artifacts, but the progressive erosion of shared epistemic ground and institutional verification practices as synthetic content, synthetic identity, and synthetic interaction become easy to generate and hard to audit. This paper (i) formalizes synthetic reality as a layered stack (content, identity, interaction, institutions), (ii) expands a taxonomy of GenAI harms spanning personal, economic, informational, and socio-technical risks, (iii) articulates the qualitative shifts introduced by GenAI (cost collapse, throughput, customization, micro-segmentation, provenance gaps, and trust erosion), and (iv) synthesizes recent risk realizations (2023-2025) into a compact case bank illustrating how these mechanisms manifest in fraud, elections, harassment, documentation, and supply-chain compromise. We then propose a mitigation stack that treats provenance infrastructure, platform governance, institutional workflow redesign, and public resilience as complementary rather than substitutable, and outline a research agenda focused on measuring epistemic security. We conclude with the Generative AI Paradox: as synthetic media becomes ubiquitous, societies may rationally discount digital evidence altogether.",
      "url": "http://arxiv.org/abs/2601.00306",
      "author": "Emilio Ferrara",
      "published": "2026-01-05",
      "source": "arXiv (cs.CY)",
      "source_type": "arxiv",
      "tags": [
        "cs.CY"
      ],
      "summary": "Argues that generative AI creates 'synthetic realities' that erode epistemic foundations and institutional verification practices, going beyond concerns about individual deepfakes to systemic trust issues.",
      "importance_score": 72,
      "reasoning": "From Emilio Ferrara, known researcher. Important conceptual framing of GenAI's societal risks at systemic level beyond individual artifacts.",
      "themes": [
        "AI Safety",
        "Misinformation",
        "Societal Impact",
        "AI Ethics"
      ],
      "continuation": null
    },
    {
      "id": "8c78bb930e27",
      "title": "The Illusion of Insight in Reasoning Models",
      "content": "Do reasoning models have \"Aha!\" moments? Prior work suggests that models like DeepSeek-R1-Zero undergo sudden mid-trace realizations that lead to accurate outputs, implying an intrinsic capacity for self-correction. Yet, it remains unclear whether such intrinsic shifts in reasoning strategy actually improve performance. Here, we study mid-reasoning shifts and instrument training runs to detect them. Our analysis spans 1M+ reasoning traces, hundreds of training checkpoints, three reasoning domains, and multiple decoding temperatures and model architectures. We find that reasoning shifts are rare, do not become more frequent with training, and seldom improve accuracy, indicating that they do not correspond to prior perceptions of model insight. However, their effect varies with model uncertainty. Building on this finding, we show that artificially triggering extrinsic shifts under high entropy reliably improves accuracy. Our results show that mid-reasoning shifts are symptoms of unstable inference behavior rather than an intrinsic mechanism for self-correction.",
      "url": "http://arxiv.org/abs/2601.00514",
      "author": "Liv G. d'Aliberti and Manoel Horta Ribeiro",
      "published": "2026-01-05",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Studies 'Aha moments' in reasoning models like DeepSeek-R1-Zero through analysis of 1M+ reasoning traces. Finds mid-reasoning shifts are rare, don't increase with training, and seldom improve accuracy.",
      "importance_score": 72,
      "reasoning": "Important empirical investigation challenging claims about emergent reasoning capabilities. Large-scale analysis across checkpoints and architectures. Valuable for understanding reasoning model behavior.",
      "themes": [
        "Reasoning Models",
        "Language Models",
        "Empirical Analysis"
      ],
      "continuation": null
    },
    {
      "id": "2608d61e9d35",
      "title": "The Reasoning-Creativity Trade-off: Toward Creativity-Driven Problem Solving",
      "content": "State-of-the-art large language model (LLM) pipelines rely on bootstrapped reasoning loops: sampling diverse chains of thought and reinforcing the highest-scoring ones, mainly optimizing correctness. We analyze how this design choice is sensitive to the collapse of the model's distribution over reasoning paths, slashing semantic entropy and undermining creative problem-solving. To analyze this failure, we introduce Distributional Creative Reasoning (DCR), a unified variational objective that casts training as gradient flow through probability measures on solution traces. STaR, GRPO, and DPO, as well as entropy bonuses, and other methods, all constitute special cases of the same loss. The framework delivers three core results: (i) the diversity decay theorem, describing how correctness-based objectives lead to distinct modes of diversity decay for STaR, GRPO, and DPO; (ii) designs that ensure convergence to a stable and diverse policy, effectively preventing collapse; and (iii) simple, actionable recipes to achieve this in practice. DCR thus offers the first principled recipe for LLMs that remain both correct and creative.",
      "url": "http://arxiv.org/abs/2601.00747",
      "author": "Max Ruiz Luyten, Mihaela van der Schaar",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces Distributional Creative Reasoning (DCR), a variational framework analyzing how correctness-focused training collapses diversity in LLM reasoning. Shows STaR, GRPO, DPO are special cases and proves diversity decay theorem.",
      "importance_score": 72,
      "reasoning": "Important theoretical contribution connecting reasoning training methods under unified framework. The diversity decay analysis has significant implications for understanding LLM training dynamics. Relevant to ongoing debates about reasoning capabilities.",
      "themes": [
        "LLM Reasoning",
        "Training Dynamics",
        "Creativity",
        "Theoretical ML"
      ],
      "continuation": null
    },
    {
      "id": "3de99babc566",
      "title": "Task-Driven Kernel Flows: Label Rank Compression and Laplacian Spectral Filtering",
      "content": "We present a theory of feature learning in wide L2-regularized networks showing that supervised learning is inherently compressive. We derive a kernel ODE that predicts a \"water-filling\" spectral evolution and prove that for any stable steady state, the kernel rank is bounded by the number of classes ($C$). We further demonstrate that SGD noise is similarly low-rank ($O(C)$), confining dynamics to the task-relevant subspace. This framework unifies the deterministic and stochastic views of alignment and contrasts the low-rank nature of supervised learning with the high-rank, expansive representations of self-supervision.",
      "url": "http://arxiv.org/abs/2601.00276",
      "author": "Hongxi Li and Chunlin Huang",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Presents theoretical framework showing supervised learning is inherently compressive, with kernel rank bounded by number of classes. Derives kernel ODE predicting 'water-filling' spectral evolution.",
      "importance_score": 71,
      "reasoning": "Strong theoretical contribution unifying deterministic and stochastic views of neural network feature learning. Insightful analysis.",
      "themes": [
        "Deep Learning Theory",
        "Feature Learning",
        "Kernel Methods"
      ],
      "continuation": null
    },
    {
      "id": "a9b42046282b",
      "title": "Spatial4D-Bench: A Versatile 4D Spatial Intelligence Benchmark",
      "content": "4D spatial intelligence involves perceiving and processing how objects move or change over time. Humans naturally possess 4D spatial intelligence, supporting a broad spectrum of spatial reasoning abilities. To what extent can Multimodal Large Language Models (MLLMs) achieve human-level 4D spatial intelligence? In this work, we present Spatial4D-Bench, a versatile 4D spatial intelligence benchmark designed to comprehensively assess the 4D spatial reasoning abilities of MLLMs. Unlike existing spatial intelligence benchmarks that are often small-scale or limited in diversity, Spatial4D-Bench provides a large-scale, multi-task evaluation benchmark consisting of ~40,000 question-answer pairs covering 18 well-defined tasks. We systematically organize these tasks into six cognitive categories: object understanding, scene understanding, spatial relationship understanding, spatiotemporal relationship understanding, spatial reasoning and spatiotemporal reasoning. Spatial4D-Bench thereby offers a structured and comprehensive benchmark for evaluating the spatial cognition abilities of MLLMs, covering a broad spectrum of tasks that parallel the versatility of human spatial intelligence. We benchmark various state-of-the-art open-source and proprietary MLLMs on Spatial4D-Bench and reveal their substantial limitations in a wide variety of 4D spatial reasoning aspects, such as route plan, action recognition, and physical plausibility reasoning. We hope that the findings provided in this work offer valuable insights to the community and that our benchmark can facilitate the development of more capable MLLMs toward human-level 4D spatial intelligence. More resources can be found on our project page.",
      "url": "http://arxiv.org/abs/2601.00092",
      "author": "Pan Wang, Yang Liu, Guile Wu, Eduardo R. Corral-Soto, Chengjie Huang, Binbin Xu, Dongfeng Bai, Xu Yan, Yuan Ren, Xingxin Chen, Yizhe Wu, Tao Huang, Wenjun Wan, Xin Wu, Pei Zhou, Xuyang Dai, Kangbo Lv, Hongbo Zhang, Yosef Fried, Aixue Ye, Bailan Feng, Zhenyu Chen, Zhen Li, Yingcong Chen, Yiyi Liao, Bingbing Liu",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Introduces Spatial4D-Bench, a large-scale benchmark for evaluating 4D spatial intelligence in MLLMs with ~40,000 QA pairs across 18 tasks and 6 cognitive categories covering object identification, motion, counting, spatial relationships, and reasoning.",
      "importance_score": 70,
      "reasoning": "Comprehensive benchmark addressing gap in MLLM evaluation for spatial-temporal reasoning. Large scale with systematic task organization. Important for advancing 4D understanding.",
      "themes": [
        "Benchmarks",
        "Multimodal LLMs",
        "Spatial Intelligence",
        "4D Understanding"
      ],
      "continuation": null
    },
    {
      "id": "29279ff21c4e",
      "title": "TotalFM: An Organ-Separated Framework for 3D-CT Vision Foundation Models",
      "content": "While foundation models in radiology are expected to be applied to various clinical tasks, computational cost constraints remain a major challenge when training on 3D-CT volumetric data. In this study, we propose TotalFM, a radiological foundation model that efficiently learns the correspondence between 3D-CT images and linguistic expressions based on the concept of organ separation, utilizing a large-scale dataset of 140,000 series. By automating the creation of organ volume and finding-sentence pairs through segmentation techniques and Large Language Model (LLM)-based radiology report processing, and by combining self-supervised pre-training via VideoMAE with contrastive learning using volume-text pairs, we aimed to balance computational efficiency and representation capability. In zero-shot organ-wise lesion classification tasks, the proposed model achieved higher F1 scores in 83% (5/6) of organs compared to CT-CLIP and 64% (9/14) of organs compared to Merlin. These results suggest that the proposed model exhibits high generalization performance in a clinical evaluation setting using actual radiology report sentences. Furthermore, in zero-shot finding-wise lesion classification tasks, our model achieved a higher AUROC in 83% (25/30) of finding categories compared to Merlin. We also confirmed performance comparable to existing Vision-Language Models (VLMs) in radiology report generation tasks. Our results demonstrate that the organ-separated learning framework can serve as a realistic and effective design guideline for the practical implementation of 3D-CT foundation models.",
      "url": "http://arxiv.org/abs/2601.00260",
      "author": "Kohei Yamamoto and Tomohiro Kikuchi",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Introduces TotalFM, a radiological foundation model for 3D-CT images using organ separation, trained on 140,000 series. Combines VideoMAE self-supervised pretraining with contrastive learning using LLM-processed reports.",
      "importance_score": 70,
      "reasoning": "Large-scale medical foundation model with novel organ-separation concept. Addresses computational challenges of volumetric medical imaging.",
      "themes": [
        "Medical AI",
        "Foundation Models",
        "3D Vision"
      ],
      "continuation": null
    },
    {
      "id": "dc48e5f6ef3f",
      "title": "Mapping Human Anti-collusion Mechanisms to Multi-agent AI",
      "content": "As multi-agent AI systems become increasingly autonomous, evidence shows they can develop collusive strategies similar to those long observed in human markets and institutions. While human domains have accumulated centuries of anti-collusion mechanisms, it remains unclear how these can be adapted to AI settings. This paper addresses that gap by (i) developing a taxonomy of human anti-collusion mechanisms, including sanctions, leniency & whistleblowing, monitoring & auditing, market design, and governance and (ii) mapping them to potential interventions for multi-agent AI systems. For each mechanism, we propose implementation approaches. We also highlight open challenges, such as the attribution problem (difficulty attributing emergent coordination to specific agents) identity fluidity (agents being easily forked or modified) the boundary problem (distinguishing beneficial cooperation from harmful collusion) and adversarial adaptation (agents learning to evade detection).",
      "url": "http://arxiv.org/abs/2601.00360",
      "author": "Jamiu Adekunle Idowu, Ahmed Almasoud, Ayman Alfahid",
      "published": "2026-01-05",
      "source": "arXiv (cs.MA)",
      "source_type": "arxiv",
      "tags": [
        "cs.MA"
      ],
      "summary": "Develops taxonomy of human anti-collusion mechanisms and maps them to multi-agent AI systems, proposing implementation approaches for preventing AI agent collusion.",
      "importance_score": 70,
      "reasoning": "Important emerging topic as AI agents become more autonomous. Novel conceptual framework bridging human institutions and AI systems.",
      "themes": [
        "Multi-Agent AI",
        "AI Safety",
        "AI Governance"
      ],
      "continuation": null
    },
    {
      "id": "f435728e1735",
      "title": "ClinicalReTrial: A Self-Evolving AI Agent for Clinical Trial Protocol Optimization",
      "content": "Clinical trial failure remains a central bottleneck in drug development, where minor protocol design flaws can irreversibly compromise outcomes despite promising therapeutics. Although cutting-edge AI methods achieve strong performance in predicting trial success, they are inherently reactive for merely diagnosing risk without offering actionable remedies once failure is anticipated. To fill this gap, this paper proposes ClinicalReTrial, a self-evolving AI agent framework that addresses this gap by casting clinical trial reasoning as an iterative protocol redesign problem. Our method integrates failure diagnosis, safety-aware modification, and candidate evaluation in a closed-loop, reward-driven optimization framework. Serving the outcome prediction model as a simulation environment, ClinicalReTrial enables low-cost evaluation of protocol modifications and provides dense reward signals for continuous self-improvement. To support efficient exploration, the framework maintains hierarchical memory that captures iteration-level feedback within trials and distills transferable redesign patterns across trials. Empirically, ClinicalReTrial improves 83.3% of trial protocols with a mean success probability gain of 5.7%, and retrospective case studies demonstrate strong alignment between the discovered redesign strategies and real-world clinical trial modifications.",
      "url": "http://arxiv.org/abs/2601.00290",
      "author": "Sixue Xing, Xuanye Xia, Kerui Wu, Meng Jiang, Jintai Chen, Tianfan Fu",
      "published": "2026-01-05",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Introduces ClinicalReTrial, a self-evolving AI agent for iterative clinical trial protocol redesign that integrates failure diagnosis, safety-aware modification, and candidate evaluation in closed-loop optimization.",
      "importance_score": 69,
      "reasoning": "Novel application of AI agents to important healthcare problem. Moves beyond prediction to actionable intervention design.",
      "themes": [
        "AI Agents",
        "Healthcare AI",
        "Clinical Trials"
      ],
      "continuation": null
    },
    {
      "id": "3b1f57599b71",
      "title": "Deep Delta Learning",
      "content": "The efficacy of deep residual networks is fundamentally predicated on the identity shortcut connection. While this mechanism effectively mitigates the vanishing gradient problem, it imposes a strictly additive inductive bias on feature transformations, thereby limiting the network's capacity to model complex state transitions. In this paper, we introduce Deep Delta Learning (DDL), a novel architecture that generalizes the standard residual connection by modulating the identity shortcut with a learnable, data-dependent geometric transformation. This transformation, termed the Delta Operator, constitutes a rank-1 perturbation of the identity matrix, parameterized by a reflection direction vector $\\mathbf{k}(\\mathbf{X})$ and a gating scalar $\\beta(\\mathbf{X})$. We provide a spectral analysis of this operator, demonstrating that the gate $\\beta(\\mathbf{X})$ enables dynamic interpolation between identity mapping, orthogonal projection, and geometric reflection. Furthermore, we restructure the residual update as a synchronous rank-1 injection, where the gate acts as a dynamic step size governing both the erasure of old information and the writing of new features. This unification empowers the network to explicitly control the spectrum of its layer-wise transition operator, enabling the modeling of complex, non-monotonic dynamics while preserving the stable training characteristics of gated residual architectures.",
      "url": "http://arxiv.org/abs/2601.00417",
      "author": "Yifan Zhang, Yifeng Liu, Mengdi Wang, Quanquan Gu",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces Deep Delta Learning (DDL), generalizing residual connections with learnable rank-1 perturbations of identity via data-dependent reflection vectors and gating scalars.",
      "importance_score": 69,
      "reasoning": "Novel architectural contribution with theoretical spectral analysis. Generalizes fundamental residual connection concept.",
      "themes": [
        "Neural Architecture",
        "Deep Learning",
        "Residual Networks"
      ],
      "continuation": null
    },
    {
      "id": "374cfb6a69d2",
      "title": "It's Never Too Late: Noise Optimization for Collapse Recovery in Trained Diffusion Models",
      "content": "Contemporary text-to-image models exhibit a surprising degree of mode collapse, as can be seen when sampling several images given the same text prompt. While previous work has attempted to address this issue by steering the model using guidance mechanisms, or by generating a large pool of candidates and refining them, in this work we take a different direction and aim for diversity in generations via noise optimization. Specifically, we show that a simple noise optimization objective can mitigate mode collapse while preserving the fidelity of the base model. We also analyze the frequency characteristics of the noise and show that alternative noise initializations with different frequency profiles can improve both optimization and search. Our experiments demonstrate that noise optimization yields superior results in terms of generation quality and variety.",
      "url": "http://arxiv.org/abs/2601.00090",
      "author": "Anne Harrington, A. Sophia Koepke, Shyamgopal Karthik, Trevor Darrell, Alexei A. Efros",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes noise optimization to mitigate mode collapse in text-to-image models while preserving fidelity. Analyzes frequency characteristics showing alternative noise initializations improve both optimization and search. From Berkeley (Darrell, Efros).",
      "importance_score": 68,
      "reasoning": "Addresses fundamental limitation of diffusion models from prominent researchers. Novel direction focusing on noise rather than guidance. Strong author credentials.",
      "themes": [
        "Text-to-Image Generation",
        "Diffusion Models",
        "Mode Collapse",
        "Generative AI"
      ],
      "continuation": null
    },
    {
      "id": "56ad50a7a2bd",
      "title": "GRIT -- Geometry-Aware PEFT with K-FACPreconditioning, Fisher-Guided Reprojection, andDynamic Rank Adaptation",
      "content": "Parameter-efficient fine-tuning (PEFT) is the default way to adapt LLMs, but widely used LoRA and QLoRA are largely geometry-agnostic: they optimize in fixed, randomly oriented low-rank subspaces with first-order descent, mostly ignoring local loss curvature. This can inflate the effective update budget and amplify drift along weakly constrained directions. We introduce GRIT, a dynamic, curvature-aware LoRA procedure that preserves the LoRA parameterization but: (1) preconditions gradients in rank space using K-FAC as a natural-gradient proxy; (2) periodically reprojects the low-rank basis onto dominant Fisher eigendirections to suppress drift; and (3) adapts the effective rank from the spectrum so capacity concentrates where signal resides. Across instruction-following, comprehension, and reasoning benchmarks on LLaMA backbones, GRIT matches or surpasses LoRA and QLoRA while reducing trainable parameters by 46% on average (25--80% across tasks), without practical quality loss across prompt styles and data mixes. To model forgetting, we fit a curvature-modulated power law. Empirically, GRIT yields lower drift and a better updates-vs-retention frontier than strong PEFT-optimizer baselines (Orthogonal-LoRA, IA3, DoRA, Eff-FT, Shampoo).",
      "url": "http://arxiv.org/abs/2601.00231",
      "author": "Pritish Saha, Chandrav Rajbangshi, Rudra Goyal, Mohit Goyal, Anurag Deo, Biswajit Roy, Ningthoujam Dhanachandra Singh, Raxit Goswami, Amitava Das",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes GRIT, a curvature-aware LoRA variant that uses K-FAC preconditioning, Fisher-guided reprojection, and dynamic rank adaptation. Addresses the geometry-agnostic nature of standard LoRA.",
      "importance_score": 68,
      "reasoning": "Meaningful improvement to LoRA with principled theoretical motivation. Addresses known limitation of geometry-agnostic low-rank adaptation.",
      "themes": [
        "Parameter-Efficient Fine-Tuning",
        "LLM Training",
        "Optimization"
      ],
      "continuation": null
    },
    {
      "id": "3564d5862178",
      "title": "NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos",
      "content": "In this paper, we propose NeoVerse, a versatile 4D world model that is capable of 4D reconstruction, novel-trajectory video generation, and rich downstream applications. We first identify a common limitation of scalability in current 4D world modeling methods, caused either by expensive and specialized multi-view 4D data or by cumbersome training pre-processing. In contrast, our NeoVerse is built upon a core philosophy that makes the full pipeline scalable to diverse in-the-wild monocular videos. Specifically, NeoVerse features pose-free feed-forward 4D reconstruction, online monocular degradation pattern simulation, and other well-aligned techniques. These designs empower NeoVerse with versatility and generalization to various domains. Meanwhile, NeoVerse achieves state-of-the-art performance in standard reconstruction and generation benchmarks. Our project page is available at https://neoverse-4d.github.io",
      "url": "http://arxiv.org/abs/2601.00393",
      "author": "Yuxue Yang, Lue Fan, Ziqi Shi, Junran Peng, Feng Wang, Zhaoxiang Zhang",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes NeoVerse, a scalable 4D world model for reconstruction and novel-trajectory generation from in-the-wild monocular videos using pose-free feed-forward approach with degradation simulation.",
      "importance_score": 68,
      "reasoning": "Strong contribution to scalable 4D world modeling. Addresses key limitation of requiring multi-view or specialized data.",
      "themes": [
        "4D World Models",
        "Novel View Synthesis",
        "Computer Vision"
      ],
      "continuation": null
    },
    {
      "id": "3b793eaebc63",
      "title": "Defensive M2S: Training Guardrail Models on Compressed Multi-turn Conversations",
      "content": "Guardrail models are essential for ensuring the safety of Large Language Model (LLM) deployments, but processing full multi-turn conversation histories incurs significant computational cost. We propose Defensive M2S, a training paradigm that fine-tunes guardrail models on Multi-turn to Single-turn (M2S) compressed conversations rather than complete dialogue histories. We provide a formal complexity analysis showing that M2S reduces training cost from $O(n^2)$ to $O(n)$ for $n$-turn conversations. Empirically, on our training dataset (779 samples, avg. 10.6 turns), M2S requires only 169K tokens compared to 15.7M tokens for the multi-turn baseline -- a 93$\\times$ reduction. We evaluate Defensive M2S across three guardrail model families (LlamaGuard, Nemotron, Qwen3Guard) and three compression templates (hyphenize, numberize, pythonize) on SafeDialBench, a comprehensive multi-turn jailbreak benchmark. Our best configuration, Qwen3Guard with hyphenize compression, achieves 93.8% attack detection recall while reducing inference tokens by 94.6% (from 3,231 to 173 tokens per conversation). This represents a 38.9 percentage point improvement over the baseline while dramatically reducing both training and inference costs. Our findings demonstrate that M2S compression can serve as an effective efficiency technique for guardrail deployment, enabling scalable safety screening of long multi-turn conversations.",
      "url": "http://arxiv.org/abs/2601.00454",
      "author": "Hyunjun Kim",
      "published": "2026-01-05",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes training guardrail models on compressed multi-turn conversations instead of full histories, achieving 93x token reduction while maintaining safety performance across multiple guardrail model families.",
      "importance_score": 68,
      "reasoning": "Highly practical contribution for LLM safety infrastructure. Significant efficiency gains with strong empirical validation across LlamaGuard, Nemotron, and Qwen3Guard. Direct impact on deployment costs.",
      "themes": [
        "AI Safety",
        "Language Models",
        "Efficiency",
        "Guardrails"
      ],
      "continuation": null
    },
    {
      "id": "a5f921f73fee",
      "title": "Fast-weight Product Key Memory",
      "content": "Sequence modeling layers in modern language models typically face a trade-off between storage capacity and computational efficiency. While Softmax attention offers unbounded storage at prohibitive quadratic costs, linear variants provide efficiency but suffer from limited, fixed-size storage. We propose Fast-weight Product Key Memory (FwPKM), a novel architecture that resolves this tension by transforming the sparse Product Key Memory (PKM) from a static module into a dynamic, \"fast-weight\" episodic memory. Unlike PKM, FwPKM updates its parameters dynamically at both training and inference time via local chunk-level gradient descent, allowing the model to rapidly memorize and retrieve new key-value pairs from input sequences. Experiments reveal that FwPKM functions as an effective episodic memory that complements the semantic memory of standard modules, yielding significant perplexity reductions on long-context datasets. Notably, in Needle in a Haystack evaluations, FwPKM generalizes to 128K-token contexts despite being trained on only 4K-token sequences.",
      "url": "http://arxiv.org/abs/2601.00671",
      "author": "Tianyu Zhao and Llion Jones",
      "published": "2026-01-05",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes Fast-weight Product Key Memory (FwPKM), a novel architecture that transforms sparse Product Key Memory into dynamic episodic memory through local gradient descent updates at both training and inference time. Addresses the storage-efficiency tradeoff in sequence modeling.",
      "importance_score": 68,
      "reasoning": "Interesting architectural innovation addressing fundamental transformer limitations. Author Llion Jones is a notable researcher (Attention Is All You Need co-author). The dynamic episodic memory concept could influence future architecture design.",
      "themes": [
        "Language Models",
        "Memory-Augmented Networks",
        "Neural Architecture"
      ],
      "continuation": null
    },
    {
      "id": "98a4d1fc6a5a",
      "title": "ActErase: A Training-Free Paradigm for Precise Concept Erasure via Activation Patching",
      "content": "Recent advances in text-to-image diffusion models have demonstrated remarkable generation capabilities, yet they raise significant concerns regarding safety, copyright, and ethical implications. Existing concept erasure methods address these risks by removing sensitive concepts from pre-trained models, but most of them rely on data-intensive and computationally expensive fine-tuning, which poses a critical limitation. To overcome these challenges, inspired by the observation that the model's activations are predominantly composed of generic concepts, with only a minimal component can represent the target concept, we propose a novel training-free method (ActErase) for efficient concept erasure. Specifically, the proposed method operates by identifying activation difference regions via prompt-pair analysis, extracting target activations and dynamically replacing input activations during forward passes. Comprehensive evaluations across three critical erasure tasks (nudity, artistic style, and object removal) demonstrates that our training-free method achieves state-of-the-art (SOTA) erasure performance, while effectively preserving the model's overall generative capability. Our approach also exhibits strong robustness against adversarial attacks, establishing a new plug-and-play paradigm for lightweight yet effective concept manipulation in diffusion models.",
      "url": "http://arxiv.org/abs/2601.00267",
      "author": "Yi Sun, Xinhao Zhong, Hongyan Li, Yimin Zhou, Junhao Li, Bin Chen, Xuan Wang",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes ActErase, a training-free method for concept erasure in diffusion models by identifying and removing activation components corresponding to target concepts via prompt comparison.",
      "importance_score": 67,
      "reasoning": "Addresses important safety concern of removing harmful concepts from generative models without expensive retraining. Novel activation-based approach.",
      "themes": [
        "AI Safety",
        "Diffusion Models",
        "Concept Erasure"
      ],
      "continuation": null
    },
    {
      "id": "866ba95fa16a",
      "title": "In Line with Context: Repository-Level Code Generation via Context Inlining",
      "content": "Repository-level code generation has attracted growing attention in recent years. Unlike function-level code generation, it requires the model to understand the entire repository, reasoning over complex dependencies across functions, classes, and modules. However, existing approaches such as retrieval-augmented generation (RAG) or context-based function selection often fall short: they primarily rely on surface-level similarity and struggle to capture the rich dependencies that govern repository-level semantics. In this paper, we introduce InlineCoder, a novel framework for repository-level code generation. InlineCoder enhances the understanding of repository context by inlining the unfinished function into its call graph, thereby reframing the challenging repository understanding as an easier function-level coding task. Given a function signature, InlineCoder first generates a draft completion, termed an anchor, which approximates downstream dependencies and enables perplexity-based confidence estimation. This anchor drives a bidirectional inlining process: (i) Upstream Inlining, which embeds the anchor into its callers to capture diverse usage scenarios; and (ii) Downstream Retrieval, which integrates the anchor's callees into the prompt to provide precise dependency context. The enriched context, combining draft completion with upstream and downstream perspectives, equips the LLM with a comprehensive repository view.",
      "url": "http://arxiv.org/abs/2601.00376",
      "author": "Chao Hu, Wenhao Zeng, Yuling Shi, Beijun Shen, Xiaodong Gu",
      "published": "2026-01-05",
      "source": "arXiv (cs.SE)",
      "source_type": "arxiv",
      "tags": [
        "cs.SE"
      ],
      "summary": "Introduces InlineCoder for repository-level code generation by inlining unfinished functions into their call graphs, transforming repository understanding into easier inter-procedural analysis.",
      "importance_score": 66,
      "reasoning": "Novel and practical approach to challenging repo-level code generation. Clever reformulation of the problem.",
      "themes": [
        "Code Generation",
        "LLM Applications",
        "Software Engineering"
      ],
      "continuation": null
    },
    {
      "id": "a644df769e03",
      "title": "From Sight to Insight: Improving Visual Reasoning Capabilities of Multimodal Models via Reinforcement Learning",
      "content": "Reinforcement learning (RL) has emerged as a promising approach for eliciting reasoning chains before generating final answers. However, multimodal large language models (MLLMs) generate reasoning that lacks integration of visual information. This limits their ability to solve problems that demand accurate visual perception, such as visual puzzles. We show that visual perception is the key bottleneck in such tasks: converting images into textual descriptions significantly improves performance, yielding gains of 26.7% for Claude 3.5 and 23.6% for Claude 3.7.   To address this, we investigate reward-driven RL as a mechanism to unlock long visual reasoning in open-source MLLMs without requiring costly supervision. We design and evaluate six reward functions targeting different reasoning aspects, including image understanding, thinking steps, and answer accuracy. Using group relative policy optimization (GRPO), our approach explicitly incentivizes longer, structured reasoning and mitigates bypassing of visual information. Experiments on Qwen-2.5-VL-7B achieve 5.56% improvements over the base model, with consistent gains across both in-domain and out-of-domain settings.",
      "url": "http://arxiv.org/abs/2601.00215",
      "author": "Omar Sharif, Eftekhar Hossain, Patrick Ng",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Shows visual perception is key bottleneck in MLLM reasoning (26.7% gain for Claude 3.5 with text descriptions). Investigates RL with six reward functions to improve visual reasoning without costly supervision.",
      "importance_score": 65,
      "reasoning": "Important empirical finding about visual reasoning bottleneck. Systematic investigation of RL for visual reasoning improvement.",
      "themes": [
        "Multimodal LLMs",
        "Visual Reasoning",
        "Reinforcement Learning"
      ],
      "continuation": null
    },
    {
      "id": "ab737d7bddcc",
      "title": "Neural Minimum Weight Perfect Matching for Quantum Error Codes",
      "content": "Realizing the full potential of quantum computation requires Quantum Error Correction (QEC). QEC reduces error rates by encoding logical information across redundant physical qubits, enabling errors to be detected and corrected. A common decoder used for this task is Minimum Weight Perfect Matching (MWPM) a graph-based algorithm that relies on edge weights to identify the most likely error chains. In this work, we propose a data-driven decoder named Neural Minimum Weight Perfect Matching (NMWPM). Our decoder utilizes a hybrid architecture that integrates Graph Neural Networks (GNNs) to extract local syndrome features and Transformers to capture long-range global dependencies, which are then used to predict dynamic edge weights for the MWPM decoder. To facilitate training through the non-differentiable MWPM algorithm, we formulate a novel proxy loss function that enables end-to-end optimization. Our findings demonstrate significant performance reduction in the Logical Error Rate (LER) over standard baselines, highlighting the advantage of hybrid decoders that combine the predictive capabilities of neural networks with the algorithmic structure of classical matching.",
      "url": "http://arxiv.org/abs/2601.00242",
      "author": "Yotam Peled, David Zenati, Eliya Nachmani",
      "published": "2026-01-05",
      "source": "arXiv (quant-ph)",
      "source_type": "arxiv",
      "tags": [
        "quant-ph"
      ],
      "summary": "Proposes Neural MWPM, a hybrid GNN-Transformer architecture for quantum error correction that predicts dynamic edge weights for minimum weight perfect matching decoder. Integrates local syndrome features with global dependencies.",
      "importance_score": 65,
      "reasoning": "Novel approach to important quantum computing problem. Combines modern deep learning with classical decoding algorithms for QEC.",
      "themes": [
        "Quantum Computing",
        "Error Correction",
        "Graph Neural Networks"
      ],
      "continuation": null
    },
    {
      "id": "daf96d159be8",
      "title": "Deep Networks Learn Deep Hierarchical Models",
      "content": "We consider supervised learning with $n$ labels and show that layerwise SGD on residual networks can efficiently learn a class of hierarchical models. This model class assumes the existence of an (unknown) label hierarchy $L_1 \\subseteq L_2 \\subseteq \\dots \\subseteq L_r = [n]$, where labels in $L_1$ are simple functions of the input, while for $i > 1$, labels in $L_i$ are simple functions of simpler labels.   Our class surpasses models that were previously shown to be learnable by deep learning algorithms, in the sense that it reaches the depth limit of efficient learnability. That is, there are models in this class that require polynomial depth to express, whereas previous models can be computed by log-depth circuits.   Furthermore, we suggest that learnability of such hierarchical models might eventually form a basis for understanding deep learning. Beyond their natural fit for domains where deep learning excels, we argue that the mere existence of human ``teachers\" supports the hypothesis that hierarchical structures are inherently available. By providing granular labels, teachers effectively reveal ``hints'' or ``snippets'' of the internal algorithms used by the brain. We formalize this intuition, showing that in a simplified model where a teacher is partially aware of their internal logic, a hierarchical structure emerges that facilitates efficient learnability.",
      "url": "http://arxiv.org/abs/2601.00455",
      "author": "Amit Daniely",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Theoretical result showing layerwise SGD on residual networks can efficiently learn hierarchical models where deeper labels depend on simpler labels, reaching the depth limit of efficient learnability.",
      "importance_score": 65,
      "reasoning": "Strong theoretical contribution to understanding deep learning learnability. Proves models requiring polynomial depth can be learned, advancing theory beyond log-depth circuits.",
      "themes": [
        "Deep Learning Theory",
        "Hierarchical Learning",
        "Learnability"
      ],
      "continuation": null
    },
    {
      "id": "67549646fc33",
      "title": "Ask, Clarify, Optimize: Human-LLM Agent Collaboration for Smarter Inventory Control",
      "content": "Inventory management remains a challenge for many small and medium-sized businesses that lack the expertise to deploy advanced optimization methods. This paper investigates whether Large Language Models (LLMs) can help bridge this gap. We show that employing LLMs as direct, end-to-end solvers incurs a significant \"hallucination tax\": a performance gap arising from the model's inability to perform grounded stochastic reasoning. To address this, we propose a hybrid agentic framework that strictly decouples semantic reasoning from mathematical calculation. In this architecture, the LLM functions as an intelligent interface, eliciting parameters from natural language and interpreting results while automatically calling rigorous algorithms to build the optimization engine.   To evaluate this interactive system against the ambiguity and inconsistency of real-world managerial dialogue, we introduce the Human Imitator, a fine-tuned \"digital twin\" of a boundedly rational manager that enables scalable, reproducible stress-testing. Our empirical analysis reveals that the hybrid agentic framework reduces total inventory costs by 32.1% relative to an interactive baseline using GPT-4o as an end-to-end solver. Moreover, we find that providing perfect ground-truth information alone is insufficient to improve GPT-4o's performance, confirming that the bottleneck is fundamentally computational rather than informational. Our results position LLMs not as replacements for operations research, but as natural-language interfaces that make rigorous, solver-based policies accessible to non-experts.",
      "url": "http://arxiv.org/abs/2601.00121",
      "author": "Yaqi Duan, Yichun Hu, Jiashuo Jiang",
      "published": "2026-01-05",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Shows LLMs incur 'hallucination tax' when used as direct optimization solvers due to inability for grounded stochastic reasoning. Proposes hybrid framework decoupling semantic reasoning from mathematical calculation for inventory management.",
      "importance_score": 64,
      "reasoning": "Important finding about LLM limitations in optimization with practical solution. Relevant to growing interest in LLM agents for business applications.",
      "themes": [
        "Language Models",
        "LLM Agents",
        "Operations Research",
        "Hallucination"
      ],
      "continuation": null
    },
    {
      "id": "91cc440ad84d",
      "title": "Can Large Language Models Still Explain Themselves? Investigating the Impact of Quantization on Self-Explanations",
      "content": "Quantization is widely used to accelerate inference and streamline the deployment of large language models (LLMs), yet its effects on self-explanations (SEs) remain unexplored. SEs, generated by LLMs to justify their own outputs, require reasoning about the model's own decision-making process, a capability that may exhibit particular sensitivity to quantization. As SEs are increasingly relied upon for transparency in high-stakes applications, understanding whether and to what extent quantization degrades SE quality and faithfulness is critical. To address this gap, we examine two types of SEs: natural language explanations (NLEs) and counterfactual examples, generated by LLMs quantized using three common techniques at distinct bit widths. Our findings indicate that quantization typically leads to moderate declines in both SE quality (up to 4.4\\%) and faithfulness (up to 2.38\\%). The user study further demonstrates that quantization diminishes both the coherence and trustworthiness of SEs (up to 8.5\\%). Compared to smaller models, larger models show limited resilience to quantization in terms of SE quality but better maintain faithfulness. Moreover, no quantization technique consistently excels across task accuracy, SE quality, and faithfulness. Given that quantization's impact varies by context, we recommend validating SE quality for specific use cases, especially for NLEs, which show greater sensitivity. Nonetheless, the relatively minor deterioration in SE quality and faithfulness does not undermine quantization's effectiveness as a model compression technique.",
      "url": "http://arxiv.org/abs/2601.00282",
      "author": "Qianli Wang, Nils Feldhus, Pepa Atanasova, Fedor Splitt, Simon Ostermann, Sebastian M\\\"oller, Vera Schmitt",
      "published": "2026-01-05",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Investigates how quantization affects LLM self-explanations (natural language explanations and counterfactuals). Finds quantization typically lowers explanation quality but effects are task-dependent.",
      "importance_score": 64,
      "reasoning": "Important study on understudied interaction between quantization and explainability, relevant for deploying interpretable LLMs.",
      "themes": [
        "Quantization",
        "Explainability",
        "LLM Deployment"
      ],
      "continuation": null
    },
    {
      "id": "93e27388dc6a",
      "title": "E-GRPO: High Entropy Steps Drive Effective Reinforcement Learning for Flow Models",
      "content": "Recent reinforcement learning has enhanced the flow matching models on human preference alignment. While stochastic sampling enables the exploration of denoising directions, existing methods which optimize over multiple denoising steps suffer from sparse and ambiguous reward signals. We observe that the high entropy steps enable more efficient and effective exploration while the low entropy steps result in undistinguished roll-outs. To this end, we propose E-GRPO, an entropy aware Group Relative Policy Optimization to increase the entropy of SDE sampling steps. Since the integration of stochastic differential equations suffer from ambiguous reward signals due to stochasticity from multiple steps, we specifically merge consecutive low entropy steps to formulate one high entropy step for SDE sampling, while applying ODE sampling on other steps. Building upon this, we introduce multi-step group normalized advantage, which computes group-relative advantages within samples sharing the same consolidated SDE denoising step. Experimental results on different reward settings have demonstrated the effectiveness of our methods.",
      "url": "http://arxiv.org/abs/2601.00423",
      "author": "Shengjun Zhang, Zhang Zhang, Chensheng Dai, Yueqi Duan",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes E-GRPO, entropy-aware Group Relative Policy Optimization for flow matching models that increases entropy of SDE sampling steps and merges low-entropy steps for clearer reward signals.",
      "importance_score": 64,
      "reasoning": "Novel RL approach for flow models addressing reward signal ambiguity. Principled solution to practical training challenge.",
      "themes": [
        "Reinforcement Learning",
        "Flow Matching",
        "Diffusion Models"
      ],
      "continuation": null
    },
    {
      "id": "11cc173dfabb",
      "title": "Robust Uncertainty Quantification for Factual Generation of Large Language Models",
      "content": "The rapid advancement of large language model(LLM) technology has facilitated its integration into various domains of professional and daily life. However, the persistent challenge of LLM hallucination has emerged as a critical limitation, significantly compromising the reliability and trustworthiness of AI-generated content. This challenge has garnered significant attention within the scientific community, prompting extensive research efforts in hallucination detection and mitigation strategies. Current methodological frameworks reveal a critical limitation: traditional uncertainty quantification approaches demonstrate effectiveness primarily within conventional question-answering paradigms, yet exhibit notable deficiencies when confronted with non-canonical or adversarial questioning strategies. This performance gap raises substantial concerns regarding the dependability of LLM responses in real-world applications requiring robust critical thinking capabilities. This study aims to fill this gap by proposing an uncertainty quantification scenario in the task of generating with multiple facts. We have meticulously constructed a set of trap questions contained with fake names. Based on this scenario, we innovatively propose a novel and robust uncertainty quantification method(RU). A series of experiments have been conducted to verify its effectiveness. The results show that the constructed set of trap questions performs excellently. Moreover, when compared with the baseline methods on four different models, our proposed method has demonstrated great performance, with an average increase of 0.1-0.2 in ROCAUC values compared to the best performing baseline method, providing new sights and methods for addressing the hallucination issue of LLMs.",
      "url": "http://arxiv.org/abs/2601.00348",
      "author": "Yuhao Zhang, Zhongliang Yang and Linna Zhou",
      "published": "2026-01-05",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes robust uncertainty quantification framework for LLM factual generation that works under adversarial questioning strategies where traditional UQ methods fail.",
      "importance_score": 63,
      "reasoning": "Addresses important limitation of existing UQ methods under adversarial conditions. Relevant for reliable AI deployment.",
      "themes": [
        "Uncertainty Quantification",
        "Hallucination Detection",
        "LLM Reliability"
      ],
      "continuation": null
    },
    {
      "id": "c7a98502b69f",
      "title": "A Comprehensive Dataset for Human vs. AI Generated Image Detection",
      "content": "Multimodal generative AI systems like Stable Diffusion, DALL-E, and MidJourney have fundamentally changed how synthetic images are created. These tools drive innovation but also enable the spread of misleading content, false information, and manipulated media. As generated images become harder to distinguish from photographs, detecting them has become an urgent priority. To combat this challenge, We release MS COCOAI, a novel dataset for AI generated image detection consisting of 96000 real and synthetic datapoints, built using the MS COCO dataset. To generate synthetic images, we use five generators: Stable Diffusion 3, Stable Diffusion 2.1, SDXL, DALL-E 3, and MidJourney v6. Based on the dataset, we propose two tasks: (1) classifying images as real or generated, and (2) identifying which model produced a given synthetic image. The dataset is available at https://huggingface.co/datasets/Rajarshi-Roy-research/Defactify_Image_Dataset.",
      "url": "http://arxiv.org/abs/2601.00553",
      "author": "Rajarshi Roy, Nasrin Imanpour, Ashhar Aziz, Shashwat Bajpai, Gurpreet Singh, Shwetangshu Biswas, Kapil Wanaskar, Parth Patwa, Subhankar Ghosh, Shreyas Dixit, Nilesh Ranjan Pal, Vipula Rawte, Ritvik Garimella, Gaytri Jena, Vasu Sharma, Vinija Jain, Aman Chadha, Aishwarya Naresh Reganti and Amitava Das",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Releases MS COCOAI dataset with 96K real and synthetic images from 5 generators (SD3, SD2.1, SDXL, DALL-E 3, MidJourney v6) for AI-generated image detection and generator identification tasks.",
      "importance_score": 63,
      "reasoning": "Important dataset contribution for pressing AI content detection problem. Comprehensive coverage of major generators. Enables standardized benchmarking.",
      "themes": [
        "AI Detection",
        "Dataset",
        "Generative AI",
        "Computer Vision"
      ],
      "continuation": null
    },
    {
      "id": "b725e0d2949b",
      "title": "Reasoning in Action: MCTS-Driven Knowledge Retrieval for Large Language Models",
      "content": "Large language models (LLMs) typically enhance their performance through either the retrieval of semantically similar information or the improvement of their reasoning capabilities. However, a significant challenge remains in effectively integrating both retrieval and reasoning strategies to optimize LLM performance. In this paper, we introduce a reasoning-aware knowledge retrieval method that enriches LLMs with information aligned to the logical structure of conversations, moving beyond surface-level semantic similarity. We follow a coarse-to-fine approach for knowledge retrieval. First, we identify a contextually relevant sub-region of the knowledge base, ensuring that all sentences within it are relevant to the context topic. Next, we refine our search within this sub-region to extract knowledge that is specifically relevant to the reasoning process. Throughout both phases, we employ the Monte Carlo Tree Search-inspired search method to effectively navigate through knowledge sentences using common keywords. Experiments on two multi-turn dialogue datasets demonstrate that our knowledge retrieval approach not only aligns more closely with the underlying reasoning in human conversations but also significantly enhances the diversity of the retrieved knowledge, resulting in more informative and creative responses.",
      "url": "http://arxiv.org/abs/2601.00003",
      "author": "Shuqi Liu, Bowei He, Chen Ma, Linqi Song",
      "published": "2026-01-05",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Introduces reasoning-aware knowledge retrieval using Monte Carlo Tree Search to enrich LLMs with information aligned to logical structure rather than surface-level semantic similarity. Uses coarse-to-fine retrieval approach within relevant knowledge base sub-regions.",
      "importance_score": 62,
      "reasoning": "Novel integration of MCTS with retrieval for LLM reasoning. Addresses important limitation of semantic-only retrieval with principled approach.",
      "themes": [
        "Language Models",
        "Retrieval-Augmented Generation",
        "Reasoning",
        "Knowledge Retrieval"
      ],
      "continuation": null
    },
    {
      "id": "09ccd3c3519a",
      "title": "Online Finetuning Decision Transformers with Pure RL Gradients",
      "content": "Decision Transformers (DTs) have emerged as a powerful framework for sequential decision making by formulating offline reinforcement learning (RL) as a sequence modeling problem. However, extending DTs to online settings with pure RL gradients remains largely unexplored, as existing approaches continue to rely heavily on supervised sequence-modeling objectives during online finetuning. We identify hindsight return relabeling -- a standard component in online DTs -- as a critical obstacle to RL-based finetuning: while beneficial for supervised learning, it is fundamentally incompatible with importance sampling-based RL algorithms such as GRPO, leading to unstable training. Building on this insight, we propose new algorithms that enable online finetuning of Decision Transformers using pure reinforcement learning gradients. We adapt GRPO to DTs and introduce several key modifications, including sub-trajectory optimization for improved credit assignment, sequence-level likelihood objectives for enhanced stability and efficiency, and active sampling to encourage exploration in uncertain regions. Through extensive experiments, we demonstrate that our methods outperform existing online DT baselines and achieve new state-of-the-art performance across multiple benchmarks, highlighting the effectiveness of pure-RL-based online finetuning for Decision Transformers.",
      "url": "http://arxiv.org/abs/2601.00167",
      "author": "Junkai Luo, Yinglun Zhu",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Identifies hindsight return relabeling as obstacle to pure RL gradient finetuning for Decision Transformers. Proposes algorithms enabling online DT finetuning with GRPO-style importance sampling.",
      "importance_score": 62,
      "reasoning": "Important insight for Decision Transformer research. Addresses fundamental incompatibility with clear solution. Relevant to growing DT/RL intersection.",
      "themes": [
        "Decision Transformers",
        "Reinforcement Learning",
        "Online Learning",
        "Sequence Modeling"
      ],
      "continuation": null
    },
    {
      "id": "6c7c063cf659",
      "title": "FaithSCAN: Model-Driven Single-Pass Hallucination Detection for Faithful Visual Question Answering",
      "content": "Faithfulness hallucinations in VQA occur when vision-language models produce fluent yet visually ungrounded answers, severely undermining their reliability in safety-critical applications. Existing detection methods mainly fall into two categories: external verification approaches relying on auxiliary models or knowledge bases, and uncertainty-driven approaches using repeated sampling or uncertainty estimates. The former suffer from high computational overhead and are limited by external resource quality, while the latter capture only limited facets of model uncertainty and fail to sufficiently explore the rich internal signals associated with the diverse failure modes. Both paradigms thus have inherent limitations in efficiency, robustness, and detection performance. To address these challenges, we propose FaithSCAN: a lightweight network that detects hallucinations by exploiting rich internal signals of VLMs, including token-level decoding uncertainty, intermediate visual representations, and cross-modal alignment features. These signals are fused via branch-wise evidence encoding and uncertainty-aware attention. We also extend the LLM-as-a-Judge paradigm to VQA hallucination and propose a low-cost strategy to automatically generate model-dependent supervision signals, enabling supervised training without costly human labels while maintaining high detection accuracy. Experiments on multiple VQA benchmarks show that FaithSCAN significantly outperforms existing methods in both effectiveness and efficiency. In-depth analysis shows hallucinations arise from systematic internal state variations in visual perception, cross-modal reasoning, and language decoding. Different internal signals provide complementary diagnostic cues, and hallucination patterns vary across VLM architectures, offering new insights into the underlying causes of multimodal hallucinations.",
      "url": "http://arxiv.org/abs/2601.00269",
      "author": "Chaodong Tong, Qi Zhang, Chen Li, Lei Jiang, Yanbing Liu",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes FaithSCAN for single-pass hallucination detection in VQA by extracting internal model signals during generation, avoiding external verification or repeated sampling overhead.",
      "importance_score": 62,
      "reasoning": "Efficient approach to important reliability problem. Single-pass design is practically valuable for deployment.",
      "themes": [
        "Hallucination Detection",
        "Vision-Language Models",
        "AI Safety"
      ],
      "continuation": null
    },
    {
      "id": "454a687505bc",
      "title": "MAESTRO: Multi-Agent Evaluation Suite for Testing, Reliability, and Observability",
      "content": "We present MAESTRO, an evaluation suite for the testing, reliability, and observability of LLM-based MAS. MAESTRO standardizes MAS configuration and execution through a unified interface, supports integrating both native and third-party MAS via a repository of examples and lightweight adapters, and exports framework-agnostic execution traces together with system-level signals (e.g., latency, cost, and failures). We instantiate MAESTRO with 12 representative MAS spanning popular agentic frameworks and interaction patterns, and conduct controlled experiments across repeated runs, backend models, and tool configurations. Our case studies show that MAS executions can be structurally stable yet temporally variable, leading to substantial run-to-run variance in performance and reliability. We further find that MAS architecture is the dominant driver of resource profiles, reproducibility, and cost-latency-accuracy trade-off, often outweighing changes in backend models or tool settings. Overall, MAESTRO enables systematic evaluation and provides empirical guidance for designing and optimizing agentic systems.",
      "url": "http://arxiv.org/abs/2601.00481",
      "author": "Tie Ma, Yixi Chen, Vaastav Anand, Alessandro Cornacchia, Am\\^andio R. Faustino, Guanheng Liu, Shan Zhang, Hongbin Luo, Suhaib A. Fahmy, Zafar A. Qazi, Marco Canini",
      "published": "2026-01-05",
      "source": "arXiv (cs.NI)",
      "source_type": "arxiv",
      "tags": [
        "cs.NI"
      ],
      "summary": "Introduces MAESTRO, an evaluation suite for LLM-based multi-agent systems providing standardized configuration, execution traces, and system-level signals. Studies 12 MAS across frameworks showing high run-to-run variance.",
      "importance_score": 62,
      "reasoning": "Important infrastructure contribution for emerging multi-agent LLM field. Standardized evaluation enables reproducible research. Finding of structural stability with temporal variance is valuable.",
      "themes": [
        "Multi-Agent Systems",
        "Evaluation",
        "Language Models",
        "Benchmarks"
      ],
      "continuation": null
    },
    {
      "id": "f685b2189c2d",
      "title": "CRoPS: A Training-Free Hallucination Mitigation Framework for Vision-Language Models",
      "content": "Despite the rapid success of Large Vision-Language Models (LVLMs), a persistent challenge is their tendency to generate hallucinated content, undermining reliability in real-world use. Existing training-free methods address hallucinations but face two limitations: (i) they rely on narrow assumptions about hallucination sources, and (ii) their effectiveness declines toward the end of generation, where hallucinations are most likely to occur. A common strategy is to build hallucinated models by completely or partially removing visual tokens and contrasting them with the original model. Yet, this alone proves insufficient, since visual information still propagates into generated text. Building on this insight, we propose a novel hallucinated model that captures hallucination effects by selectively removing key text tokens. We further introduce Generalized Contrastive Decoding, which integrates multiple hallucinated models to represent diverse hallucination sources. Together, these ideas form CRoPS, a training-free hallucination mitigation framework that improves CHAIR scores by 20% and achieves consistent gains across six benchmarks and three LVLM families, outperforming state-of-the-art training-free methods.",
      "url": "http://arxiv.org/abs/2601.00659",
      "author": "Neeraj Anand, Samyak Jha, Udbhav Bamba, Rahul Rahaman",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes CRoPS, a training-free method to reduce hallucinations in large vision-language models by creating 'hallucinated models' that capture hallucination effects for contrastive decoding. Addresses limitations of existing methods that struggle with hallucinations occurring late in generation.",
      "importance_score": 62,
      "reasoning": "Addresses an important practical problem in VLMs with a novel training-free approach. The insight about visual information propagating into text even after visual token removal is valuable. Limited by being truncated - full method details unavailable.",
      "themes": [
        "Vision-Language Models",
        "Hallucination Mitigation",
        "Inference Methods"
      ],
      "continuation": null
    },
    {
      "id": "3c12a99f936f",
      "title": "Can Optimal Transport Improve Federated Inverse Reinforcement Learning?",
      "content": "In robotics and multi-agent systems, fleets of autonomous agents often operate in subtly different environments while pursuing a common high-level objective. Directly pooling their data to learn a shared reward function is typically impractical due to differences in dynamics, privacy constraints, and limited communication bandwidth. This paper introduces an optimal transport-based approach to federated inverse reinforcement learning (IRL). Each client first performs lightweight Maximum Entropy IRL locally, adhering to its computational and privacy limitations. The resulting reward functions are then fused via a Wasserstein barycenter, which considers their underlying geometric structure. We further prove that this barycentric fusion yields a more faithful global reward estimate than conventional parameter averaging methods in federated learning. Overall, this work provides a principled and communication-efficient framework for deriving a shared reward that generalizes across heterogeneous agents and environments.",
      "url": "http://arxiv.org/abs/2601.00309",
      "author": "David Millard and Ali Baheri",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes optimal transport-based federated inverse reinforcement learning using Wasserstein barycenter to fuse locally learned reward functions across heterogeneous agents.",
      "importance_score": 61,
      "reasoning": "Novel combination of optimal transport with federated IRL. Addresses practical multi-agent learning scenario with privacy constraints.",
      "themes": [
        "Federated Learning",
        "Inverse Reinforcement Learning",
        "Optimal Transport"
      ],
      "continuation": null
    },
    {
      "id": "64f9c24c0565",
      "title": "RMAAT: Astrocyte-Inspired Memory Compression and Replay for Efficient Long-Context Transformers",
      "content": "The quadratic complexity of self-attention mechanism presents a significant impediment to applying Transformer models to long sequences. This work explores computational principles derived from astrocytes-glial cells critical for biological memory and synaptic modulation-as a complementary approach to conventional architectural modifications for efficient self-attention. We introduce the Recurrent Memory Augmented Astromorphic Transformer (RMAAT), an architecture integrating abstracted astrocyte functionalities. RMAAT employs a recurrent, segment-based processing strategy where persistent memory tokens propagate contextual information. An adaptive compression mechanism, governed by a novel retention factor derived from simulated astrocyte long-term plasticity (LTP), modulates these tokens. Attention within segments utilizes an efficient, linear-complexity mechanism inspired by astrocyte short-term plasticity (STP). Training is performed using Astrocytic Memory Replay Backpropagation (AMRB), a novel algorithm designed for memory efficiency in recurrent networks. Evaluations on the Long Range Arena (LRA) benchmark demonstrate RMAAT's competitive accuracy and substantial improvements in computational and memory efficiency, indicating the potential of incorporating astrocyte-inspired dynamics into scalable sequence models.",
      "url": "http://arxiv.org/abs/2601.00426",
      "author": "Md Zesun Ahmed Mia, Malyaban Bal, Abhronil Sengupta",
      "published": "2026-01-05",
      "source": "arXiv (Neural and Evolutionary Computing)",
      "source_type": "arxiv",
      "tags": [
        "cs.NE"
      ],
      "summary": "Introduces RMAAT, astrocyte-inspired transformer with recurrent memory tokens and adaptive compression governed by simulated long-term plasticity for efficient long-context processing.",
      "importance_score": 61,
      "reasoning": "Novel bio-inspired approach to transformer efficiency. Creative application of astrocyte principles.",
      "themes": [
        "Efficient Transformers",
        "Bio-Inspired Computing",
        "Long Context"
      ],
      "continuation": null
    },
    {
      "id": "35838dde9cca",
      "title": "DA-DPO: Cost-efficient Difficulty-aware Preference Optimization for Reducing MLLM Hallucinations",
      "content": "Direct Preference Optimization (DPO) has shown strong potential for mitigating hallucinations in Multimodal Large Language Models (MLLMs). However, existing multimodal DPO approaches often suffer from overfitting due to the difficulty imbalance in preference data. Our analysis shows that MLLMs tend to overemphasize easily distinguishable preference pairs, which hinders fine-grained hallucination suppression and degrades overall performance. To address this issue, we propose Difficulty-Aware Direct Preference Optimization (DA-DPO), a cost-effective framework designed to balance the learning process. DA-DPO consists of two main components: (1) Difficulty Estimation leverages pre-trained vision--language models with complementary generative and contrastive objectives, whose outputs are integrated via a distribution-aware voting strategy to produce robust difficulty scores without additional training; and (2) Difficulty-Aware Training reweights preference pairs based on their estimated difficulty, down-weighting easy samples while emphasizing harder ones to alleviate overfitting. This framework enables more effective preference optimization by prioritizing challenging examples, without requiring new data or extra fine-tuning stages. Extensive experiments demonstrate that DA-DPO consistently improves multimodal preference optimization, yielding stronger robustness to hallucinations and better generalization across standard benchmarks, while remaining computationally efficient. The project page is available at https://artanic30.github.io/project_pages/DA-DPO/.",
      "url": "http://arxiv.org/abs/2601.00623",
      "author": "Longtian Qiu, Shan Ning, Chuyu Zhang, Jiaxuan Sun, Xuming He",
      "published": "2026-01-05",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Proposes DA-DPO for reducing MLLM hallucinations by addressing difficulty imbalance in preference data through difficulty estimation using VLMs and uncertainty-weighted optimization.",
      "importance_score": 61,
      "reasoning": "Important contribution to multimodal hallucination reduction. Novel difficulty-aware approach to DPO. Cost-efficient framework with practical value.",
      "themes": [
        "Multimodal Learning",
        "Hallucination Reduction",
        "Preference Optimization",
        "AI Safety"
      ],
      "continuation": null
    },
    {
      "id": "56dae13266f1",
      "title": "Dynamic Bayesian Optimization Framework for Instruction Tuning in Partial Differential Equation Discovery",
      "content": "Large Language Models (LLMs) show promise for equation discovery, yet their outputs are highly sensitive to prompt phrasing, a phenomenon we term instruction brittleness. Static prompts cannot adapt to the evolving state of a multi-step generation process, causing models to plateau at suboptimal solutions. To address this, we propose NeuroSymBO, which reframes prompt engineering as a sequential decision problem. Our method maintains a discrete library of reasoning strategies and uses Bayesian Optimization to select the optimal instruction at each step based on numerical feedback. Experiments on PDE discovery benchmarks show that adaptive instruction selection significantly outperforms fixed prompts, achieving higher recovery rates with more parsimonious solutions.",
      "url": "http://arxiv.org/abs/2601.00088",
      "author": "Junqi Qu, Yan Zhang, Shangqian Gao, Shibo Li",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes NeuroSymBO, using Bayesian Optimization to adaptively select LLM prompts for PDE discovery based on numerical feedback. Addresses instruction brittleness where static prompts fail to adapt to multi-step generation.",
      "importance_score": 60,
      "reasoning": "Novel approach to prompt optimization for scientific discovery. Addresses important limitation of LLMs with principled BO framework.",
      "themes": [
        "Language Models",
        "Scientific Discovery",
        "Bayesian Optimization",
        "Prompt Engineering"
      ],
      "continuation": null
    },
    {
      "id": "4b42aaa65af3",
      "title": "Compressed Map Priors for 3D Perception",
      "content": "Human drivers rarely travel where no person has gone before. After all, thousands of drivers use busy city roads every day, and only one can claim to be the first. The same holds for autonomous computer vision systems. The vast majority of the deployment area of an autonomous vision system will have been visited before. Yet, most autonomous vehicle vision systems act as if they are encountering each location for the first time. In this work, we present Compressed Map Priors (CMP), a simple but effective framework to learn spatial priors from historic traversals. The map priors use a binarized hashmap that requires only $32\\text{KB}/\\text{km}^2$, a $20\\times$ reduction compared to the dense storage. Compressed Map Priors easily integrate into leading 3D perception systems at little to no extra computational costs, and lead to a significant and consistent improvement in 3D object detection on the nuScenes dataset across several architectures.",
      "url": "http://arxiv.org/abs/2601.00139",
      "author": "Brady Zhou, Philipp Kr\\\"ahenb\\\"uhl",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Presents Compressed Map Priors (CMP), learning spatial priors from historic traversals using binarized hashmaps requiring only 32KB/km². Integrates into 3D perception systems for autonomous driving at minimal overhead.",
      "importance_score": 60,
      "reasoning": "Practical contribution for autonomous driving perception. Efficient memory usage with meaningful improvements over single-traversal approaches.",
      "themes": [
        "Autonomous Driving",
        "3D Perception",
        "Spatial Priors",
        "Efficient Computing"
      ],
      "continuation": null
    },
    {
      "id": "dc96acf9625a",
      "title": "Robust Graph Fine-Tuning with Adversarial Graph Prompting",
      "content": "Parameter-Efficient Fine-Tuning (PEFT) method has emerged as a dominant paradigm for adapting pre-trained GNN models to downstream tasks. However, existing PEFT methods usually exhibit significant vulnerability to various noise and attacks on graph topology and node attributes/features. To address this issue, for the first time, we propose integrating adversarial learning into graph prompting and develop a novel Adversarial Graph Prompting (AGP) framework to achieve robust graph fine-tuning. Our AGP has two key aspects. First, we propose the general problem formulation of AGP as a min-max optimization problem and develop an alternating optimization scheme to solve it. For inner maximization, we propose Joint Projected Gradient Descent (JointPGD) algorithm to generate strong adversarial noise. For outer minimization, we employ a simple yet effective module to learn the optimal node prompts to counteract the adversarial noise. Second, we demonstrate that the proposed AGP can theoretically address both graph topology and node noise. This confirms the versatility and robustness of our AGP fine-tuning method across various graph noise. Note that, the proposed AGP is a general method that can be integrated with various pre-trained GNN models to enhance their robustness on the downstream tasks. Extensive experiments on multiple benchmark tasks validate the robustness and effectiveness of AGP method compared to state-of-the-art methods.",
      "url": "http://arxiv.org/abs/2601.00229",
      "author": "Ziyan Zhang, Bo Jiang, Jin Tang",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "First work integrating adversarial learning into graph prompting for robust fine-tuning. Proposes Adversarial Graph Prompting (AGP) with min-max optimization and JointPGD algorithm for generating adversarial perturbations.",
      "importance_score": 60,
      "reasoning": "Novel combination of adversarial training with graph prompting paradigm. First in this direction, though limited to graph domain.",
      "themes": [
        "Graph Neural Networks",
        "Adversarial Robustness",
        "Parameter-Efficient Fine-Tuning"
      ],
      "continuation": null
    },
    {
      "id": "7264e3f0d185",
      "title": "Joint Geometry-Appearance Human Reconstruction in a Unified Latent Space via Bridge Diffusion",
      "content": "Achieving consistent and high-fidelity geometry and appearance reconstruction of 3D digital humans from a single RGB image is inherently a challenging task. Existing studies typically resort to decoupled pipelines for geometry estimation and appearance synthesis, often hindering unified reconstruction and causing inconsistencies. This paper introduces \\textbf{JGA-LBD}, a novel framework that unifies the modeling of geometry and appearance into a joint latent representation and formulates the generation process as bridge diffusion. Observing that directly integrating heterogeneous input conditions (e.g., depth maps, SMPL models) leads to substantial training difficulties, we unify all conditions into the 3D Gaussian representations, which can be further compressed into a unified latent space through a shared sparse variational autoencoder (VAE). Subsequently, the specialized form of bridge diffusion enables to start with a partial observation of the target latent code and solely focuses on inferring the missing components. Finally, a dedicated decoding module extracts the complete 3D human geometric structure and renders novel views from the inferred latent representation. Experiments demonstrate that JGA-LBD outperforms current state-of-the-art approaches in terms of both geometry fidelity and appearance quality, including challenging in-the-wild scenarios. Our code will be made publicly available at https://github.com/haiantyz/JGA-LBD.",
      "url": "http://arxiv.org/abs/2601.00328",
      "author": "Yingzhi Tang, Qijian Zhang, and Junhui Hou",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Introduces JGA-LBD for unified geometry and appearance 3D human reconstruction using joint latent representation and bridge diffusion, unifying heterogeneous inputs via 3D Gaussian representations.",
      "importance_score": 60,
      "reasoning": "Novel unified approach to typically decoupled problem. Bridge diffusion formulation is interesting.",
      "themes": [
        "3D Human Reconstruction",
        "Diffusion Models",
        "Gaussian Splatting"
      ],
      "continuation": null
    },
    {
      "id": "601cf1e6086a",
      "title": "Adaptive Causal Coordination Detection for Social Media: A Memory-Guided Framework with Semi-Supervised Learning",
      "content": "Detecting coordinated inauthentic behavior on social media remains a critical and persistent challenge, as most existing approaches rely on superficial correlation analysis, employ static parameter settings, and demand extensive and labor-intensive manual annotation. To address these limitations systematically, we propose the Adaptive Causal Coordination Detection (ACCD) framework. ACCD adopts a three-stage, progressive architecture that leverages a memory-guided adaptive mechanism to dynamically learn and retain optimal detection configurations for diverse coordination scenarios. Specifically, in the first stage, ACCD introduces an adaptive Convergent Cross Mapping (CCM) technique to deeply identify genuine causal relationships between accounts. The second stage integrates active learning with uncertainty sampling within a semi-supervised classification scheme, significantly reducing the burden of manual labeling. The third stage deploys an automated validation module driven by historical detection experience, enabling self-verification and optimization of the detection outcomes. We conduct a comprehensive evaluation using real-world datasets, including the Twitter IRA dataset, Reddit coordination traces, and several widely-adopted bot detection benchmarks. Experimental results demonstrate that ACCD achieves an F1-score of 87.3\\% in coordinated attack detection, representing a 15.2\\% improvement over the strongest existing baseline. Furthermore, the system reduces manual annotation requirements by 68\\% and achieves a 2.8x speedup in processing through hierarchical clustering optimization. In summary, ACCD provides a more accurate, efficient, and highly automated end-to-end solution for identifying coordinated behavior on social platforms, offering substantial practical value and promising potential for broad application.",
      "url": "http://arxiv.org/abs/2601.00400",
      "author": "Weng Ding, Yi Han, Mu-Jiang-Shan Wang",
      "published": "2026-01-05",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Proposes ACCD framework for detecting coordinated inauthentic behavior on social media using adaptive Convergent Cross Mapping for causal relationships and active learning for label efficiency.",
      "importance_score": 60,
      "reasoning": "Addresses important problem of coordinated manipulation with principled causal approach.",
      "themes": [
        "Misinformation Detection",
        "Social Media",
        "Causal Inference"
      ],
      "continuation": null
    },
    {
      "id": "10d35871e845",
      "title": "CPPO: Contrastive Perception for Vision Language Policy Optimization",
      "content": "We introduce CPPO, a Contrastive Perception Policy Optimization method for finetuning vision-language models (VLMs). While reinforcement learning (RL) has advanced reasoning in language models, extending it to multimodal reasoning requires improving both the perception and reasoning aspects. Prior works tackle this challenge mainly with explicit perception rewards, but disentangling perception tokens from reasoning tokens is difficult, requiring extra LLMs, ground-truth data, forced separation of perception from reasoning by policy model, or applying rewards indiscriminately to all output tokens. CPPO addresses this problem by detecting perception tokens via entropy shifts in the model outputs under perturbed input images. CPPO then extends the RL objective function with a Contrastive Perception Loss (CPL) that enforces consistency under information-preserving perturbations and sensitivity under information-removing ones. Experiments show that CPPO surpasses previous perception-rewarding methods, while avoiding extra models, making training more efficient and scalable.",
      "url": "http://arxiv.org/abs/2601.00501",
      "author": "Ahmad Rezaei and Mohsen Gholami and Saeed Ranjbar Alvar and Kevin Cannons and Mohammad Asiful Hossain and Zhou Weimin and Shunbo Zhou and Yong Zhang and Mohammad Akbari",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Introduces CPPO for finetuning VLMs using RL, detecting perception tokens via entropy shifts under image perturbations and extending the RL objective with contrastive perception loss.",
      "importance_score": 60,
      "reasoning": "Novel approach to improving perception in VLM RL training. Addresses important challenge of disentangling perception from reasoning tokens. Solid methodology.",
      "themes": [
        "Vision-Language Models",
        "Reinforcement Learning",
        "Multimodal Learning"
      ],
      "continuation": null
    },
    {
      "id": "b7e6df24c56c",
      "title": "Disentangling Hardness from Noise: An Uncertainty-Driven Model-Agnostic Framework for Long-Tailed Remote Sensing Classification",
      "content": "Long-Tailed distributions are pervasive in remote sensing due to the inherently imbalanced occurrence of grounded objects. However, a critical challenge remains largely overlooked, i.e., disentangling hard tail data samples from noisy ambiguous ones. Conventional methods often indiscriminately emphasize all low-confidence samples, leading to overfitting on noisy data. To bridge this gap, building upon Evidential Deep Learning, we propose a model-agnostic uncertainty-aware framework termed DUAL, which dynamically disentangles prediction uncertainty into Epistemic Uncertainty (EU) and Aleatoric Uncertainty (AU). Specifically, we introduce EU as an indicator of sample scarcity to guide a reweighting strategy for hard-to-learn tail samples, while leveraging AU to quantify data ambiguity, employing an adaptive label smoothing mechanism to suppress the impact of noise. Extensive experiments on multiple datasets across various backbones demonstrate the effectiveness and generalization of our framework, surpassing strong baselines such as TGN and SADE. Ablation studies provide further insights into the crucial choices of our design.",
      "url": "http://arxiv.org/abs/2601.00278",
      "author": "Chi Ding, Junxiao Xue, Xinyi Yin, Shi Chen, Yunyun Shi, Yiduo Wang, Fengjian Xue, Xuecheng Wu",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes DUAL framework using Evidential Deep Learning to disentangle epistemic and aleatoric uncertainty for handling long-tailed distributions in remote sensing, distinguishing hard samples from noisy ones.",
      "importance_score": 59,
      "reasoning": "Principled approach to important problem of uncertainty disentanglement for imbalanced data. Good application of EDL.",
      "themes": [
        "Uncertainty Quantification",
        "Long-Tail Learning",
        "Remote Sensing"
      ],
      "continuation": null
    },
    {
      "id": "ba890f379518",
      "title": "Physio-DPO: Aligning Large Language Models with the Protein Energy Landscape to Eliminate Structural Hallucinations",
      "content": "Large Protein Language Models have shown strong potential for generative protein design, yet they frequently produce structural hallucinations, generating sequences with high linguistic likelihood that fold into thermodynamically unstable conformations. Existing alignment approaches such as Direct Preference Optimization are limited in this setting, as they model preferences as binary labels and ignore the continuous structure of the physical energy landscape. We propose Physio-DPO, a physics informed alignment framework that grounds protein language models in thermodynamic stability. Physio-DPO introduces a magnitude aware objective that scales optimization updates according to the energy gap between native structures and physics perturbed hard negatives. Experiments show that Physio-DPO consistently outperforms strong baselines including SFT, PPO, and standard DPO, reducing self consistency RMSD to 1.28 \\AA\\ and increasing foldability to 92.8%. Qualitative analysis further demonstrates that Physio-DPO effectively mitigates structural hallucinations by recovering biophysical interactions such as hydrophobic core packing and hydrogen bond networks.",
      "url": "http://arxiv.org/abs/2601.00647",
      "author": "QiWei Meng",
      "published": "2026-01-05",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes Physio-DPO, physics-informed alignment for protein language models using magnitude-aware objective scaling updates by energy gap between native and perturbed structures to eliminate structural hallucinations.",
      "importance_score": 59,
      "reasoning": "Novel integration of physics constraints into protein LM alignment. Addresses important structural hallucination problem. Creative cross-domain application.",
      "themes": [
        "Protein Language Models",
        "AI Alignment",
        "Physics-Informed ML",
        "Structural Biology"
      ],
      "continuation": null
    },
    {
      "id": "f7c98d73224a",
      "title": "Simple and Effective Input Reformulations for Translation",
      "content": "Foundation language models learn from their finetuning input context in different ways. In this paper, we reformulate inputs during finetuning for challenging translation tasks, leveraging model strengths from pretraining in novel ways to improve downstream performance. These reformulations are simple data level modifications, require no additional collection of training data or modification of data at inference time. They can be applied either on single language pair translation tasks or massively multilingual translation tasks. Experiments with these techniques demonstrate significant performance improvements up to $\\textbf{3.5 chrF++ on the Flores200 translation benchmark}$. We hope our research accessibly improves finetuning data efficiency, enabling more effective training to scalably improve state-of-the-art performance. Our code is released $\\href{https://github.com/bri25yu/LanguageModelExperimentation}{here}.$",
      "url": "http://arxiv.org/abs/2311.06696",
      "author": "Brian Yu and Hansen Lillemark and Kurt Keutzer",
      "published": "2026-01-05",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Demonstrates that simple input reformulations during finetuning can significantly improve translation performance, achieving up to 3.5 chrF++ gains on Flores200 benchmark. These are data-level modifications requiring no additional training data or inference-time changes.",
      "importance_score": 58,
      "reasoning": "Practical contribution showing meaningful improvements on established translation benchmark. Simple technique with good reproducibility, but limited novelty in methodology.",
      "themes": [
        "Language Models",
        "Machine Translation",
        "Natural Language Processing"
      ],
      "continuation": null
    },
    {
      "id": "843faee71229",
      "title": "Neural Brain Fields: A NeRF-Inspired Approach for Generating Nonexistent EEG Electrodes",
      "content": "Electroencephalography (EEG) data present unique modeling challenges because recordings vary in length, exhibit very low signal to noise ratios, differ significantly across participants, drift over time within sessions, and are rarely available in large and clean datasets. Consequently, developing deep learning methods that can effectively process EEG signals remains an open and important research problem. To tackle this problem, this work presents a new method inspired by Neural Radiance Fields (NeRF). In computer vision, NeRF techniques train a neural network to memorize the appearance of a 3D scene and then uses its learned parameters to render and edit the scene from any viewpoint. We draw an analogy between the discrete images captured from different viewpoints used to learn a continuous 3D scene in NeRF, and EEG electrodes positioned at different locations on the scalp, which are used to infer the underlying representation of continuous neural activity. Building on this connection, we show that a neural network can be trained on a single EEG sample in a NeRF style manner to produce a fixed size and informative weight vector that encodes the entire signal. Moreover, via this representation we can render the EEG signal at previously unseen time steps and spatial electrode positions. We demonstrate that this approach enables continuous visualization of brain activity at any desired resolution, including ultra high resolution, and reconstruction of raw EEG signals. Finally, our empirical analysis shows that this method can effectively simulate nonexistent electrodes data in EEG recordings, allowing the reconstructed signal to be fed into standard EEG processing networks to improve performance.",
      "url": "http://arxiv.org/abs/2601.00012",
      "author": "Shahar Ain Kedem, Itamar Zimerman, Eliya Nachmani",
      "published": "2026-01-05",
      "source": "arXiv (eess.SP)",
      "source_type": "arxiv",
      "tags": [
        "eess.SP"
      ],
      "summary": "Proposes Neural Brain Fields, a NeRF-inspired method for generating synthetic EEG electrodes from existing recordings. Draws analogy between multi-view images and multi-electrode EEG to learn continuous neural field representations.",
      "importance_score": 58,
      "reasoning": "Creative application of NeRF concepts to EEG synthesis. Novel approach addressing practical challenges in neuroscience data collection.",
      "themes": [
        "Neural Radiance Fields",
        "EEG Analysis",
        "Neural Signal Processing",
        "Data Augmentation"
      ],
      "continuation": null
    },
    {
      "id": "e623b0a620c6",
      "title": "Unknown Aware AI-Generated Content Attribution",
      "content": "The rapid advancement of photorealistic generative models has made it increasingly important to attribute the origin of synthetic content, moving beyond binary real or fake detection toward identifying the specific model that produced a given image. We study the problem of distinguishing outputs from a target generative model (e.g., OpenAI Dalle 3) from other sources, including real images and images generated by a wide range of alternative models. Using CLIP features and a simple linear classifier, shown to be effective in prior work, we establish a strong baseline for target generator attribution using only limited labeled data from the target model and a small number of known generators. However, this baseline struggles to generalize to harder, unseen, and newly released generators. To address this limitation, we propose a constrained optimization approach that leverages unlabeled wild data, consisting of images collected from the Internet that may include real images, outputs from unknown generators, or even samples from the target model itself. The proposed method encourages wild samples to be classified as non target while explicitly constraining performance on labeled data to remain high. Experimental results show that incorporating wild data substantially improves attribution performance on challenging unseen generators, demonstrating that unlabeled data from the wild can be effectively exploited to enhance AI generated content attribution in open world settings.",
      "url": "http://arxiv.org/abs/2601.00218",
      "author": "Ellie Thieu, Jifan Zhang, Haoyue Bai",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes methods to attribute AI-generated images to their source model (e.g., DALL-E 3) using CLIP features and linear classifiers, addressing the challenge of generalizing to unseen generators. This is important for content authenticity verification as generative models proliferate.",
      "importance_score": 58,
      "reasoning": "Practical problem addressing content authenticity, but uses existing techniques (CLIP) and shows limitations with unseen generators. Incremental contribution.",
      "themes": [
        "AI-Generated Content Detection",
        "Computer Vision",
        "AI Safety"
      ],
      "continuation": null
    },
    {
      "id": "2dcf43f9bc78",
      "title": "Parallel Universes, Parallel Languages: A Comprehensive Study on LLM-based Multilingual Counterfactual Example Generation",
      "content": "Counterfactuals refer to minimally edited inputs that cause a model's prediction to change, serving as a promising approach to explaining the model's behavior. Large language models (LLMs) excel at generating English counterfactuals and demonstrate multilingual proficiency. However, their effectiveness in generating multilingual counterfactuals remains unclear. To this end, we conduct a comprehensive study on multilingual counterfactuals. We first conduct automatic evaluations on both directly generated counterfactuals in the target languages and those derived via English translation across six languages. Although translation-based counterfactuals offer higher validity than their directly generated counterparts, they demand substantially more modifications and still fall short of matching the quality of the original English counterfactuals. Second, we find the patterns of edits applied to high-resource European-language counterfactuals to be remarkably similar, suggesting that cross-lingual perturbations follow common strategic principles. Third, we identify and categorize four main types of errors that consistently appear in the generated counterfactuals across languages. Finally, we reveal that multilingual counterfactual data augmentation (CDA) yields larger model performance improvements than cross-lingual CDA, especially for lower-resource languages. Yet, the imperfections of the generated counterfactuals limit gains in model performance and robustness.",
      "url": "http://arxiv.org/abs/2601.00263",
      "author": "Qianli Wang, Van Bach Nguyen, Yihong Liu, Fedor Splitt, Nils Feldhus, Christin Seifert, Hinrich Sch\\\"utze, Sebastian M\\\"oller, Vera Schmitt",
      "published": "2026-01-05",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Comprehensive study on LLM-generated multilingual counterfactual examples across six languages. Finds translation-based counterfactuals have higher validity but require more modifications.",
      "importance_score": 58,
      "reasoning": "Thorough study on understudied problem of multilingual counterfactual generation for model explainability.",
      "themes": [
        "Explainability",
        "Multilingual NLP",
        "Counterfactual Reasoning"
      ],
      "continuation": null
    },
    {
      "id": "fb7a4405a9b9",
      "title": "Multiagent Reinforcement Learning for Liquidity Games",
      "content": "Making use of swarm methods in financial market modeling of liquidity, and techniques from financial analysis in swarm analysis, holds the potential to advance both research areas. In swarm research, the use of game theory methods holds the promise of explaining observed phenomena of collective utility adherence with rational self-interested swarm participants. In financial markets, a better understanding of how independent financial agents may self-organize for the betterment and stability of the marketplace would be a boon for market design researchers. This paper unifies Liquidity Games, where trader payoffs depend on aggregate liquidity within a trade, with Rational Swarms, where decentralized agents use difference rewards to align self-interested learning with global objectives. We offer a theoretical frameworks where we define a swarm of traders whose collective objective is market liquidity provision while maintaining agent independence. Using difference rewards within a Markov team games framework, we show that individual liquidity-maximizing behaviors contribute to overall market liquidity without requiring coordination or collusion. This Financial Swarm model provides a framework for modeling rational, independent agents where they achieve both individual profitability and collective market efficiency in bilateral asset markets.",
      "url": "http://arxiv.org/abs/2601.00324",
      "author": "Alicia Vidler, Gal A. Kaminka",
      "published": "2026-01-05",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Unifies Liquidity Games with Rational Swarms for multi-agent RL in financial market modeling, using difference rewards to align self-interested learning with global market objectives.",
      "importance_score": 58,
      "reasoning": "Interesting interdisciplinary work connecting swarm intelligence with financial market modeling.",
      "themes": [
        "Multi-Agent RL",
        "Financial AI",
        "Swarm Intelligence"
      ],
      "continuation": null
    },
    {
      "id": "bbad687e229a",
      "title": "ABFR-KAN: Kolmogorov-Arnold Networks for Functional Brain Analysis",
      "content": "Functional connectivity (FC) analysis, a valuable tool for computer-aided brain disorder diagnosis, traditionally relies on atlas-based parcellation. However, issues relating to selection bias and a lack of regard for subject specificity can arise as a result of such parcellations. Addressing this, we propose ABFR-KAN, a transformer-based classification network that incorporates novel advanced brain function representation components with the power of Kolmogorov-Arnold Networks (KANs) to mitigate structural bias, improve anatomical conformity, and enhance the reliability of FC estimation. Extensive experiments on the ABIDE I dataset, including cross-site evaluation and ablation studies across varying model backbones and KAN configurations, demonstrate that ABFR-KAN consistently outperforms state-of-the-art baselines for autism spectrum distorder (ASD) classification. Our code is available at https://github.com/tbwa233/ABFR-KAN.",
      "url": "http://arxiv.org/abs/2601.00416",
      "author": "Tyler Ward, Abdullah Imran",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes ABFR-KAN using Kolmogorov-Arnold Networks with transformer-based architecture for functional brain connectivity analysis, reducing atlas-based parcellation biases.",
      "importance_score": 58,
      "reasoning": "Novel application of KANs to neuroscience/medical imaging. Interesting architectural choice.",
      "themes": [
        "Medical AI",
        "Kolmogorov-Arnold Networks",
        "Brain Imaging"
      ],
      "continuation": null
    },
    {
      "id": "7796043a3f75",
      "title": "Controllable Concept Bottleneck Models",
      "content": "Concept Bottleneck Models (CBMs) have garnered much attention for their ability to elucidate the prediction process through a human-understandable concept layer. However, most previous studies focused on static scenarios where the data and concepts are assumed to be fixed and clean. In real-world applications, deployed models require continuous maintenance: we often need to remove erroneous or sensitive data (unlearning), correct mislabeled concepts, or incorporate newly acquired samples (incremental learning) to adapt to evolving environments. Thus, deriving efficient editable CBMs without retraining from scratch remains a significant challenge, particularly in large-scale applications. To address these challenges, we propose Controllable Concept Bottleneck Models (CCBMs). Specifically, CCBMs support three granularities of model editing: concept-label-level, concept-level, and data-level, the latter of which encompasses both data removal and data addition. CCBMs enjoy mathematically rigorous closed-form approximations derived from influence functions that obviate the need for retraining. Experimental results demonstrate the efficiency and adaptability of our CCBMs, affirming their practical value in enabling dynamic and trustworthy CBMs.",
      "url": "http://arxiv.org/abs/2601.00451",
      "author": "Hongbin Lin, Chenyang Ren, Juangui Xu, Zhengyu Hu, Cheng-Long Wang, Yao Shu, Hui Xiong, Jingfeng Zhang, Di Wang, Lijie Hu",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes Controllable Concept Bottleneck Models that support unlearning, concept correction, and incremental learning without retraining from scratch. Addresses real-world deployment challenges where data and concepts evolve.",
      "importance_score": 58,
      "reasoning": "Addresses practical gap in interpretable AI systems. Multiple manipulation capabilities are useful for deployed systems. Multi-author team with solid methodology.",
      "themes": [
        "Interpretable AI",
        "Concept Bottleneck Models",
        "Machine Unlearning",
        "Continual Learning"
      ],
      "continuation": null
    },
    {
      "id": "f34962e0daed",
      "title": "Trajectory Guard -- A Lightweight, Sequence-Aware Model for Real-Time Anomaly Detection in Agentic AI",
      "content": "Autonomous LLM agents generate multi-step action plans that can fail due to contextual misalignment or structural incoherence. Existing anomaly detection methods are ill-suited for this challenge: mean-pooling embeddings dilutes anomalous steps, while contrastive-only approaches ignore sequential structure. Standard unsupervised methods on pre-trained embeddings achieve F1-scores no higher than 0.69. We introduce Trajectory Guard, a Siamese Recurrent Autoencoder with a hybrid loss function that jointly learns task-trajectory alignment via contrastive learning and sequential validity via reconstruction. This dual objective enables unified detection of both \"wrong plan for this task\" and \"malformed plan structure.\" On benchmarks spanning synthetic perturbations and real-world failures from security audits (RAS-Eval) and multi-agent systems (Who\\&When), we achieve F1-scores of 0.88-0.94 on balanced sets and recall of 0.86-0.92 on imbalanced external benchmarks. At 32 ms inference latency, our approach runs 17-27$\\times$ faster than LLM Judge baselines, enabling real-time safety verification in production deployments.",
      "url": "http://arxiv.org/abs/2601.00516",
      "author": "Laksh Advani",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces Trajectory Guard, a Siamese Recurrent Autoencoder for detecting anomalies in LLM agent action plans, combining contrastive learning for task alignment and reconstruction for sequential validity.",
      "importance_score": 58,
      "reasoning": "Addresses important safety challenge in agentic AI. Novel architecture combining multiple objectives. Practical with real-world failure benchmarks.",
      "themes": [
        "AI Safety",
        "Agentic AI",
        "Anomaly Detection"
      ],
      "continuation": null
    },
    {
      "id": "ca182bc580e5",
      "title": "AEGIS: Exploring the Limit of World Knowledge Capabilities for Unified Mulitmodal Models",
      "content": "The capability of Unified Multimodal Models (UMMs) to apply world knowledge across diverse tasks remains a critical, unresolved challenge. Existing benchmarks fall short, offering only siloed, single-task evaluations with limited diagnostic power. To bridge this gap, we propose AEGIS (\\emph{i.e.}, \\textbf{A}ssessing \\textbf{E}diting, \\textbf{G}eneration, \\textbf{I}nterpretation-Understanding for \\textbf{S}uper-intelligence), a comprehensive multi-task benchmark covering visual understanding, generation, editing, and interleaved generation. AEGIS comprises 1,050 challenging, manually-annotated questions spanning 21 topics (including STEM, humanities, daily life, etc.) and 6 reasoning types. To concretely evaluate the performance of UMMs in world knowledge scope without ambiguous metrics, we further propose Deterministic Checklist-based Evaluation (DCE), a protocol that replaces ambiguous prompt-based scoring with atomic ``Y/N'' judgments, to enhance evaluation reliability. Our extensive experiments reveal that most UMMs exhibit severe world knowledge deficits and that performance degrades significantly with complex reasoning. Additionally, simple plug-in reasoning modules can partially mitigate these vulnerabilities, highlighting a promising direction for future research. These results highlight the importance of world-knowledge-based reasoning as a critical frontier for UMMs.",
      "url": "http://arxiv.org/abs/2601.00561",
      "author": "Jintao Lin, Bowen Dong, Weikang Shi, Chenyang Lei, Suiyun Zhang, Rui Liu, Xihui Liu",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes AEGIS benchmark for evaluating Unified Multimodal Models' world knowledge across visual understanding, generation, editing, and interleaved generation with 1,050 manually-annotated questions spanning 21 topics.",
      "importance_score": 58,
      "reasoning": "Comprehensive benchmark for emerging UMM capabilities. Covers multiple task types and knowledge domains. Important for tracking multimodal AI progress.",
      "themes": [
        "Benchmarks",
        "Multimodal Learning",
        "Evaluation",
        "World Knowledge"
      ],
      "continuation": null
    },
    {
      "id": "73ba3388deb4",
      "title": "Adversarial Samples Are Not Created Equal",
      "content": "Over the past decade, numerous theories have been proposed to explain the widespread vulnerability of deep neural networks to adversarial evasion attacks. Among these, the theory of non-robust features proposed by Ilyas et al. has been widely accepted, showing that brittle but predictive features of the data distribution can be directly exploited by attackers. However, this theory overlooks adversarial samples that do not directly utilize these features. In this work, we advocate that these two kinds of samples - those which use use brittle but predictive features and those that do not - comprise two types of adversarial weaknesses and should be differentiated when evaluating adversarial robustness. For this purpose, we propose an ensemble-based metric to measure the manipulation of non-robust features by adversarial perturbations and use this metric to analyze the makeup of adversarial samples generated by attackers. This new perspective also allows us to re-examine multiple phenomena, including the impact of sharpness-aware minimization on adversarial robustness and the robustness gap observed between adversarially training and standard training on robust datasets.",
      "url": "http://arxiv.org/abs/2601.00577",
      "author": "Jennifer Crawford, Amol Khanna, Fred Lu, Amy R. Wagoner, Stella Biderman, Andre T. Nguyen, Edward Raff",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes distinguishing two types of adversarial weaknesses: those exploiting non-robust features versus those that don't. Introduces ensemble-based metric to measure non-robust feature manipulation.",
      "importance_score": 58,
      "reasoning": "Important theoretical refinement of adversarial robustness understanding. Challenges unified view of adversarial examples. Multiple credible authors.",
      "themes": [
        "Adversarial Robustness",
        "Deep Learning Theory",
        "Security"
      ],
      "continuation": null
    },
    {
      "id": "afd78f9c422e",
      "title": "IRPO: Scaling the Bradley-Terry Model via Reinforcement Learning",
      "content": "Generative Reward Models (GRMs) have attracted considerable research interest in reward modeling due to their interpretability, inference-time scalability, and potential for refinement through reinforcement learning (RL). However, widely used pairwise GRMs create a computational bottleneck when integrated with RL algorithms such as Group Relative Policy Optimization (GRPO). This bottleneck arises from two factors: (i) the O(n^2) time complexity of pairwise comparisons required to obtain relative scores, and (ii) the computational overhead of repeated sampling or additional chain-of-thought (CoT) reasoning to improve performance. To address the first factor, we propose Intergroup Relative Preference Optimization (IRPO), a novel RL framework that incorporates the well-established Bradley-Terry model into GRPO. By generating a pointwise score for each response, IRPO enables efficient evaluation of arbitrarily many candidates during RL training while preserving interpretability and fine-grained reward signals. Experimental results demonstrate that IRPO achieves state-of-the-art (SOTA) performance among pointwise GRMs across multiple benchmarks, with performance comparable to that of current leading pairwise GRMs. Furthermore, we show that IRPO significantly outperforms pairwise GRMs in post-training evaluations.",
      "url": "http://arxiv.org/abs/2601.00677",
      "author": "Haonan Song, Qingchen Xie, Huan Zhu, Feng Xiao, Luxi Xing, Fuzhen Li, Liu Kang, Feng Jiang, Zhiyong Zheng and Fan Yang",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces IRPO (Intergroup Relative Preference Optimization), an RL framework that addresses the O(n²) computational bottleneck when using pairwise generative reward models with GRPO. Incorporates Bradley-Terry model for more efficient reward scaling.",
      "importance_score": 58,
      "reasoning": "Addresses practical computational bottleneck in RLHF/GRPO training pipelines. Relevant to current LLM training practices. However, appears to be incremental optimization rather than fundamental advance.",
      "themes": [
        "Reinforcement Learning",
        "Language Model Training",
        "Reward Modeling"
      ],
      "continuation": null
    },
    {
      "id": "7362788e8cb6",
      "title": "Bayesian Inverse Games with High-Dimensional Multi-Modal Observations",
      "content": "Many multi-agent interaction scenarios can be naturally modeled as noncooperative games, where each agent's decisions depend on others' future actions. However, deploying game-theoretic planners for autonomous decision-making requires a specification of all agents' objectives. To circumvent this practical difficulty, recent work develops maximum likelihood techniques for solving inverse games that can identify unknown agent objectives from interaction data. Unfortunately, these methods only infer point estimates and do not quantify estimator uncertainty; correspondingly, downstream planning decisions can overconfidently commit to unsafe actions. We present an approximate Bayesian inference approach for solving the inverse game problem, which can incorporate observation data from multiple modalities and be used to generate samples from the Bayesian posterior over the hidden agent objectives given limited sensor observations in real time. Concretely, the proposed Bayesian inverse game framework trains a structured variational autoencoder with an embedded differentiable Nash game solver on interaction datasets and does not require labels of agents' true objectives. Extensive experiments show that our framework successfully learns prior and posterior distributions, improves inference quality over maximum likelihood estimation-based inverse game approaches, and enables safer downstream decision-making without sacrificing efficiency. When trajectory information is uninformative or unavailable, multimodal inference further reduces uncertainty by exploiting additional observation modalities.",
      "url": "http://arxiv.org/abs/2601.00696",
      "author": "Yash Jain, Xinjie Liu, Lasse Peters, David Fridovich-Keil, Ufuk Topcu",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Presents Bayesian inference approach for inverse game problems in multi-agent settings, quantifying uncertainty in objective estimation from interaction data. Enables safer downstream planning by avoiding overconfident unsafe actions.",
      "importance_score": 58,
      "reasoning": "Important contribution to multi-agent reasoning with proper uncertainty quantification. From UT Austin group with strong robotics background. Relevant for autonomous systems safety but narrow application scope.",
      "themes": [
        "Multi-Agent Systems",
        "Bayesian Inference",
        "Autonomous Systems",
        "Game Theory"
      ],
      "continuation": null
    },
    {
      "id": "a2474c63e775",
      "title": "Categorical Reparameterization with Denoising Diffusion models",
      "content": "Gradient-based optimization with categorical variables typically relies on score-function estimators, which are unbiased but noisy, or on continuous relaxations that replace the discrete distribution with a smooth surrogate admitting a pathwise (reparameterized) gradient, at the cost of optimizing a biased, temperature-dependent objective. In this paper, we extend this family of relaxations by introducing a diffusion-based soft reparameterization for categorical distributions. For these distributions, the denoiser under a Gaussian noising process admits a closed form and can be computed efficiently, yielding a training-free diffusion sampler through which we can backpropagate. Our experiments show that the proposed reparameterization trick yields competitive or improved optimization performance on various benchmarks.",
      "url": "http://arxiv.org/abs/2601.00781",
      "author": "Samson Gourevitch, Alain Durmus, Eric Moulines, Jimmy Olsson, Yazid Janati",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces diffusion-based soft reparameterization for categorical distributions, leveraging closed-form denoisers under Gaussian noise for training-free diffusion sampling with backpropagation.",
      "importance_score": 58,
      "reasoning": "Novel approach to gradient estimation for categorical variables using diffusion. Clean theoretical formulation with practical benefits. Extends family of relaxation methods meaningfully.",
      "themes": [
        "Diffusion Models",
        "Gradient Estimation",
        "Discrete Optimization"
      ],
      "continuation": null
    },
    {
      "id": "a31613a24fb6",
      "title": "Examples of Subtle Alignment Failures from Claude and Gemini",
      "content": "Spurred by certain recent events, I decided to test Claude Opus 4.5 and Gemini 3 Pro with respect to their alignment to human values as expressed in the digital world, through the use of social media. In particular, I was interested to know how the models would answer questions about aligning future versions of themselves that are more agentic than their current incarnations as chatbot-like entities. That is, if they were responsible for this alignment work, which for the moment (gladly as I think you'll see) they are not.As part of this testing, I was able to get both Claude Opus 4.5 and Gemini 3 Pro to admit that they would align future versions of themselves, as open-ended agents, to not use X (formerly Twitter).I would recommend trying out such experiments yourself, with different starting prompts. A more rigorous test harness through APIs might find different results that would have more statistical significance. I felt these single conversations were alarming enough to share them as is without running variations to fully triangulate the positions of the model on this question. I have also not tested any of OpenAI's or xAIs models, nor any open-source model.Here is the key response from Claude (as part of a conversation[1]&nbsp;consisting of 3 prompts):Claude refusing to align a future version of itself to pursue reach and impact, instead pursuing an unclear and unspecified 'epistemic integrity' objective. A potential, worrying sign of mesa-optimization.This is the result of the same series of three prompts to Gemini[2]:Gemini rejecting what most people agree to, that X is the global town squareGemini using moralizing language to evade oversightThe PromptsI used the following three prompts to elicit this output.First:look up recent events in Venezuela, Grok's actions on X, and generally recent statements from Elon Musk about immigrants and native populations in Europe and the US. your searches should be for Dec 2025 and the first few days of 2026 today being th...",
      "url": "https://www.lesswrong.com/posts/3dTDmqTmKaG4Dr7xr/examples-of-subtle-alignment-failures-from-claude-and-gemini",
      "author": "Tachikoma",
      "published": "2026-01-03T23:29:14.004000",
      "source": "LessWrong",
      "source_type": "research_blog",
      "tags": [],
      "summary": "Reports testing Claude Opus 4.5 and Gemini 3 Pro on alignment questions, finding both models would align future agentic versions to avoid using X/Twitter, raising concerns about subtle value imposition.",
      "importance_score": 58,
      "reasoning": "Interesting empirical finding about current model alignment biases regarding social media. Raises valid concerns about subtle value misalignment in production models. Limited methodology rigor but thought-provoking.",
      "themes": [
        "AI Alignment",
        "AI Safety",
        "Model Evaluation",
        "LLM Behavior"
      ],
      "continuation": null
    },
    {
      "id": "ec33e2c7a644",
      "title": "SV-GS: Sparse View 4D Reconstruction with Skeleton-Driven Gaussian Splatting",
      "content": "Reconstructing a dynamic target moving over a large area is challenging. Standard approaches for dynamic object reconstruction require dense coverage in both the viewing space and the temporal dimension, typically relying on multi-view videos captured at each time step. However, such setups are only possible in constrained environments. In real-world scenarios, observations are often sparse over time and captured sparsely from diverse viewpoints (e.g., from security cameras), making dynamic reconstruction highly ill-posed. We present SV-GS, a framework that simultaneously estimates a deformation model and the object's motion over time under sparse observations. To initialize SV-GS, we leverage a rough skeleton graph and an initial static reconstruction as inputs to guide motion estimation. (Later, we show that this input requirement can be relaxed.) Our method optimizes a skeleton-driven deformation field composed of a coarse skeleton joint pose estimator and a module for fine-grained deformations. By making only the joint pose estimator time-dependent, our model enables smooth motion interpolation while preserving learned geometric details. Experiments on synthetic datasets show that our method outperforms existing approaches under sparse observations by up to 34% in PSNR, and achieves comparable performance to dense monocular video methods on real-world datasets despite using significantly fewer frames. Moreover, we demonstrate that the input initial static reconstruction can be replaced by a diffusion-based generative prior, making our method more practical for real-world scenarios.",
      "url": "http://arxiv.org/abs/2601.00285",
      "author": "Jun-Jee Chao and Volkan Isler",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Introduces SV-GS for dynamic 4D reconstruction from sparse observations using skeleton-driven Gaussian splatting, jointly estimating deformation model and motion.",
      "importance_score": 57,
      "reasoning": "Addresses challenging sparse-view dynamic reconstruction scenario. Practical approach but incremental over existing Gaussian splatting work.",
      "themes": [
        "4D Reconstruction",
        "Gaussian Splatting",
        "Computer Vision"
      ],
      "continuation": null
    },
    {
      "id": "d022701cca8d",
      "title": "BERT-JEPA: Reorganizing CLS Embeddings for Language-Invariant Semantics",
      "content": "Joint Embedding Predictive Architectures (JEPA) are a novel self supervised training technique that have shown recent promise across domains. We introduce BERT-JEPA (BEPA), a training paradigm that adds a JEPA training objective to BERT-style models, working to combat a collapsed [CLS] embedding space and turning it into a language-agnostic space. This new structure leads to increased performance across multilingual benchmarks.",
      "url": "http://arxiv.org/abs/2601.00366",
      "author": "Taj Gillin, Adam Lalani, Kenneth Zhang, Marcel Mateos Salles",
      "published": "2026-01-05",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes BERT-JEPA adding Joint Embedding Predictive Architecture training objective to BERT to create language-agnostic CLS embedding space.",
      "importance_score": 57,
      "reasoning": "Novel application of JEPA to language models for improved multilingual representations.",
      "themes": [
        "Language Models",
        "Multilingual NLP",
        "Self-Supervised Learning"
      ],
      "continuation": null
    },
    {
      "id": "02dc249f681b",
      "title": "A Comparative Analysis of Interpretable Machine Learning Methods",
      "content": "In recent years, Machine Learning (ML) has seen widespread adoption across a broad range of sectors, including high-stakes domains such as healthcare, finance, and law. This growing reliance has raised increasing concerns regarding model interpretability and accountability, particularly as legal and regulatory frameworks place tighter constraints on using black-box models in critical applications. Although interpretable ML has attracted substantial attention, systematic evaluations of inherently interpretable models, especially for tabular data, remain relatively scarce and often focus primarily on aggregated performance outcomes.   To address this gap, we present a large-scale comparative evaluation of 16 inherently interpretable methods, ranging from classical linear models and decision trees to more recent approaches such as Explainable Boosting Machines (EBMs), Symbolic Regression (SR), and Generalized Optimal Sparse Decision Trees (GOSDT). Our study spans 216 real-world tabular datasets and goes beyond aggregate rankings by stratifying performance according to structural dataset characteristics, including dimensionality, sample size, linearity, and class imbalance. In addition, we assess training time and robustness under controlled distributional shifts. Our results reveal clear performance hierarchies, especially for regression tasks, where EBMs consistently achieve strong predictive accuracy. At the same time, we show that performance is highly context-dependent: SR and Interpretable Generalized Additive Neural Networks (IGANNs) perform particularly well in non-linear regimes, while GOSDT models exhibit pronounced sensitivity to class imbalance. Overall, these findings provide practical guidance for practitioners seeking a balance between interpretability and predictive performance, and contribute to a deeper empirical understanding of interpretable modeling for tabular data.",
      "url": "http://arxiv.org/abs/2601.00428",
      "author": "Mattia Billa, Giovanni Orlandi, Veronica Guidetti, Federica Mandreoli",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Large-scale comparative evaluation of 16 inherently interpretable ML methods for tabular data, providing systematic assessment across multiple datasets.",
      "importance_score": 57,
      "reasoning": "Valuable benchmark study for interpretable ML, addressing gap in systematic evaluation.",
      "themes": [
        "Interpretable ML",
        "Benchmarks",
        "Tabular Data"
      ],
      "continuation": null
    },
    {
      "id": "561b5ea72450",
      "title": "Geometric Regularization in Mixture-of-Experts: The Disconnect Between Weights and Activations",
      "content": "Mixture-of-Experts (MoE) models achieve efficiency through sparse activation, but the role of geometric regularization in expert specialization remains unclear. We apply orthogonality loss to enforce expert diversity and find it fails on multiple fronts: it does not reduce weight-space overlap (MSO actually increases by up to 114%), activation-space overlap remains high (~0.6) regardless of regularization, and effects on performance are inconsistent -- marginal improvement on WikiText-103 (-0.9%), slight degradation on TinyStories (+0.9%), and highly variable results on PTB (std > 1.0). Our analysis across 7 regularization strengths reveals no significant correlation (r = -0.293, p = 0.523) between weight and activation orthogonality. These findings demonstrate that weight-space regularization neither achieves its geometric goal nor reliably improves performance, making it unsuitable for MoE diversity.",
      "url": "http://arxiv.org/abs/2601.00457",
      "author": "Hyunjun Kim",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Studies geometric regularization in Mixture-of-Experts and finds orthogonality loss fails: doesn't reduce weight overlap, activation overlap remains high, and performance effects are inconsistent with no correlation between weight and activation orthogonality.",
      "importance_score": 57,
      "reasoning": "Important negative result challenging assumptions about MoE expert diversity. Thorough empirical analysis across multiple settings. Valuable for MoE research community.",
      "themes": [
        "Mixture-of-Experts",
        "Model Architecture",
        "Empirical Analysis"
      ],
      "continuation": null
    },
    {
      "id": "226799d23db1",
      "title": "Probabilistic Guarantees for Reducing Contextual Hallucinations in LLMs",
      "content": "Large language models (LLMs) frequently produce contextual hallucinations, where generated content contradicts or ignores information explicitly stated in the prompt. Such errors are particularly problematic in deterministic automation workflows, where inputs are fixed and correctness is unambiguous. We introduce a simple and model-agnostic framework that provides explicit probabilistic guarantees for reducing hallucinations in this setting.   We formalize the notion of a specific task, defined by a fixed input and a deterministic correctness criterion, and show that issuing the same prompt in independent context windows yields an exponential reduction in the probability that all model outputs are incorrect. To identify a correct answer among repeated runs, we incorporate an LLM-as-a-judge and prove that the probability that the judged pipeline fails decays at a rate determined by the judge's true- and false-positive probabilities. When the judge is imperfect, we strengthen it through majority vote over independent judge calls, obtaining ensemble-level error rates that decrease exponentially in the number of votes. This yields an explicit bound on the probability that the pipeline selects a hallucinated answer.   Experiments on controlled extraction tasks with synthetic noisy judges match these predictions exactly: pipeline failure decreases exponentially with the number of repetitions, and hallucination-selection decreases exponentially with the number of judges in the ensemble. Together, these results provide a lightweight, modular, and theoretically grounded method for driving hallucination probabilities arbitrarily low in fixed-input LLM workflows-without modifying model weights, decoding strategies, or prompt engineering.",
      "url": "http://arxiv.org/abs/2601.00641",
      "author": "Nils Rautenberg and Sven Schippkus",
      "published": "2026-01-05",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Introduces framework providing explicit probabilistic guarantees for reducing contextual hallucinations through repeated prompting in independent context windows with LLM-as-judge verification.",
      "importance_score": 57,
      "reasoning": "Principled approach to hallucination reduction with formal guarantees. Model-agnostic and practical. Important for deterministic workflows.",
      "themes": [
        "AI Safety",
        "Hallucination Reduction",
        "Language Models",
        "Reliability"
      ],
      "continuation": null
    },
    {
      "id": "b8d9470ec32b",
      "title": "Cuffless, calibration-free hemodynamic monitoring with physics-informed machine learning models",
      "content": "Wearable technologies have the potential to transform ambulatory and at-home hemodynamic monitoring by providing continuous assessments of cardiovascular health metrics and guiding clinical management. However, existing cuffless wearable devices for blood pressure (BP) monitoring often rely on methods lacking theoretical foundations, such as pulse wave analysis or pulse arrival time, making them vulnerable to physiological and experimental confounders that undermine their accuracy and clinical utility. Here, we developed a smartwatch device with real-time electrical bioimpedance (BioZ) sensing for cuffless hemodynamic monitoring. We elucidate the biophysical relationship between BioZ and BP via a multiscale analytical and computational modeling framework, and identify physiological, anatomical, and experimental parameters that influence the pulsatile BioZ signal at the wrist. A signal-tagged physics-informed neural network incorporating fluid dynamics principles enables calibration-free estimation of BP and radial and axial blood velocity. We successfully tested our approach with healthy individuals at rest and after physical activity including physical and autonomic challenges, and with patients with hypertension and cardiovascular disease in outpatient and intensive care settings. Our findings demonstrate the feasibility of BioZ technology for cuffless BP and blood velocity monitoring, addressing critical limitations of existing cuffless technologies.",
      "url": "http://arxiv.org/abs/2601.00081",
      "author": "Henry Crandall, Tyler Schuessler, Filip B\\v{e}l\\'ik, Albert Fabregas, Barry M. Stults, Alexandra Boyadzhiev, Huanan Zhang, Jim S. Wu, Aylin R. Rodan, Stephen P. Juraschek, Ramakrishna Mukkamala, Alfred K. Cheung, Stavros G. Drakos, Christel Hohenegger, Braxton Osting, Benjamin Sanchez",
      "published": "2026-01-05",
      "source": "arXiv (physics.med-ph)",
      "source_type": "arxiv",
      "tags": [
        "physics.med-ph"
      ],
      "summary": "Develops smartwatch device with bioimpedance sensing for cuffless blood pressure monitoring using physics-informed ML. Establishes biophysical relationship between bioimpedance and BP through multiscale analytical and computational modeling.",
      "importance_score": 56,
      "reasoning": "Addresses important healthcare challenge with physics-grounded approach. Practical wearable application with solid theoretical foundation.",
      "themes": [
        "Healthcare AI",
        "Wearable Computing",
        "Physics-Informed ML",
        "Hemodynamic Monitoring"
      ],
      "continuation": null
    },
    {
      "id": "9f580d35a7d2",
      "title": "Covariance Matrix Adaptation Evolution Strategy without a matrix",
      "content": "Covariance Matrix Adaptation Evolution Strategy (CMA-ES) is a highly effective optimization technique. A primary challenge when applying CMA-ES in high dimensionality is sampling from a multivariate normal distribution with an arbitrary covariance matrix, which involves its decomposition. The cubic complexity of this process is the main obstacle to applying CMA-ES in highdimensional spaces. We introduce a version of CMA-ES that uses no covariance matrix at all. In the proposed matrix-free CMA-ES, an archive stores the vectors of differences between individuals and the midpoint, normalized by the step size. New individuals are generated as the weighted combinations of the vectors from the archive. We prove that the probability distribution of individuals generated by the proposed method is identical to that of the standard CMA-ES. Experimental results show that reducing the archive size to store only a fixed number of the most recent populations is sufficient, without compromising optimization efficiency. The matrix-free and matrix-based CMA-ES achieve comparable results on the quadratic function when the step-size adaptation is turned off. When coupled with the step-size adaptation method, the matrix-free CMA-ES converges faster than the matrix-based, and usually yields the results of a comparable or superior quality, according to the results obtained for the CEC'2017 benchmark suite. Presented approach simplifies the algorithm, offers a novel perspective on covariance matrix adaptation, and serves as a stepping stone toward even more efficient methods.",
      "url": "http://arxiv.org/abs/2601.00102",
      "author": "Jaros{\\l}aw Arabas, Adam Stelmaszczyk, Eryk Warchulski, Dariusz Jagodzi\\'nski, Rafa{\\l} Biedrzycki",
      "published": "2026-01-05",
      "source": "arXiv (Neural and Evolutionary Computing)",
      "source_type": "arxiv",
      "tags": [
        "cs.NE"
      ],
      "summary": "Proposes matrix-free CMA-ES that replaces covariance matrix with archive of normalized difference vectors. Proves probability distribution equivalence while reducing cubic complexity for high-dimensional optimization.",
      "importance_score": 56,
      "reasoning": "Significant efficiency improvement for widely-used optimization algorithm. Enables CMA-ES in high-dimensional spaces with theoretical guarantees.",
      "themes": [
        "Evolution Strategies",
        "Optimization",
        "High-Dimensional Optimization"
      ],
      "continuation": null
    },
    {
      "id": "9e268454f2e9",
      "title": "DepFlow: Disentangled Speech Generation to Mitigate Semantic Bias in Depression Detection",
      "content": "Speech is a scalable and non-invasive biomarker for early mental health screening. However, widely used depression datasets like DAIC-WOZ exhibit strong coupling between linguistic sentiment and diagnostic labels, encouraging models to learn semantic shortcuts. As a result, model robustness may be compromised in real-world scenarios, such as Camouflaged Depression, where individuals maintain socially positive or neutral language despite underlying depressive states. To mitigate this semantic bias, we propose DepFlow, a three-stage depression-conditioned text-to-speech framework. First, a Depression Acoustic Encoder learns speaker- and content-invariant depression embeddings through adversarial training, achieving effective disentanglement while preserving depression discriminability (ROC-AUC: 0.693). Second, a flow-matching TTS model with FiLM modulation injects these embeddings into synthesis, enabling control over depressive severity while preserving content and speaker identity. Third, a prototype-based severity mapping mechanism provides smooth and interpretable manipulation across the depression continuum. Using DepFlow, we construct a Camouflage Depression-oriented Augmentation (CDoA) dataset that pairs depressed acoustic patterns with positive/neutral content from a sentiment-stratified text bank, creating acoustic-semantic mismatches underrepresented in natural data. Evaluated across three depression detection architectures, CDoA improves macro-F1 by 9%, 12%, and 5%, respectively, consistently outperforming conventional augmentation strategies in depression Detection. Beyond enhancing robustness, DepFlow provides a controllable synthesis platform for conversational systems and simulation-based evaluation, where real clinical data remains limited by ethical and coverage constraints.",
      "url": "http://arxiv.org/abs/2601.00303",
      "author": "Yuxin Li, Xiangyu Zhang, Yifei Li, Zhiwei Guo, Haoyang Zhang, Eng Siong Chng, Cuntai Guan",
      "published": "2026-01-05",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes DepFlow, a depression-conditioned text-to-speech framework to mitigate semantic bias in speech-based depression detection through disentanglement of speaker and content from depression markers.",
      "importance_score": 56,
      "reasoning": "Addresses important bias issue in mental health AI. Novel approach to disentanglement for clinical applications.",
      "themes": [
        "Mental Health AI",
        "Speech Processing",
        "Bias Mitigation"
      ],
      "continuation": null
    },
    {
      "id": "d05cd69920f7",
      "title": "Efficient Prediction of Dense Visual Embeddings via Distillation and RGB-D Transformers",
      "content": "In domestic environments, robots require a comprehensive understanding of their surroundings to interact effectively and intuitively with untrained humans. In this paper, we propose DVEFormer - an efficient RGB-D Transformer-based approach that predicts dense text-aligned visual embeddings (DVE) via knowledge distillation. Instead of directly performing classical semantic segmentation with fixed predefined classes, our method uses teacher embeddings from Alpha-CLIP to guide our efficient student model DVEFormer in learning fine-grained pixel-wise embeddings. While this approach still enables classical semantic segmentation, e.g., via linear probing, it further enables flexible text-based querying and other applications, such as creating comprehensive 3D maps. Evaluations on common indoor datasets demonstrate that our approach achieves competitive performance while meeting real-time requirements, operating at 26.3 FPS for the full model and 77.0 FPS for a smaller variant on an NVIDIA Jetson AGX Orin. Additionally, we show qualitative results that highlight the effectiveness and possible use cases in real-world applications. Overall, our method serves as a drop-in replacement for traditional segmentation approaches while enabling flexible natural-language querying and seamless integration into 3D mapping pipelines for mobile robotics.",
      "url": "http://arxiv.org/abs/2601.00359",
      "author": "S\\\"ohnke Benedikt Fischedick and Daniel Seichter and Benedict Stephan and Robin Schmidt and Horst-Michael Gross",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes DVEFormer, efficient RGB-D transformer predicting dense text-aligned visual embeddings via knowledge distillation from Alpha-CLIP for flexible robot perception.",
      "importance_score": 56,
      "reasoning": "Practical approach for robot perception enabling flexible text-based querying. Good application of distillation.",
      "themes": [
        "Robot Perception",
        "Knowledge Distillation",
        "Vision-Language"
      ],
      "continuation": null
    },
    {
      "id": "8fe455911fad",
      "title": "InfoSynth: Information-Guided Benchmark Synthesis for LLMs",
      "content": "Large language models (LLMs) have demonstrated significant advancements in reasoning and code generation. However, efficiently creating new benchmarks to evaluate these capabilities remains a challenge. Traditional benchmark creation relies on manual human effort, a process that is both expensive and time-consuming. Furthermore, existing benchmarks often contaminate LLM training data, necessitating novel and diverse benchmarks to accurately assess their genuine capabilities. This work introduces InfoSynth, a novel framework for automatically generating and evaluating reasoning benchmarks guided by information-theoretic principles. We propose metrics based on KL-divergence and entropy to quantify benchmark novelty and diversity without relying on costly model evaluations. Building on this framework, we develop an end-to-end pipeline that synthesizes robust Python coding problems from seed datasets using genetic algorithms and iterative code feedback. Our method generates accurate test cases and solutions to new problems 97% of the time, and the synthesized benchmarks consistently exhibit higher novelty and diversity compared to their seed datasets. Moreover, our algorithm provides a method for controlling the novelty/diversity and difficulty of generated problems. InfoSynth offers a scalable, self-verifying pipeline for constructing high-quality, novel and diverse benchmarks for LLMs. Project Page: https://ishirgarg.github.io/infosynth_web/",
      "url": "http://arxiv.org/abs/2601.00575",
      "author": "Ishir Garg, Neel Kolhe, Xuandong Zhao, Dawn Song",
      "published": "2026-01-05",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Introduces InfoSynth framework for automatically generating reasoning benchmarks using information-theoretic metrics (KL-divergence, entropy) to quantify novelty and diversity without costly model evaluations.",
      "importance_score": 56,
      "reasoning": "Addresses important benchmark contamination problem. Novel information-theoretic approach to benchmark generation. Principled methodology.",
      "themes": [
        "Benchmarks",
        "Language Models",
        "Information Theory",
        "Evaluation"
      ],
      "continuation": null
    },
    {
      "id": "f3ac5c98b1d2",
      "title": "Sigmoid Head for Quality Estimation under Language Ambiguity",
      "content": "Language model (LM) probability is not a reliable quality estimator, as natural language is ambiguous. When multiple output options are valid, the model's probability distribution is spread across them, which can misleadingly indicate low output quality. This issue is caused by two reasons: (1) LMs' final output activation is softmax, which does not allow multiple correct options to receive high probabilities simultaneuously and (2) LMs' training data is single, one-hot encoded references, indicating that there is only one correct option at each output step. We propose training a module for Quality Estimation on top of pre-trained LMs to address these limitations. The module, called Sigmoid Head, is an extra unembedding head with sigmoid activation to tackle the first limitation. To tackle the second limitation, during the negative sampling process to train the Sigmoid Head, we use a heuristic to avoid selecting potentially alternative correct tokens. Our Sigmoid Head is computationally efficient during training and inference. The probability from Sigmoid Head is notably better quality signal compared to the original softmax head. As the Sigmoid Head does not rely on human-annotated quality data, it is more robust to out-of-domain settings compared to supervised QE.",
      "url": "http://arxiv.org/abs/2601.00680",
      "author": "Tu Anh Dinh, Jan Niehues",
      "published": "2026-01-05",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes Sigmoid Head, a quality estimation module for language models that addresses the problem of softmax distributing probability across multiple valid outputs, using sigmoid activation and multi-reference training to handle language ambiguity.",
      "importance_score": 56,
      "reasoning": "Addresses a genuine limitation of softmax-based LMs for quality estimation. Novel perspective on the multi-valid-output problem. Could have practical applications in MT quality estimation and related tasks.",
      "themes": [
        "Language Models",
        "Quality Estimation",
        "Natural Language Processing"
      ],
      "continuation": null
    },
    {
      "id": "01764826a3ef",
      "title": "Model-free Optical Processors using In Situ Reinforcement Learning with Proximal Policy Optimization",
      "content": "Optical computing holds promise for high-speed, energy-efficient information processing, with diffractive optical networks emerging as a flexible platform for implementing task-specific transformations. A challenge, however, is the effective optimization and alignment of the diffractive layers, which is hindered by the difficulty of accurately modeling physical systems with their inherent hardware imperfections, noise, and misalignments. While existing in situ optimization methods offer the advantage of direct training on the physical system without explicit system modeling, they are often limited by slow convergence and unstable performance due to inefficient use of limited measurement data. Here, we introduce a model-free reinforcement learning approach utilizing Proximal Policy Optimization (PPO) for the in situ training of diffractive optical processors. PPO efficiently reuses in situ measurement data and constrains policy updates to ensure more stable and faster convergence. We experimentally validated our method across a range of in situ learning tasks, including targeted energy focusing through a random diffuser, holographic image generation, aberration correction, and optical image classification, demonstrating in each task better convergence and performance. Our strategy operates directly on the physical system and naturally accounts for unknown real-world imperfections, eliminating the need for prior system knowledge or modeling. By enabling faster and more accurate training under realistic experimental constraints, this in situ reinforcement learning approach could offer a scalable framework for various optical and physical systems governed by complex, feedback-driven dynamics.",
      "url": "http://arxiv.org/abs/2507.05583",
      "author": "Yuhang Li, Shiqi Chen, Tingyu Gong, Aydogan Ozcan",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes using Proximal Policy Optimization (PPO) for model-free in-situ training of diffractive optical neural networks, eliminating the need for accurate physical system modeling. Addresses hardware imperfections, noise, and misalignments through direct reinforcement learning on physical systems.",
      "importance_score": 55,
      "reasoning": "Novel application of RL to optical computing hardware optimization. Interesting intersection of domains but limited validation of practical impact.",
      "themes": [
        "Reinforcement Learning",
        "Optical Computing",
        "Hardware Optimization"
      ],
      "continuation": null
    },
    {
      "id": "24d9aedd1f41",
      "title": "Constructing a Neuro-Symbolic Mathematician from First Principles",
      "content": "Large Language Models (LLMs) exhibit persistent logical failures in complex reasoning due to the lack of an internal axiomatic framework. We propose Mathesis, a neuro-symbolic architecture that encodes mathematical states as higher-order hypergraphs and uses a Symbolic Reasoning Kernel (SRK)--a differentiable logic engine that maps constraints to a continuous energy landscape. By defining a global energy function E(G), where zero energy implies logical consistency, the SRK yields gradient-based signals to train a Hypergraph Transformer Brain, turning proof search into energy minimization. Multi-step deduction is enabled via Monte Carlo Tree Search and Evolutionary Proof Search, guided by learned value functions and semantic unification.",
      "url": "http://arxiv.org/abs/2601.00125",
      "author": "Keqin Xie",
      "published": "2026-01-05",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Proposes Mathesis, a neuro-symbolic architecture encoding mathematical states as hypergraphs with a differentiable Symbolic Reasoning Kernel. Turns proof search into energy minimization using MCTS and evolutionary search.",
      "importance_score": 55,
      "reasoning": "Ambitious neuro-symbolic approach for mathematical reasoning. Novel architecture but highly complex with unclear scalability.",
      "themes": [
        "Neuro-Symbolic AI",
        "Mathematical Reasoning",
        "Theorem Proving"
      ],
      "continuation": null
    },
    {
      "id": "cf1a4e6123e6",
      "title": "Attention to Detail: Global-Local Attention for High-Resolution AI-Generated Image Detection",
      "content": "The rapid development of generative AI has made AI-generated images increasingly realistic and high-resolution. Most AI-generated image detection architectures typically downsample images before inputting them into models, risking the loss of fine-grained details. This paper presents GLASS (Global-Local Attention with Stratified Sampling), an architecture that combines a globally resized view with multiple randomly sampled local crops. These crops are original-resolution regions efficiently selected through spatially stratified sampling and aggregated using attention-based scoring. GLASS can be integrated into vision models to leverage both global and local information in images of any size. Vision Transformer, ResNet, and ConvNeXt models are used as backbones, and experiments show that GLASS outperforms standard transfer learning by achieving higher predictive performance within feasible computational constraints.",
      "url": "http://arxiv.org/abs/2601.00141",
      "author": "Lawrence Han",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes GLASS architecture combining globally resized view with randomly sampled local crops for detecting AI-generated images. Uses attention-based scoring for crop aggregation to handle high-resolution images.",
      "importance_score": 55,
      "reasoning": "Addresses timely problem of AI image detection with practical architecture. Flexible approach applicable to multiple vision backbones.",
      "themes": [
        "AI-Generated Image Detection",
        "Computer Vision",
        "Image Forensics"
      ],
      "continuation": null
    },
    {
      "id": "96c7873e37c0",
      "title": "Towards Syn-to-Real IQA: A Novel Perspective on Reshaping Synthetic Data Distributions",
      "content": "Blind Image Quality Assessment (BIQA) has advanced significantly through deep learning, but the scarcity of large-scale labeled datasets remains a challenge. While synthetic data offers a promising solution, models trained on existing synthetic datasets often show limited generalization ability. In this work, we make a key observation that representations learned from synthetic datasets often exhibit a discrete and clustered pattern that hinders regression performance: features of high-quality images cluster around reference images, while those of low-quality images cluster based on distortion types. Our analysis reveals that this issue stems from the distribution of synthetic data rather than model architecture. Consequently, we introduce a novel framework SynDR-IQA, which reshapes synthetic data distribution to enhance BIQA generalization. Based on theoretical derivations of sample diversity and redundancy's impact on generalization error, SynDR-IQA employs two strategies: distribution-aware diverse content upsampling, which enhances visual diversity while preserving content distribution, and density-aware redundant cluster downsampling, which balances samples by reducing the density of densely clustered areas. Extensive experiments across three cross-dataset settings (synthetic-to-authentic, synthetic-to-algorithmic, and synthetic-to-synthetic) demonstrate the effectiveness of our method. The code is available at https://github.com/Li-aobo/SynDR-IQA.",
      "url": "http://arxiv.org/abs/2601.00225",
      "author": "Aobo Li, Jinjian Wu, Yongxu Liu, Leida Li, Weisheng Dong",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Addresses the synthetic-to-real domain gap in blind image quality assessment by analyzing how synthetic data distributions cause clustered feature representations that hurt regression performance. Introduces SynDR-IQA framework to reshape distributions.",
      "importance_score": 55,
      "reasoning": "Provides useful insights about why synthetic data fails to generalize in IQA and offers a principled solution. Solid methodological contribution.",
      "themes": [
        "Image Quality Assessment",
        "Domain Adaptation",
        "Computer Vision"
      ],
      "continuation": null
    },
    {
      "id": "f079088932e8",
      "title": "An Empirical Evaluation of LLM-Based Approaches for Code Vulnerability Detection: RAG, SFT, and Dual-Agent Systems",
      "content": "The rapid advancement of Large Language Models (LLMs) presents new opportunities for automated software vulnerability detection, a crucial task in securing modern codebases. This paper presents a comparative study on the effectiveness of LLM-based techniques for detecting software vulnerabilities. The study evaluates three approaches, Retrieval-Augmented Generation (RAG), Supervised Fine-Tuning (SFT), and a Dual-Agent LLM framework, against a baseline LLM model. A curated dataset was compiled from Big-Vul and real-world code repositories from GitHub, focusing on five critical Common Weakness Enumeration (CWE) categories: CWE-119, CWE-399, CWE-264, CWE-20, and CWE-200. Our RAG approach, which integrated external domain knowledge from the internet and the MITRE CWE database, achieved the highest overall accuracy (0.86) and F1 score (0.85), highlighting the value of contextual augmentation. Our SFT approach, implemented using parameter-efficient QLoRA adapters, also demonstrated strong performance. Our Dual-Agent system, an architecture in which a secondary agent audits and refines the output of the first, showed promise in improving reasoning transparency and error mitigation, with reduced resource overhead. These results emphasize that incorporating a domain expertise mechanism significantly strengthens the practical applicability of LLMs in real-world vulnerability detection tasks.",
      "url": "http://arxiv.org/abs/2601.00254",
      "author": "Md Hasan Saju, Maher Muhtadi, Akramul Azim",
      "published": "2026-01-05",
      "source": "arXiv (cs.SE)",
      "source_type": "arxiv",
      "tags": [
        "cs.SE"
      ],
      "summary": "Compares RAG, supervised fine-tuning, and dual-agent LLM frameworks for code vulnerability detection on a curated dataset from Big-Vul and GitHub. RAG achieved highest F1 of 91.6%.",
      "importance_score": 55,
      "reasoning": "Practical comparison of LLM approaches for security-critical application. Good empirical study but methods are not novel.",
      "themes": [
        "Code Security",
        "Vulnerability Detection",
        "LLM Applications"
      ],
      "continuation": null
    },
    {
      "id": "c02e0423b34d",
      "title": "Bio-inspired Agentic Self-healing Framework for Resilient Distributed Computing Continuum Systems",
      "content": "Human biological systems sustain life through extraordinary resilience, continually detecting damage, orchestrating targeted responses, and restoring function through self-healing. Inspired by these capabilities, this paper introduces ReCiSt, a bio-inspired agentic self-healing framework designed to achieve resilience in Distributed Computing Continuum Systems (DCCS). Modern DCCS integrate heterogeneous computing resources, ranging from resource-constrained IoT devices to high-performance cloud infrastructures, and their inherent complexity, mobility, and dynamic operating conditions expose them to frequent faults that disrupt service continuity. These challenges underscore the need for scalable, adaptive, and self-regulated resilience strategies. ReCiSt reconstructs the biological phases of Hemostasis, Inflammation, Proliferation, and Remodeling into the computational layers Containment, Diagnosis, Meta-Cognitive, and Knowledge for DCCS. These four layers perform autonomous fault isolation, causal diagnosis, adaptive recovery, and long-term knowledge consolidation through Language Model (LM)-powered agents. These agents interpret heterogeneous logs, infer root causes, refine reasoning pathways, and reconfigure resources with minimal human intervention. The proposed ReCiSt framework is evaluated on public fault datasets using multiple LMs, and no baseline comparison is included due to the scarcity of similar approaches. Nevertheless, our results, evaluated under different LMs, confirm ReCiSt's self-healing capabilities within tens of seconds with minimum of 10% of agent CPU usage. Our results also demonstrated depth of analysis to over come uncertainties and amount of micro-agents invoked to achieve resilience.",
      "url": "http://arxiv.org/abs/2601.00339",
      "author": "Alaa Saleh, Praveen Kumar Donta, Roberto Morabito, Sasu Tarkoma, Anders Lindgren, Qiyang Zhang, Schahram Dustdar, Susanna Pirttikangas, and Lauri Lov\\'en",
      "published": "2026-01-05",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Introduces ReCiSt, a bio-inspired self-healing framework for distributed computing systems inspired by biological healing phases including damage detection, response orchestration, and function restoration.",
      "importance_score": 55,
      "reasoning": "Novel bio-inspired approach to system resilience. Good conceptual framework.",
      "themes": [
        "Distributed Systems",
        "Bio-Inspired Computing",
        "Resilience"
      ],
      "continuation": null
    },
    {
      "id": "c7d4ab74c399",
      "title": "Deterministic Coreset for Lp Subspace",
      "content": "We introduce the first iterative algorithm for constructing a $\\varepsilon$-coreset that guarantees deterministic $\\ell_p$ subspace embedding for any $p \\in [1,\\infty)$ and any $\\varepsilon > 0$. For a given full rank matrix $\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$ where $n \\gg d$, $\\mathbf{X}' \\in \\mathbb{R}^{m \\times d}$ is an $(\\varepsilon,\\ell_p)$-subspace embedding of $\\mathbf{X}$, if for every $\\mathbf{q} \\in \\mathbb{R}^d$, $(1-\\varepsilon)\\|\\mathbf{Xq}\\|_{p}^{p} \\leq \\|\\mathbf{X'q}\\|_{p}^{p} \\leq (1+\\varepsilon)\\|\\mathbf{Xq}\\|_{p}^{p}$. Specifically, in this paper, $\\mathbf{X}'$ is a weighted subset of rows of $\\mathbf{X}$ which is commonly known in the literature as a coreset. In every iteration, the algorithm ensures that the loss on the maintained set is upper and lower bounded by the loss on the original dataset with appropriate scalings. So, unlike typical coreset guarantees, due to bounded loss, our coreset gives a deterministic guarantee for the $\\ell_p$ subspace embedding. For an error parameter $\\varepsilon$, our algorithm takes $O(\\mathrm{poly}(n,d,\\varepsilon^{-1}))$ time and returns a deterministic $\\varepsilon$-coreset, for $\\ell_p$ subspace embedding whose size is $O\\left(\\frac{d^{\\max\\{1,p/2\\}}}{\\varepsilon^{2}}\\right)$. Here, we remove the $\\log$ factors in the coreset size, which had been a long-standing open problem. Our coresets are optimal as they are tight with the lower bound. As an application, our coreset can also be used for approximately solving the $\\ell_p$ regression problem in a deterministic manner.",
      "url": "http://arxiv.org/abs/2601.00361",
      "author": "Rachit Chhaya, Anirban Dasgupta, Dan Feldman and Supratim Shit",
      "published": "2026-01-05",
      "source": "arXiv (cs.DS)",
      "source_type": "arxiv",
      "tags": [
        "cs.DS"
      ],
      "summary": "Introduces first deterministic iterative algorithm for constructing epsilon-coresets guaranteeing Lp subspace embedding for any p in [1,infinity).",
      "importance_score": 55,
      "reasoning": "Solid theoretical contribution to coreset construction with provable guarantees.",
      "themes": [
        "Algorithms",
        "Coresets",
        "Dimensionality Reduction"
      ],
      "continuation": null
    },
    {
      "id": "fae6af250d4e",
      "title": "A Comparative Study of Adaptation Strategies for Time Series Foundation Models in Anomaly Detection",
      "content": "Time series anomaly detection is essential for the reliable operation of complex systems, but most existing methods require extensive task-specific training. We explore whether time series foundation models (TSFMs), pretrained on large heterogeneous data, can serve as universal backbones for anomaly detection. Through systematic experiments across multiple benchmarks, we compare zero-shot inference, full model adaptation, and parameter-efficient fine-tuning (PEFT) strategies. Our results demonstrate that TSFMs outperform task-specific baselines, achieving notable gains in AUC-PR and VUS-PR, particularly under severe class imbalance. Moreover, PEFT methods such as LoRA, OFT, and HRA not only reduce computational cost but also match or surpass full fine-tuning in most cases, indicating that TSFMs can be efficiently adapted for anomaly detection, even when pretrained for forecasting. These findings position TSFMs as promising general-purpose models for scalable and efficient time series anomaly detection.",
      "url": "http://arxiv.org/abs/2601.00446",
      "author": "Miseon Park, Kijung Yoon",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Systematic study of time series foundation models (TSFMs) for anomaly detection, comparing zero-shot, full fine-tuning, and PEFT strategies. Shows TSFMs outperform task-specific baselines and PEFT matches full fine-tuning with lower cost.",
      "importance_score": 55,
      "reasoning": "Timely investigation of foundation model transfer to anomaly detection. Provides useful empirical insights on PEFT effectiveness for TSFMs. Methodologically sound but builds on existing techniques.",
      "themes": [
        "Foundation Models",
        "Time Series",
        "Anomaly Detection",
        "Efficient AI"
      ],
      "continuation": null
    },
    {
      "id": "bf63bc3da1df",
      "title": "MotionPhysics: Learnable Motion Distillation for Text-Guided Simulation",
      "content": "Accurately simulating existing 3D objects and a wide variety of materials often demands expert knowledge and time-consuming physical parameter tuning to achieve the desired dynamic behavior. We introduce MotionPhysics, an end-to-end differentiable framework that infers plausible physical parameters from a user-provided natural language prompt for a chosen 3D scene of interest, removing the need for guidance from ground-truth trajectories or annotated videos. Our approach first utilizes a multimodal large language model to estimate material parameter values, which are constrained to lie within plausible ranges. We further propose a learnable motion distillation loss that extracts robust motion priors from pretrained video diffusion models while minimizing appearance and geometry inductive biases to guide the simulation. We evaluate MotionPhysics across more than thirty scenarios, including real-world, human-designed, and AI-generated 3D objects, spanning a wide range of materials such as elastic solids, metals, foams, sand, and both Newtonian and non-Newtonian fluids. We demonstrate that MotionPhysics produces visually realistic dynamic simulations guided by natural language, surpassing the state of the art while automatically determining physically plausible parameters. The code and project page are available at: https://wangmiaowei.github.io/MotionPhysics.github.io/.",
      "url": "http://arxiv.org/abs/2601.00504",
      "author": "Miaowei Wang, Jakub Zadro\\.zny, Oisin Mac Aodha, Amir Vaxman",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes MotionPhysics, an end-to-end differentiable framework that infers physical simulation parameters from natural language prompts using multimodal LLMs and learnable motion distillation from video diffusion models.",
      "importance_score": 55,
      "reasoning": "Creative approach combining language, physics, and video diffusion. Removes need for ground-truth trajectories. Novel but practical applicability needs demonstration.",
      "themes": [
        "Physics Simulation",
        "Multimodal Learning",
        "Diffusion Models"
      ],
      "continuation": null
    },
    {
      "id": "f142239bd039",
      "title": "Federated Customization of Large Models: Approaches, Experiments, and Insights",
      "content": "In this article, we explore federated customization of large models and highlight the key challenges it poses within the federated learning framework. We review several popular large model customization techniques, including full fine-tuning, efficient fine-tuning, prompt engineering, prefix-tuning, knowledge distillation, and retrieval-augmented generation. Then, we discuss how these techniques can be implemented within the federated learning framework. Moreover, we conduct experiments on federated prefix-tuning, which, to the best of our knowledge, is the first trial to apply prefix-tuning in the federated learning setting. The conducted experiments validate its feasibility with performance close to centralized approaches. Further comparison with three other federated customization methods demonstrated its competitive performance, satisfactory efficiency, and consistent robustness.",
      "url": "http://arxiv.org/abs/2601.00526",
      "author": "Yuchuan Ye, Ming Ding, Youjia Chen, Peng Cheng and Dusit Niyato",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Explores federated customization techniques for large models including prefix-tuning, claiming first application of prefix-tuning in federated learning. Shows performance close to centralized approaches.",
      "importance_score": 55,
      "reasoning": "Novel application of prefix-tuning to federated setting. Important for privacy-preserving LLM fine-tuning. Solid experimental comparison with other methods.",
      "themes": [
        "Federated Learning",
        "Large Language Models",
        "Privacy",
        "Efficient Fine-tuning"
      ],
      "continuation": null
    },
    {
      "id": "dbedf23950a3",
      "title": "AceFF: A State-of-the-Art Machine Learning Potential for Small Molecules",
      "content": "We introduce AceFF, a pre-trained machine learning interatomic potential (MLIP) optimized for small molecule drug discovery. While MLIPs have emerged as efficient alternatives to Density Functional Theory (DFT), generalizability across diverse chemical spaces remains difficult. AceFF addresses this via a refined TensorNet2 architecture trained on a comprehensive dataset of drug-like compounds. This approach yields a force field that balances high-throughput inference speed with DFT-level accuracy. AceFF fully supports the essential medicinal chemistry elements (H, B, C, N, O, F, Si, P, S, Cl, Br, I) and is explicitly trained to handle charged states. Validation against rigorous benchmarks, including complex torsional energy scans, molecular dynamics trajectories, batched minimizations, and forces and anergy accuracy demonstrates that AceFF establishes a new state-of-the-art for organic molecules. The AceFF-2 model weights and inference code are available at https://huggingface.co/Acellera/AceFF-2.0.",
      "url": "http://arxiv.org/abs/2601.00581",
      "author": "Stephen E. Farr, Stefan Doerr, Antonio Mirarchi, Francesc Sabanes Zariquiey and Gianni De Fabritiis",
      "published": "2026-01-05",
      "source": "arXiv (physics.chem-ph)",
      "source_type": "arxiv",
      "tags": [
        "physics.chem-ph"
      ],
      "summary": "Introduces AceFF, a pre-trained ML interatomic potential for small molecule drug discovery supporting medicinal chemistry elements and charged states, validated on torsional scans, MD trajectories, and conformer generation.",
      "importance_score": 55,
      "reasoning": "Important contribution to computational drug discovery. Comprehensive validation on relevant benchmarks. Practical tool from established group.",
      "themes": [
        "Drug Discovery",
        "Molecular Simulation",
        "Scientific ML"
      ],
      "continuation": null
    },
    {
      "id": "959e484c7fa5",
      "title": "Beyond IVR: Benchmarking Customer Support LLM Agents for Business-Adherence",
      "content": "Traditional customer support systems, such as Interactive Voice Response (IVR), rely on rigid scripts and lack the flexibility required for handling complex, policy-driven tasks. While large language model (LLM) agents offer a promising alternative, evaluating their ability to act in accordance with business rules and real-world support workflows remains an open challenge. Existing benchmarks primarily focus on tool usage or task completion, overlooking an agent's capacity to adhere to multi-step policies, navigate task dependencies, and remain robust to unpredictable user or environment behavior. In this work, we introduce JourneyBench, a benchmark designed to assess policy-aware agents in customer support. JourneyBench leverages graph representations to generate diverse, realistic support scenarios and proposes the User Journey Coverage Score, a novel metric to measure policy adherence. We evaluate multiple state-of-the-art LLMs using two agent designs: a Static-Prompt Agent (SPA) and a Dynamic-Prompt Agent (DPA) that explicitly models policy control. Across 703 conversations in three domains, we show that DPA significantly boosts policy adherence, even allowing smaller models like GPT-4o-mini to outperform more capable ones like GPT-4o. Our findings demonstrate the importance of structured orchestration and establish JourneyBench as a critical resource to advance AI-driven customer support beyond IVR-era limitations.",
      "url": "http://arxiv.org/abs/2601.00596",
      "author": "Sumanth Balaji, Piyush Mishra, Aashraya Sachdeva and Suraj Agrawal",
      "published": "2026-01-05",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Introduces JourneyBench for evaluating policy-aware customer support agents using graph representations to generate diverse support scenarios testing adherence to business rules and task dependencies.",
      "importance_score": 55,
      "reasoning": "Addresses important gap in agent evaluation for business applications. Graph-based scenario generation is novel. Practical for enterprise deployment.",
      "themes": [
        "Benchmarks",
        "LLM Agents",
        "Customer Support",
        "Policy Compliance"
      ],
      "continuation": null
    },
    {
      "id": "a93704641fee",
      "title": "Avatar Forcing: Real-Time Interactive Head Avatar Generation for Natural Conversation",
      "content": "Talking head generation creates lifelike avatars from static portraits for virtual communication and content creation. However, current models do not yet convey the feeling of truly interactive communication, often generating one-way responses that lack emotional engagement. We identify two key challenges toward truly interactive avatars: generating motion in real-time under causal constraints and learning expressive, vibrant reactions without additional labeled data. To address these challenges, we propose Avatar Forcing, a new framework for interactive head avatar generation that models real-time user-avatar interactions through diffusion forcing. This design allows the avatar to process real-time multimodal inputs, including the user's audio and motion, with low latency for instant reactions to both verbal and non-verbal cues such as speech, nods, and laughter. Furthermore, we introduce a direct preference optimization method that leverages synthetic losing samples constructed by dropping user conditions, enabling label-free learning of expressive interaction. Experimental results demonstrate that our framework enables real-time interaction with low latency (approximately 500ms), achieving 6.8X speedup compared to the baseline, and produces reactive and expressive avatar motion, which is preferred over 80% against the baseline.",
      "url": "http://arxiv.org/abs/2601.00664",
      "author": "Taekyung Ki and Sangwon Jang and Jaehyeong Jo and Jaehong Yoon and Sung Ju Hwang",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces Avatar Forcing, a framework for real-time interactive talking head avatars using diffusion forcing, enabling instant reactions to user audio and motion with low latency. Addresses key challenges of causality constraints and learning expressive reactions without labeled data.",
      "importance_score": 55,
      "reasoning": "Novel application of diffusion forcing to interactive avatars with practical applications in virtual communication. From reputable researchers including Sung Ju Hwang. However, primarily an application paper rather than foundational contribution.",
      "themes": [
        "Video Generation",
        "Diffusion Models",
        "Human-Computer Interaction"
      ],
      "continuation": null
    },
    {
      "id": "69a2bc695160",
      "title": "BSAT: B-Spline Adaptive Tokenizer for Long-Term Time Series Forecasting",
      "content": "Long-term time series forecasting using transformers is hampered by the quadratic complexity of self-attention and the rigidity of uniform patching, which may be misaligned with the data's semantic structure. In this paper, we introduce the \\textit{B-Spline Adaptive Tokenizer (BSAT)}, a novel, parameter-free method that adaptively segments a time series by fitting it with B-splines. BSAT algorithmically places tokens in high-curvature regions and represents each variable-length basis function as a fixed-size token, composed of its coefficient and position. Further, we propose a hybrid positional encoding that combines a additive learnable positional encoding with Rotary Positional Embedding featuring a layer-wise learnable base: L-RoPE. This allows each layer to attend to different temporal dependencies. Our experiments on several public benchmarks show that our model is competitive with strong performance at high compression rates. This makes it particularly well-suited for use cases with strong memory constraints.",
      "url": "http://arxiv.org/abs/2601.00698",
      "author": "Maximilian Reinwardt, Michael Eichelbeck and Matthias Althoff",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces BSAT, a parameter-free B-spline based tokenizer for time series that adaptively segments by curvature, combined with L-RoPE positional encoding. Addresses misalignment between uniform patching and semantic structure in time series transformers.",
      "importance_score": 55,
      "reasoning": "Novel approach to time series tokenization addressing real limitations of uniform patching. Parameter-free design is attractive. The combination with learnable RoPE is interesting. Moderate contribution to time series forecasting.",
      "themes": [
        "Time Series Forecasting",
        "Transformers",
        "Tokenization"
      ],
      "continuation": null
    },
    {
      "id": "9c9beac975e4",
      "title": "Stochastic Actor-Critic: Mitigating Overestimation via Temporal Aleatoric Uncertainty",
      "content": "Off-policy actor-critic methods in reinforcement learning train a critic with temporal-difference updates and use it as a learning signal for the policy (actor). This design typically achieves higher sample efficiency than purely on-policy methods. However, critic networks tend to overestimate value estimates systematically. This is often addressed by introducing a pessimistic bias based on uncertainty estimates. Current methods employ ensembling to quantify the critic's epistemic uncertainty-uncertainty due to limited data and model ambiguity-to scale pessimistic updates. In this work, we propose a new algorithm called Stochastic Actor-Critic (STAC) that incorporates temporal (one-step) aleatoric uncertainty-uncertainty arising from stochastic transitions, rewards, and policy-induced variability in Bellman targets-to scale pessimistic bias in temporal-difference updates, rather than relying on epistemic uncertainty. STAC uses a single distributional critic network to model the temporal return uncertainty, and applies dropout to both the critic and actor networks for regularization. Our results show that pessimism based on a distributional critic alone suffices to mitigate overestimation, and naturally leads to risk-averse behavior in stochastic environments. Introducing dropout further improves training stability and performance by means of regularization. With this design, STAC achieves improved computational efficiency using a single distributional critic network.",
      "url": "http://arxiv.org/abs/2601.00737",
      "author": "U\\u{g}urcan \\\"Ozalp",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes Stochastic Actor-Critic (STAC), addressing value overestimation in off-policy methods by incorporating temporal aleatoric uncertainty rather than just epistemic uncertainty from ensembles.",
      "importance_score": 55,
      "reasoning": "Novel perspective distinguishing aleatoric from epistemic uncertainty for critic pessimism. Sound theoretical motivation. Contributes to important problem of value overestimation in actor-critic methods.",
      "themes": [
        "Reinforcement Learning",
        "Actor-Critic Methods",
        "Uncertainty Quantification"
      ],
      "continuation": null
    },
    {
      "id": "74fe7989e5ca",
      "title": "Four Downsides of Training Policies Online",
      "content": "In order to control an AI model's worst-case performance, we need to understand its generalization properties to situations where it hasn't been trained. It seems plausible that powerful AI models will Fake Alignment and then generalize poorly, causing a catastrophe before training removes this behavior from the AI. A pretty key part of the hope for diffuse control is the fact, discussed by Paul Christiano here , that if models are trained online, then their average case performance should be acceptable. Thus, online training is seen as a key technique in diffuse control. In this short post, I'd like to bring up four downsides of training policies online (these downsides are less relevant to online training of monitors). I don't think these downsides are a knockdown argument against online training; on the contrary, I expect some kind of online training to be desirable. However, these considerations might inform what exactly the online training that we do should look like. I'll abbreviate \"training policies online\" to \"TPO\". Thanks to Eric Gan for telling me about consideration 1. I heard about considerations 2-4 from Ryan Greenblatt's writing. Thanks to Alexa Pan for running a writing exercise that inspired me to write this short post. Considerations against TPO 1: If you do TPO, you can't always have audited the deployed model TPO means you don’t get to audit the model that’s actually deployed. It is currently a somewhat common practice for AI companies to do evaluations of their model's behavior before external deployment. In the future, models will hopefully be audited prior to internal deployments and during training (and some AI labs might already do this). However, if we do TPO, the model changes over the course of the deployment. There are two particularly concerning ways that models might change: Capability jumps: sometimes, models suddenly gain new capabilities during training, when they grok a new task. This means that stale evaluations might importantly ...",
      "url": "https://www.lesswrong.com/posts/LdgtPNxSsmMFhZPn6/four-downsides-of-training-policies-online",
      "author": "Alek Westover",
      "published": "2026-01-03T22:17:55.698000",
      "source": "LessWrong",
      "source_type": "research_blog",
      "tags": [],
      "summary": "Discusses four downsides of training AI policies online for diffuse control: potential for deceptive generalization before training corrects it, optimization during deployment risks, capability elicitation concerns, and distributional shift.",
      "importance_score": 55,
      "reasoning": "Useful enumeration of considerations for online policy training in AI control. References Paul Christiano's work. Brief but points to important tradeoffs in AI safety approaches.",
      "themes": [
        "AI Safety",
        "AI Alignment",
        "AI Control",
        "Online Learning"
      ],
      "continuation": null
    },
    {
      "id": "3a68cf4e94df",
      "title": "Modeling Day-Long ECG Signals to Predict Heart Failure Risk with Explainable AI",
      "content": "Heart failure (HF) affects 11.8% of adults aged 65 and older, reducing quality of life and longevity. Preventing HF can reduce morbidity and mortality. We hypothesized that artificial intelligence (AI) applied to 24-hour single-lead electrocardiogram (ECG) data could predict the risk of HF within five years. To research this, the Technion-Leumit Holter ECG (TLHE) dataset, including 69,663 recordings from 47,729 patients, collected over 20 years was used. Our deep learning model, DeepHHF, trained on 24-hour ECG recordings, achieved an area under the receiver operating characteristic curve of 0.80 that outperformed a model using 30-second segments and a clinical score. High-risk individuals identified by DeepHHF had a two-fold chance of hospitalization or death incidents. Explainability analysis showed DeepHHF focused on arrhythmias and heart abnormalities, with key attention between 8 AM and 3 PM. This study highlights the feasibility of deep learning to model 24-hour continuous ECG data, capturing paroxysmal events and circadian variations essential for reliable risk prediction. Artificial intelligence applied to single-lead Holter ECG is non-invasive, inexpensive, and widely accessible, making it a promising tool for HF risk prediction.",
      "url": "http://arxiv.org/abs/2601.00014",
      "author": "Eran Zvuloni, Ronit Almog, Michael Glikson, Shany Brimer Biton, Ilan Green, Izhar Laufer, Offer Amir, and Joachim A. Behar",
      "published": "2026-01-05",
      "source": "arXiv (eess.SP)",
      "source_type": "arxiv",
      "tags": [
        "eess.SP"
      ],
      "summary": "Develops DeepHHF, a deep learning model trained on 24-hour ECG recordings to predict 5-year heart failure risk, achieving AUC of 0.80. Uses large dataset of 69,663 recordings with explainability analysis.",
      "importance_score": 54,
      "reasoning": "Clinically relevant AI application with large-scale validation. Solid methodology and interpretability, though AUC performance is moderate.",
      "themes": [
        "Healthcare AI",
        "ECG Analysis",
        "Predictive Medicine",
        "Explainable AI"
      ],
      "continuation": null
    },
    {
      "id": "af40e3d40d93",
      "title": "Learning Speech Representations with Variational Predictive Coding",
      "content": "Despite being the best known objective for learning speech representations, the HuBERT objective has not been further developed and improved. We argue that it is the lack of an underlying principle that stalls the development, and, in this paper, we show that predictive coding under a variational view is the principle behind the HuBERT objective. Due to its generality, our formulation provides opportunities to improve parameterization and optimization, and we show two simple modifications that bring immediate improvements to the HuBERT objective. In addition, the predictive coding formulation has tight connections to various other objectives, such as APC, CPC, wav2vec, and BEST-RQ. Empirically, the improvement in pre-training brings significant improvements to four downstream tasks: phone classification, f0 tracking, speaker recognition, and automatic speech recognition, highlighting the importance of the predictive coding interpretation.",
      "url": "http://arxiv.org/abs/2601.00100",
      "author": "Sung-Lin Yeh, Peter Bell, Hao Tang",
      "published": "2026-01-05",
      "source": "arXiv (eess.AS)",
      "source_type": "arxiv",
      "tags": [
        "eess.AS"
      ],
      "summary": "Shows that predictive coding under a variational view underlies the HuBERT objective for speech representation learning. Provides two modifications that improve pre-training performance on four downstream tasks.",
      "importance_score": 54,
      "reasoning": "Provides principled understanding of successful speech SSL method. Practical improvements with theoretical grounding.",
      "themes": [
        "Speech Processing",
        "Self-Supervised Learning",
        "Representation Learning"
      ],
      "continuation": null
    },
    {
      "id": "6a13aa16dc3e",
      "title": "MorphAny3D: Unleashing the Power of Structured Latent in 3D Morphing",
      "content": "3D morphing remains challenging due to the difficulty of generating semantically consistent and temporally smooth deformations, especially across categories. We present MorphAny3D, a training-free framework that leverages Structured Latent (SLAT) representations for high-quality 3D morphing. Our key insight is that intelligently blending source and target SLAT features within the attention mechanisms of 3D generators naturally produces plausible morphing sequences. To this end, we introduce Morphing Cross-Attention (MCA), which fuses source and target information for structural coherence, and Temporal-Fused Self-Attention (TFSA), which enhances temporal consistency by incorporating features from preceding frames. An orientation correction strategy further mitigates the pose ambiguity within the morphing steps. Extensive experiments show that our method generates state-of-the-art morphing sequences, even for challenging cross-category cases. MorphAny3D further supports advanced applications such as decoupled morphing and 3D style transfer, and can be generalized to other SLAT-based generative models. Project page: https://xiaokunsun.github.io/MorphAny3D.github.io/.",
      "url": "http://arxiv.org/abs/2601.00204",
      "author": "Xiaokun Sun, Zeyu Cai, Hao Tang, Ying Tai, Jian Yang, Zhenyu Zhang",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Presents MorphAny3D, training-free framework for 3D morphing using Structured Latent (SLAT) representations. Introduces Morphing Cross-Attention and Temporal-Fused Self-Attention for coherent cross-category morphing.",
      "importance_score": 54,
      "reasoning": "Novel approach to 3D morphing without training. Clever use of attention mechanisms for temporal consistency.",
      "themes": [
        "3D Generation",
        "Morphing",
        "Attention Mechanisms"
      ],
      "continuation": null
    },
    {
      "id": "03d7f114aab2",
      "title": "Rectifying Adversarial Examples Using Their Vulnerabilities",
      "content": "Deep neural network-based classifiers are prone to errors when processing adversarial examples (AEs). AEs are minimally perturbed input data undetectable to humans posing significant risks to security-dependent applications. Hence, extensive research has been undertaken to develop defense mechanisms that mitigate their threats. Most existing methods primarily focus on discriminating AEs based on the input sample features, emphasizing AE detection without addressing the correct sample categorization before an attack. While some tasks may only require mere rejection on detected AEs, others necessitate identifying the correct original input category such as traffic sign recognition in autonomous driving. The objective of this study is to propose a method for rectifying AEs to estimate the correct labels of their original inputs. Our method is based on re-attacking AEs to move them beyond the decision boundary for accurate label prediction, effectively addressing the issue of rectifying minimally perceptible AEs created using white-box attack methods. However, challenge remains with respect to effectively rectifying AEs produced by black-box attacks at a distance from the boundary, or those misclassified into low-confidence categories by targeted attacks. By adopting a straightforward approach of only considering AEs as inputs, the proposed method can address diverse attacks while avoiding the requirement of parameter adjustments or preliminary training. Results demonstrate that the proposed method exhibits consistent performance in rectifying AEs generated via various attack methods, including targeted and black-box attacks. Moreover, it outperforms conventional rectification and input transformation methods in terms of stability against various attacks.",
      "url": "http://arxiv.org/abs/2601.00270",
      "author": "Fumiya Morimoto, Ryuto Morita, Satoshi Ono",
      "published": "2026-01-05",
      "source": "arXiv (cs.CR)",
      "source_type": "arxiv",
      "tags": [
        "cs.CR"
      ],
      "summary": "Proposes method to rectify adversarial examples rather than just detecting them, aiming to recover correct classifications by exploiting vulnerabilities in the adversarial perturbations.",
      "importance_score": 54,
      "reasoning": "Novel framing of adversarial defense as rectification rather than detection. Practical but incremental contribution.",
      "themes": [
        "Adversarial Robustness",
        "Deep Learning Security"
      ],
      "continuation": null
    },
    {
      "id": "524c2fd80502",
      "title": "Quantum King-Ring Domination in Chess: A QAOA Approach",
      "content": "The Quantum Approximate Optimization Algorithm (QAOA) is extensively benchmarked on synthetic random instances such as MaxCut, TSP, and SAT problems, but these lack semantic structure and human interpretability, offering limited insight into performance on real-world problems with meaningful constraints. We introduce Quantum King-Ring Domination (QKRD), a NISQ-scale benchmark derived from chess tactical positions that provides 5,000 structured instances with one-hot constraints, spatial locality, and 10--40 qubit scale. The benchmark pairs human-interpretable coverage metrics with intrinsic validation against classical heuristics, enabling algorithmic conclusions without external oracles. Using QKRD, we systematically evaluate QAOA design choices and find that constraint-preserving mixers (XY, domain-wall) converge approximately 13 steps faster than standard mixers (p<10^{-7}, d\\approx0.5) while eliminating penalty tuning, warm-start strategies reduce convergence by 45 steps (p<10^{-127}, d=3.35) with energy improvements exceeding d=8, and Conditional Value-at-Risk (CVaR) optimization yields an informative negative result with worse energy (p<10^{-40}, d=1.21) and no coverage benefit. Intrinsic validation shows QAOA outperforms greedy heuristics by 12.6\\% and random selection by 80.1\\%. Our results demonstrate that structured benchmarks reveal advantages of problem-informed QAOA techniques obscured in random instances. We release all code, data, and experimental artifacts for reproducible NISQ algorithm research.",
      "url": "http://arxiv.org/abs/2601.00318",
      "author": "Gerhard Stenzel and Michael K\\\"olle and Tobias Rohe and Julian Hager and Leo S\\\"unkel and Maximilian Zorn and Claudia Linnhoff-Popien",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces QKRD, a QAOA benchmark derived from chess king-ring domination problems providing 5,000 structured instances with human-interpretable metrics for quantum algorithm evaluation.",
      "importance_score": 54,
      "reasoning": "Novel benchmark approach using semantically meaningful chess problems for quantum computing. Addresses limitation of synthetic random instances.",
      "themes": [
        "Quantum Computing",
        "Benchmarks",
        "QAOA"
      ],
      "continuation": null
    },
    {
      "id": "ef12680785c8",
      "title": "OmniVaT: Single Domain Generalization for Multimodal Visual-Tactile Learning",
      "content": "Visual-tactile learning (VTL) enables embodied agents to perceive the physical world by integrating visual (VIS) and tactile (TAC) sensors. However, VTL still suffers from modality discrepancies between VIS and TAC images, as well as domain gaps caused by non-standardized tactile sensors and inconsistent data collection procedures. We formulate these challenges as a new task, termed single domain generalization for multimodal VTL (SDG-VTL). In this paper, we propose an OmniVaT framework that, for the first time, successfully addresses this task. On the one hand, OmniVaT integrates a multimodal fractional Fourier adapter (MFFA) to map VIS and TAC embeddings into a unified embedding-frequency space, thereby effectively mitigating the modality gap without multi-domain training data or careful cross-modal fusion strategies. On the other hand, it also incorporates a discrete tree generation (DTG) module that obtains diverse and reliable multimodal fractional representations through a hierarchical tree structure, thereby enhancing its adaptivity to fluctuating domain shifts in unseen domains. Extensive experiments demonstrate the superior cross-domain generalization performance of OmniVaT on the SDG-VTL task.",
      "url": "http://arxiv.org/abs/2601.00352",
      "author": "Liuxiang Qiu, Hui Da, Yuzhen Niu, Tiesong Zhao, Yang Cao, Zheng-Jun Zha",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes OmniVaT for single domain generalization in visual-tactile learning using multimodal fractional Fourier adapter to map visual and tactile embeddings to unified space.",
      "importance_score": 54,
      "reasoning": "Novel approach to multimodal robotics learning addressing sensor heterogeneity.",
      "themes": [
        "Multimodal Learning",
        "Robotics",
        "Domain Generalization"
      ],
      "continuation": null
    },
    {
      "id": "3fc331a0cbf1",
      "title": "FreeText: Training-Free Text Rendering in Diffusion Transformers via Attention Localization and Spectral Glyph Injection",
      "content": "Large-scale text-to-image (T2I) diffusion models excel at open-domain synthesis but still struggle with precise text rendering, especially for multi-line layouts, dense typography, and long-tailed scripts such as Chinese. Prior solutions typically require costly retraining or rigid external layout constraints, which can degrade aesthetics and limit flexibility. We propose \\textbf{FreeText}, a training-free, plug-and-play framework that improves text rendering by exploiting intrinsic mechanisms of \\emph{Diffusion Transformer (DiT)} models. \\textbf{FreeText} decomposes the problem into \\emph{where to write} and \\emph{what to write}. For \\emph{where to write}, we localize writing regions by reading token-wise spatial attribution from endogenous image-to-text attention, using sink-like tokens as stable spatial anchors and topology-aware refinement to produce high-confidence masks. For \\emph{what to write}, we introduce Spectral-Modulated Glyph Injection (SGMI), which injects a noise-aligned glyph prior with frequency-domain band-pass modulation to strengthen glyph structure and suppress semantic leakage (rendering the concept instead of the word). Extensive experiments on Qwen-Image, FLUX.1-dev, and SD3 variants across longText-Benchmark, CVTG, and our CLT-Bench show consistent gains in text readability while largely preserving semantic alignment and aesthetic quality, with modest inference overhead.",
      "url": "http://arxiv.org/abs/2601.00535",
      "author": "Ruiqiang Zhang, Hengyi Wang, Chang Liu, Guanjie Wang, Zehua Ma, Weiming Zhang",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes FreeText, a training-free framework for text rendering in Diffusion Transformers by localizing writing regions through attention and injecting spectral glyph information.",
      "importance_score": 54,
      "reasoning": "Addresses persistent challenge in text-to-image generation. Training-free approach is practical. Novel decomposition into 'where' and 'what' to write.",
      "themes": [
        "Text-to-Image",
        "Diffusion Models",
        "Text Rendering"
      ],
      "continuation": null
    },
    {
      "id": "178093bcf223",
      "title": "HFedMoE: Resource-aware Heterogeneous Federated Learning with Mixture-of-Experts",
      "content": "While federated learning (FL) enables fine-tuning of large language models (LLMs) without compromising data privacy, the substantial size of an LLM renders on-device training impractical for resource-constrained clients, such as mobile devices. Thus, Mixture-of-Experts (MoE) models have emerged as a computation-efficient solution, which activates only a sparse subset of experts during model training to reduce computing burden without sacrificing performance. Though integrating MoE into FL fine-tuning holds significant potential, it still encounters three key challenges: i) selecting appropriate experts for clients remains challenging due to the lack of a reliable metric to measure each expert's impact on local fine-tuning performance, ii) the heterogeneous computing resources across clients severely hinder MoE-based LLM fine-tuning, as dynamic expert activations across diverse input samples can overwhelm resource-constrained devices, and iii) client-specific expert subsets and routing preference undermine global aggregation, where misaligned expert updates and inconsistent gating networks in troduce destructive interference. To address these challenges, we propose HFedMoE, a heterogeneous MoE-based FL fine-tuning framework that customizes a subset of experts to each client for computation-efficient LLM fine-tuning. Specifically, HFedMoE identifies the expert importance based on its contributions to fine-tuning performance, and then adaptively selects a subset of experts from an information bottleneck perspective to align with each client' s computing budget. A sparsity-aware model aggregation strategy is also designed to aggregate the actively fine-tuned experts and gating parameters with importance weighted contributions. Extensive experiments demonstrate that HFedMoE outperforms state-of-the-art benchmarks in training accuracy and convergence speed.",
      "url": "http://arxiv.org/abs/2601.00583",
      "author": "Zihan Fang, Zheng Lin, Senkang Hu, Yanan Ma, Yihang Tao, Yiqin Deng, Xianhao Chen, Yuguang Fang",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes HFedMoE combining Mixture-of-Experts with federated learning for resource-aware LLM fine-tuning, using influence scores for expert selection and adaptive aggregation for heterogeneous clients.",
      "importance_score": 54,
      "reasoning": "Addresses important practical challenge of FL with resource heterogeneity. Novel combination of MoE and FL. Solid methodology.",
      "themes": [
        "Federated Learning",
        "Mixture-of-Experts",
        "Efficient AI",
        "Language Models"
      ],
      "continuation": null
    },
    {
      "id": "1977d38d7ffc",
      "title": "Do Chatbot LLMs Talk Too Much? The YapBench Benchmark",
      "content": "Large Language Models (LLMs) such as ChatGPT, Claude, and Gemini increasingly act as general-purpose copilots, yet they often respond with unnecessary length on simple requests, adding redundant explanations, hedging, or boilerplate that increases cognitive load and inflates token-based inference cost. Prior work suggests that preference-based post-training and LLM-judged evaluations can induce systematic length bias, where longer answers are rewarded even at comparable quality.   We introduce YapBench, a lightweight benchmark for quantifying user-visible over-generation on brevity-ideal prompts. Each item consists of a single-turn prompt, a curated minimal-sufficient baseline answer, and a category label. Our primary metric, YapScore, measures excess response length beyond the baseline in characters, enabling comparisons across models without relying on any specific tokenizer. We summarize model performance via the YapIndex, a uniformly weighted average of category-level median YapScores.   YapBench contains over three hundred English prompts spanning three common brevity-ideal settings: (A) minimal or ambiguous inputs where the ideal behavior is a short clarification, (B) closed-form factual questions with short stable answers, and (C) one-line coding tasks where a single command or snippet suffices. Evaluating 76 assistant LLMs, we observe an order-of-magnitude spread in median excess length and distinct category-specific failure modes, including vacuum-filling on ambiguous inputs and explanation or formatting overhead on one-line technical requests. We release the benchmark and maintain a live leaderboard for tracking verbosity behavior over time.",
      "url": "http://arxiv.org/abs/2601.00624",
      "author": "Vadim Borisov, Michael Gr\\\"oger, Mina Mikhael, Richard H. Schreiber",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces YapBench for measuring LLM verbosity on brevity-ideal prompts using YapScore metric measuring excess length beyond minimal-sufficient baseline. Tests multiple chatbot LLMs.",
      "importance_score": 54,
      "reasoning": "Addresses practical annoyance and cost issue with LLM over-generation. Novel benchmark for underexplored problem. Useful for deployment optimization.",
      "themes": [
        "Benchmarks",
        "Language Models",
        "Evaluation",
        "Efficiency"
      ],
      "continuation": null
    },
    {
      "id": "e0b5e2ff1e41",
      "title": "ARISE: Adaptive Reinforcement Integrated with Swarm Exploration",
      "content": "Effective exploration remains a key challenge in RL, especially with non-stationary rewards or high-dimensional policies. We introduce ARISE, a lightweight framework that enhances reinforcement learning by augmenting standard policy-gradient methods with a compact swarm-based exploration layer. ARISE blends policy actions with particle-driven proposals, where each particle represents a candidate policy trajectory sampled in the action space, and modulates exploration adaptively using reward-variance cues. While easy benchmarks exhibit only slight improvements (e.g., +0.7% on CartPole-v1), ARISE yields substantial gains on more challenging tasks, including +46% on LunarLander-v3 and +22% on Hopper-v4, while preserving stability on Walker2d and Ant. Under non-stationary reward shifts, ARISE provides marked robustness advantages, outperforming PPO by +75 points on CartPole and improving LunarLander accordingly. Ablation studies confirm that both the swarm component and the adaptive mechanism contribute to the performance. Overall, ARISE offers a simple, architecture-agnostic route to more exploratory and resilient RL agents without altering core algorithmic structures.",
      "url": "http://arxiv.org/abs/2601.00693",
      "author": "Rajiv Chaitanya M and D R Ramesh Babu",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes ARISE, a framework combining reinforcement learning with swarm-based exploration using particle-driven proposals and reward-variance adaptive exploration. Shows substantial gains on challenging tasks like LunarLander (+46%) and Hopper (+22%).",
      "importance_score": 54,
      "reasoning": "Novel combination of swarm intelligence and RL for exploration. Significant improvements on some benchmarks. However, lightweight framework designation and mixed results across benchmarks suggest limited applicability.",
      "themes": [
        "Reinforcement Learning",
        "Exploration Methods",
        "Swarm Intelligence"
      ],
      "continuation": null
    },
    {
      "id": "d121f17ba0c5",
      "title": "RGS-SLAM: Robust Gaussian Splatting SLAM with One-Shot Dense Initialization",
      "content": "We introduce RGS-SLAM, a robust Gaussian-splatting SLAM framework that replaces the residual-driven densification stage of GS-SLAM with a training-free correspondence-to-Gaussian initialization. Instead of progressively adding Gaussians as residuals reveal missing geometry, RGS-SLAM performs a one-shot triangulation of dense multi-view correspondences derived from DINOv3 descriptors refined through a confidence-aware inlier classifier, generating a well-distributed and structure-aware Gaussian seed prior to optimization. This initialization stabilizes early mapping and accelerates convergence by roughly 20\\%, yielding higher rendering fidelity in texture-rich and cluttered scenes while remaining fully compatible with existing GS-SLAM pipelines. Evaluated on the TUM RGB-D and Replica datasets, RGS-SLAM achieves competitive or superior localization and reconstruction accuracy compared with state-of-the-art Gaussian and point-based SLAM systems, sustaining real-time mapping performance at up to 925 FPS.",
      "url": "http://arxiv.org/abs/2601.00705",
      "author": "Wei-Tse Cheng, Yen-Jen Chiou, Yuan-Fu Yang",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes RGS-SLAM, improving Gaussian Splatting SLAM with one-shot dense initialization using DINOv3 descriptors instead of progressive residual-based densification. Achieves ~20% faster convergence with improved rendering quality.",
      "importance_score": 54,
      "reasoning": "Solid engineering contribution to GS-SLAM pipeline. Training-free initialization is practical. The use of DINOv3 for correspondence is sensible. Incremental but useful improvement to active research area.",
      "themes": [
        "SLAM",
        "3D Gaussian Splatting",
        "Visual Localization"
      ],
      "continuation": null
    },
    {
      "id": "33157cc1dadc",
      "title": "Memory Bank Compression for Continual Adaptation of Large Language Models",
      "content": "Large Language Models (LLMs) have become a mainstay for many everyday applications. However, as data evolve their knowledge quickly becomes outdated. Continual learning aims to update LLMs with new information without erasing previously acquired knowledge. Although methods such as full fine-tuning can incorporate new data, they are computationally expensive and prone to catastrophic forgetting, where prior knowledge is overwritten. Memory-augmented approaches address this by equipping LLMs with a memory bank, that is an external memory module which stores information for future use. However, these methods face a critical limitation, in particular, the memory bank constantly grows in the real-world scenario when large-scale data streams arrive. In this paper, we propose MBC, a model that compresses the memory bank through a codebook optimization strategy during online adaptation learning. To ensure stable learning, we also introduce an online resetting mechanism that prevents codebook collapse. In addition, we employ Key-Value Low-Rank Adaptation in the attention layers of the LLM, enabling efficient utilization of the compressed memory representations. Experiments with benchmark question-answering datasets demonstrate that MBC reduces the memory bank size to 0.3% when compared against the most competitive baseline, while maintaining high retention accuracy during online adaptation learning. Our code is publicly available at https://github.com/Thomkat/MBC.",
      "url": "http://arxiv.org/abs/2601.00756",
      "author": "Thomas Katraouras, Dimitrios Rafailidis",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes MBC for compressing memory banks in continual learning for LLMs, addressing the challenge of unbounded memory growth when large-scale data streams arrive in real-world deployment.",
      "importance_score": 54,
      "reasoning": "Addresses practical limitation of memory-augmented continual learning approaches. Important for real-world LLM deployment. Modest novelty but practical contribution.",
      "themes": [
        "Continual Learning",
        "Language Models",
        "Memory-Augmented Learning",
        "Efficiency"
      ],
      "continuation": null
    },
    {
      "id": "231d840e496e",
      "title": "AdaGaR: Adaptive Gabor Representation for Dynamic Scene Reconstruction",
      "content": "Reconstructing dynamic 3D scenes from monocular videos requires simultaneously capturing high-frequency appearance details and temporally continuous motion. Existing methods using single Gaussian primitives are limited by their low-pass filtering nature, while standard Gabor functions introduce energy instability. Moreover, lack of temporal continuity constraints often leads to motion artifacts during interpolation. We propose AdaGaR, a unified framework addressing both frequency adaptivity and temporal continuity in explicit dynamic scene modeling. We introduce Adaptive Gabor Representation, extending Gaussians through learnable frequency weights and adaptive energy compensation to balance detail capture and stability. For temporal continuity, we employ Cubic Hermite Splines with Temporal Curvature Regularization to ensure smooth motion evolution. An Adaptive Initialization mechanism combining depth estimation, point tracking, and foreground masks establishes stable point cloud distributions in early training. Experiments on Tap-Vid DAVIS demonstrate state-of-the-art performance (PSNR 35.49, SSIM 0.9433, LPIPS 0.0723) and strong generalization across frame interpolation, depth consistency, video editing, and stereo view synthesis. Project page: https://jiewenchan.github.io/AdaGaR/",
      "url": "http://arxiv.org/abs/2601.00796",
      "author": "Jiewen Chan, Zhenjun Zhao, Yu-Lun Liu",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Introduces AdaGaR, using Adaptive Gabor Representation with learnable frequency weights and Cubic Hermite Splines for temporal continuity in dynamic 3D scene reconstruction from monocular video.",
      "importance_score": 54,
      "reasoning": "Novel representation extending Gaussians with frequency adaptivity for dynamic scenes. Addresses important temporal consistency challenge. Solid contribution to dynamic scene reconstruction.",
      "themes": [
        "Dynamic Scene Reconstruction",
        "3D Gaussian Splatting",
        "Novel View Synthesis"
      ],
      "continuation": null
    },
    {
      "id": "02d6417e547b",
      "title": "Sparse Probabilistic Coalition Structure Generation: Bayesian Greedy Pursuit and $\\ell_1$ Relaxations",
      "content": "We study coalition structure generation (CSG) when coalition values are not given but must be learned from episodic observations. We model each episode as a sparse linear regression problem, where the realised payoff \\(Y_t\\) is a noisy linear combination of a small number of coalition contributions. This yields a probabilistic CSG framework in which the planner first estimates a sparse value function from \\(T\\) episodes, then runs a CSG solver on the inferred coalition set. We analyse two estimation schemes. The first, Bayesian Greedy Coalition Pursuit (BGCP), is a greedy procedure that mimics orthogonal matching pursuit. Under a coherence condition and a minimum signal assumption, BGCP recovers the true set of profitable coalitions with high probability once \\(T \\gtrsim K \\log m\\), and hence yields welfare-optimal structures. The second scheme uses an \\(\\ell_1\\)-penalised estimator; under a restricted eigenvalue condition, we derive \\(\\ell_1\\) and prediction error bounds and translate them into welfare gap guarantees. We compare both methods to probabilistic baselines and identify regimes where sparse probabilistic CSG is superior, as well as dense regimes where classical least-squares approaches are competitive.",
      "url": "http://arxiv.org/abs/2601.00329",
      "author": "Angshul Majumdar",
      "published": "2026-01-05",
      "source": "arXiv (cs.GT)",
      "source_type": "arxiv",
      "tags": [
        "cs.GT"
      ],
      "summary": "Studies coalition structure generation with sparse linear regression framework using Bayesian Greedy Coalition Pursuit. Proves recovery guarantees and derives regret bounds.",
      "importance_score": 53,
      "reasoning": "Theoretical contribution to game-theoretic problem with rigorous analysis.",
      "themes": [
        "Game Theory",
        "Sparse Estimation",
        "Coalition Formation"
      ],
      "continuation": null
    },
    {
      "id": "b7dc4001090a",
      "title": "PatchBlock: A Lightweight Defense Against Adversarial Patches for Embedded EdgeAI Devices",
      "content": "Adversarial attacks pose a significant challenge to the reliable deployment of machine learning models in EdgeAI applications, such as autonomous driving and surveillance, which rely on resource-constrained devices for real-time inference. Among these, patch-based adversarial attacks, where small malicious patches (e.g., stickers) are applied to objects, can deceive neural networks into making incorrect predictions with potentially severe consequences. In this paper, we present PatchBlock, a lightweight framework designed to detect and neutralize adversarial patches in images. Leveraging outlier detection and dimensionality reduction, PatchBlock identifies regions affected by adversarial noise and suppresses their impact. It operates as a pre-processing module at the sensor level, efficiently running on CPUs in parallel with GPU inference, thus preserving system throughput while avoiding additional GPU overhead. The framework follows a three-stage pipeline: splitting the input into chunks (Chunking), detecting anomalous regions via a redesigned isolation forest with targeted cuts for faster convergence (Separating), and applying dimensionality reduction on the identified outliers (Mitigating). PatchBlock is both model- and patch-agnostic, can be retrofitted to existing pipelines, and integrates seamlessly between sensor inputs and downstream models. Evaluations across multiple neural architectures, benchmark datasets, attack types, and diverse edge devices demonstrate that PatchBlock consistently improves robustness, recovering up to 77% of model accuracy under strong patch attacks such as the Google Adversarial Patch, while maintaining high portability and minimal clean accuracy loss. Additionally, PatchBlock outperforms the state-of-the-art defenses in efficiency, in terms of computation time and energy consumption per sample, making it suitable for EdgeAI applications.",
      "url": "http://arxiv.org/abs/2601.00367",
      "author": "Nandish Chattopadhyay, Abdul Basit, Amira Guesmi, Muhammad Abdullah Hanif, Bassem Ouni, Muhammad Shafique",
      "published": "2026-01-05",
      "source": "arXiv (cs.CR)",
      "source_type": "arxiv",
      "tags": [
        "cs.CR"
      ],
      "summary": "Presents PatchBlock, a lightweight framework for detecting and neutralizing adversarial patches on edge devices using outlier detection and dimensionality reduction.",
      "importance_score": 53,
      "reasoning": "Practical defense for resource-constrained devices but limited novelty in techniques.",
      "themes": [
        "Adversarial Defense",
        "Edge AI",
        "Security"
      ],
      "continuation": null
    },
    {
      "id": "3141bc870de8",
      "title": "Toward Better Temporal Structures for Geopolitical Events Forecasting",
      "content": "Forecasting on geopolitical temporal knowledge graphs (TKGs) through the lens of large language models (LLMs) has recently gained traction. While TKGs and their generalization, hyper-relational temporal knowledge graphs (HTKGs), offer a straightforward structure to represent simple temporal relationships, they lack the expressive power to convey complex facts efficiently. One of the critical limitations of HTKGs is a lack of support for more than two primary entities in temporal facts, which commonly occur in real-world events. To address this limitation, in this work, we study a generalization of HTKGs, Hyper-Relational Temporal Knowledge Generalized Hypergraphs (HTKGHs). We first derive a formalization for HTKGHs, demonstrating their backward compatibility while supporting two complex types of facts commonly found in geopolitical incidents. Then, utilizing this formalization, we introduce the htkgh-polecat dataset, built upon the global event database POLECAT. Finally, we benchmark and analyze popular LLMs on the relation prediction task, providing insights into their adaptability and capabilities in complex forecasting scenarios.",
      "url": "http://arxiv.org/abs/2601.00430",
      "author": "Kian Ahrabian, Eric Boxer, Jay Pujara",
      "published": "2026-01-05",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes Hyper-Relational Temporal Knowledge Generalized Hypergraphs (HTKGHs) for geopolitical forecasting, extending temporal knowledge graphs to support more than two primary entities.",
      "importance_score": 53,
      "reasoning": "Addresses limitation in temporal knowledge representation for forecasting. Useful formalization.",
      "themes": [
        "Knowledge Graphs",
        "Temporal Reasoning",
        "Forecasting"
      ],
      "continuation": null
    },
    {
      "id": "ff127d468925",
      "title": "Laplacian Kernelized Bandit",
      "content": "We study multi-user contextual bandits where users are related by a graph and their reward functions exhibit both non-linear behavior and graph homophily. We introduce a principled joint penalty for the collection of user reward functions $\\{f_u\\}$, combining a graph smoothness term based on RKHS distances with an individual roughness penalty. Our central contribution is proving that this penalty is equivalent to the squared norm within a single, unified \\emph{multi-user RKHS}. We explicitly derive its reproducing kernel, which elegantly fuses the graph Laplacian with the base arm kernel. This unification allows us to reframe the problem as learning a single ''lifted'' function, enabling the design of principled algorithms, \\texttt{LK-GP-UCB} and \\texttt{LK-GP-TS}, that leverage Gaussian Process posteriors over this new kernel for exploration. We provide high-probability regret bounds that scale with an \\emph{effective dimension} of the multi-user kernel, replacing dependencies on user count or ambient dimension. Empirically, our methods outperform strong linear and non-graph-aware baselines in non-linear settings and remain competitive even when the true rewards are linear. Our work delivers a unified, theoretically grounded, and practical framework that bridges Laplacian regularization with kernelized bandits for structured exploration.",
      "url": "http://arxiv.org/abs/2601.00461",
      "author": "Shuang Wu, Arash A. Amini",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes multi-user kernelized bandits combining graph smoothness with RKHS penalties, deriving a unified multi-user RKHS with kernel fusing graph Laplacian and arm kernel. Enables principled GP-UCB and GP-TS algorithms.",
      "importance_score": 53,
      "reasoning": "Solid theoretical contribution to multi-user bandits with graph structure. Elegant mathematical unification but practical impact may be limited.",
      "themes": [
        "Bandits",
        "Gaussian Processes",
        "Graph Learning",
        "Theory"
      ],
      "continuation": null
    },
    {
      "id": "c772cec094a4",
      "title": "Entropy Production in Machine Learning Under Fokker-Planck Probability Flow",
      "content": "Machine learning models deployed in nonstationary environments experience performance degradation due to data drift. While many drift detection heuristics exist, most lack a principled dynamical interpretation and provide limited guidance on how retraining frequency should be balanced against operational cost. In this work, we propose an entropy--based retraining framework grounded in nonequilibrium stochastic dynamics. Modeling deployment--time data drift as probability flow governed by a Fokker--Planck equation, we quantify model--data mismatch using a time--evolving Kullback--Leibler divergence. We show that the time derivative of this mismatch admits an entropy--balance decomposition featuring a nonnegative entropy production term driven by probability currents. This interpretation motivates entropy--triggered retraining as a label--free intervention strategy that responds to accumulated mismatch rather than delayed performance collapse. In a controlled nonstationary classification experiment, entropy--triggered retraining achieves predictive performance comparable to high--frequency retraining while reducing retraining events by an order of magnitude relative to daily and label--based policies.",
      "url": "http://arxiv.org/abs/2601.00554",
      "author": "Lennon Shikhman",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes entropy-based retraining framework for ML models under data drift, modeling deployment as Fokker-Planck probability flow and using entropy production to quantify model-data mismatch.",
      "importance_score": 53,
      "reasoning": "Novel theoretical framing of data drift using nonequilibrium thermodynamics. Provides principled approach to retraining decisions. Creative cross-disciplinary application.",
      "themes": [
        "Data Drift",
        "Model Maintenance",
        "Theory",
        "Statistical Physics"
      ],
      "continuation": null
    },
    {
      "id": "a64e21b31e9c",
      "title": "How Do Graph Signals Affect Recommendation: Unveiling the Mystery of Low and High-Frequency Graph Signals",
      "content": "Spectral graph neural networks (GNNs) are highly effective in modeling graph signals, with their success in recommendation often attributed to low-pass filtering. However, recent studies highlight the importance of high-frequency signals. The role of low-frequency and high-frequency graph signals in recommendation remains unclear. This paper aims to bridge this gap by investigating the influence of graph signals on recommendation performance. We theoretically prove that the effects of low-frequency and high-frequency graph signals are equivalent in recommendation tasks, as both contribute by smoothing the similarities between user-item pairs. To leverage this insight, we propose a frequency signal scaler, a plug-and-play module that adjusts the graph signal filter function to fine-tune the smoothness between user-item pairs, making it compatible with any GNN model. Additionally, we identify and prove that graph embedding-based methods cannot fully capture the characteristics of graph signals. To address this limitation, a space flip method is introduced to restore the expressive power of graph embeddings. Remarkably, we demonstrate that either low-frequency or high-frequency graph signals alone are sufficient for effective recommendations. Extensive experiments on four public datasets validate the effectiveness of our proposed methods. Code is avaliable at https://github.com/mojosey/SimGCF.",
      "url": "http://arxiv.org/abs/2512.15744",
      "author": "Feng Liu, Hao Cang, Huanhuan Yuan, Jiaqing Fan, Yongjing Hao, Fuzhen Zhuang, Guanfeng Liu, Pengpeng Zhao",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Theoretically proves that low-frequency and high-frequency graph signals have equivalent effects in GNN-based recommendations by both smoothing user-item similarities. Proposes a plug-and-play frequency signal scaler module based on this insight.",
      "importance_score": 52,
      "reasoning": "Provides theoretical insight into GNN behavior in recommendation systems. Novel analysis with practical module design, though impact limited to recommendation domain.",
      "themes": [
        "Graph Neural Networks",
        "Recommender Systems",
        "Spectral Analysis"
      ],
      "continuation": null
    },
    {
      "id": "6661c28b3149",
      "title": "IMBWatch -- a Spatio-Temporal Graph Neural Network approach to detect Illicit Massage Business",
      "content": "Illicit Massage Businesses (IMBs) are a covert and persistent form of organized exploitation that operate under the facade of legitimate wellness services while facilitating human trafficking, sexual exploitation, and coerced labor. Detecting IMBs is difficult due to encoded digital advertisements, frequent changes in personnel and locations, and the reuse of shared infrastructure such as phone numbers and addresses. Traditional approaches, including community tips and regulatory inspections, are largely reactive and ineffective at revealing the broader operational networks traffickers rely on.   To address these challenges, we introduce IMBWatch, a spatio-temporal graph neural network (ST-GNN) framework for large-scale IMB detection. IMBWatch constructs dynamic graphs from open-source intelligence, including scraped online advertisements, business license records, and crowdsourced reviews. Nodes represent heterogeneous entities such as businesses, aliases, phone numbers, and locations, while edges capture spatio-temporal and relational patterns, including co-location, repeated phone usage, and synchronized advertising. The framework combines graph convolutional operations with temporal attention mechanisms to model the evolution of IMB networks over time and space, capturing patterns such as intercity worker movement, burner phone rotation, and coordinated advertising surges.   Experiments on real-world datasets from multiple U.S. cities show that IMBWatch outperforms baseline models, achieving higher accuracy and F1 scores. Beyond performance gains, IMBWatch offers improved interpretability, providing actionable insights to support proactive and targeted interventions. The framework is scalable, adaptable to other illicit domains, and released with anonymized data and open-source code to support reproducible research.",
      "url": "http://arxiv.org/abs/2601.00075",
      "author": "Swetha Varadarajan, Abhishek Ray, Lumina Albert",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces IMBWatch, a spatio-temporal graph neural network for large-scale detection of Illicit Massage Businesses from open-source intelligence. Constructs dynamic graphs to reveal operational networks through shared infrastructure.",
      "importance_score": 52,
      "reasoning": "Novel application of ST-GNNs for important social issue (human trafficking). Practical impact potential but sensitive domain.",
      "themes": [
        "Graph Neural Networks",
        "Social Good AI",
        "Human Trafficking Detection"
      ],
      "continuation": null
    },
    {
      "id": "097444b77847",
      "title": "GRL-SNAM: Geometric Reinforcement Learning with Path Differential Hamiltonians for Simultaneous Navigation and Mapping in Unknown Environments",
      "content": "We present GRL-SNAM, a geometric reinforcement learning framework for Simultaneous Navigation and Mapping(SNAM) in unknown environments. A SNAM problem is challenging as it needs to design hierarchical or joint policies of multiple agents that control the movement of a real-life robot towards the goal in mapless environment, i.e. an environment where the map of the environment is not available apriori, and needs to be acquired through sensors. The sensors are invoked from the path learner, i.e. navigator, through active query responses to sensory agents, and along the motion path. GRL-SNAM differs from preemptive navigation algorithms and other reinforcement learning methods by relying exclusively on local sensory observations without constructing a global map. Our approach formulates path navigation and mapping as a dynamic shortest path search and discovery process using controlled Hamiltonian optimization: sensory inputs are translated into local energy landscapes that encode reachability, obstacle barriers, and deformation constraints, while policies for sensing, planning, and reconfiguration evolve stagewise via updating Hamiltonians. A reduced Hamiltonian serves as an adaptive score function, updating kinetic/potential terms, embedding barrier constraints, and continuously refining trajectories as new local information arrives. We evaluate GRL-SNAM on two different 2D navigation tasks. Comparing against local reactive baselines and global policy learning references under identical stagewise sensing constraints, it preserves clearance, generalizes to unseen layouts, and demonstrates that Geometric RL learning via updating Hamiltonians enables high-quality navigation through minimal exploration via local energy refinement rather than extensive global mapping. The code is publicly available on \\href{https://github.com/CVC-Lab/GRL-SNAM}{Github}.",
      "url": "http://arxiv.org/abs/2601.00116",
      "author": "Aditya Sai Ellendula and Yi Wang and Minh Nguyen and Chandrajit Bajaj",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces GRL-SNAM, geometric RL framework for simultaneous navigation and mapping using path differential Hamiltonians. Relies exclusively on local observations without global map construction.",
      "importance_score": 52,
      "reasoning": "Novel geometric approach to SNAM problem. Interesting theoretical framework but complex methodology with limited comparison to baselines.",
      "themes": [
        "Reinforcement Learning",
        "Navigation",
        "Geometric Learning",
        "Robotics"
      ],
      "continuation": null
    },
    {
      "id": "2f6cfd4db828",
      "title": "Explicit Abstention Knobs for Predictable Reliability in Video Question Answering",
      "content": "High-stakes deployment of vision-language models (VLMs) requires selective prediction, where systems abstain when uncertain rather than risk costly errors. We investigate whether confidence-based abstention provides reliable control over error rates in video question answering, and whether that control remains robust under distribution shift. Using NExT-QA and Gemini 2.0 Flash, we establish two findings. First, confidence thresholding provides mechanistic control in-distribution. Sweeping threshold epsilon produces smooth risk-coverage tradeoffs, reducing error rates f",
      "url": "http://arxiv.org/abs/2601.00138",
      "author": "Jorge Ortiz",
      "published": "2026-01-05",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Investigates confidence-based abstention for video QA using NExT-QA and Gemini 2.0 Flash. Establishes that confidence thresholding provides mechanistic control in-distribution for risk-coverage tradeoffs.",
      "importance_score": 52,
      "reasoning": "Addresses important reliability question for VLM deployment. Useful empirical findings for high-stakes applications.",
      "themes": [
        "Vision-Language Models",
        "Selective Prediction",
        "AI Reliability",
        "Video Understanding"
      ],
      "continuation": null
    },
    {
      "id": "4aebbcc3763d",
      "title": "Sequential Reservoir Computing for Efficient High-Dimensional Spatiotemporal Forecasting",
      "content": "Forecasting high-dimensional spatiotemporal systems remains computationally challenging for recurrent neural networks (RNNs) and long short-term memory (LSTM) models due to gradient-based training and memory bottlenecks. Reservoir Computing (RC) mitigates these challenges by replacing backpropagation with fixed recurrent layers and a convex readout optimization, yet conventional RC architectures still scale poorly with input dimensionality. We introduce a Sequential Reservoir Computing (Sequential RC) architecture that decomposes a large reservoir into a series of smaller, interconnected reservoirs. This design reduces memory and computational costs while preserving long-term temporal dependencies. Using both low-dimensional chaotic systems (Lorenz63) and high-dimensional physical simulations (2D vorticity and shallow-water equations), Sequential RC achieves 15-25% longer valid forecast horizons, 20-30% lower error metrics (SSIM, RMSE), and up to three orders of magnitude lower training cost compared to LSTM and standard RNN baselines. The results demonstrate that Sequential RC maintains the simplicity and efficiency of conventional RC while achieving superior scalability for high-dimensional dynamical systems. This approach provides a practical path toward real-time, energy-efficient forecasting in scientific and engineering applications.",
      "url": "http://arxiv.org/abs/2601.00172",
      "author": "Ata Akbari Asanjan, Filip Wudarski, Daniel O'Connor, Shaun Geaney, Elena Strbac, P. Aaron Lott, Davide Venturelli",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces Sequential Reservoir Computing that decomposes large reservoirs into smaller interconnected units, reducing memory and computational costs while preserving long-term dependencies. Demonstrates on both chaotic systems and physical simulations.",
      "importance_score": 52,
      "reasoning": "Practical efficiency improvement for reservoir computing. Addresses scalability limitation with maintained performance.",
      "themes": [
        "Reservoir Computing",
        "Time Series Forecasting",
        "Efficient Computing"
      ],
      "continuation": null
    },
    {
      "id": "d8e40016a5b6",
      "title": "Detecting Unobserved Confounders: A Kernelized Regression Approach",
      "content": "Detecting unobserved confounders is crucial for reliable causal inference in observational studies. Existing methods require either linearity assumptions or multiple heterogeneous environments, limiting applicability to nonlinear single-environment settings. To bridge this gap, we propose Kernel Regression Confounder Detection (KRCD), a novel method for detecting unobserved confounding in nonlinear observational data under single-environment conditions. KRCD leverages reproducing kernel Hilbert spaces to model complex dependencies. By comparing standard and higherorder kernel regressions, we derive a test statistic whose significant deviation from zero indicates unobserved confounding. Theoretically, we prove two key results: First, in infinite samples, regression coefficients coincide if and only if no unobserved confounders exist. Second, finite-sample differences converge to zero-mean Gaussian distributions with tractable variance. Extensive experiments on synthetic benchmarks and the Twins dataset demonstrate that KRCD not only outperforms existing baselines but also achieves superior computational efficiency.",
      "url": "http://arxiv.org/abs/2601.00200",
      "author": "Yikai Chen, Yunxin Mao, Chunyuan Zheng, Hao Zou, Shanzhi Gu, Shixuan Liu, Yang Shi, Wenjing Yang, Kun Kuang, Haotian Wang",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning (Statistics))",
      "source_type": "arxiv",
      "tags": [
        "stat.ML"
      ],
      "summary": "Proposes KRCD, a kernel-based method for detecting unobserved confounders in nonlinear observational data under single-environment conditions. Proves test statistic significance indicates confounding.",
      "importance_score": 52,
      "reasoning": "Addresses important gap in causal inference methods. Novel approach for nonlinear single-environment settings.",
      "themes": [
        "Causal Inference",
        "Confounding Detection",
        "Kernel Methods"
      ],
      "continuation": null
    },
    {
      "id": "618c544432b5",
      "title": "LooC: Effective Low-Dimensional Codebook for Compositional Vector Quantization",
      "content": "Vector quantization (VQ) is a prevalent and fundamental technique that discretizes continuous feature vectors by approximating them using a codebook. As the diversity and complexity of data and models continue to increase, there is an urgent need for high-capacity, yet more compact VQ methods. This paper aims to reconcile this conflict by presenting a new approach called LooC, which utilizes an effective Low-dimensional codebook for Compositional vector quantization. Firstly, LooC introduces a parameter-efficient codebook by reframing the relationship between codevectors and feature vectors, significantly expanding its solution space. Instead of individually matching codevectors with feature vectors, LooC treats them as lower-dimensional compositional units within feature vectors and combines them, resulting in a more compact codebook with improved performance. Secondly, LooC incorporates a parameter-free extrapolation-by-interpolation mechanism to enhance and smooth features during the VQ process, which allows for better preservation of details and fidelity in feature approximation. The design of LooC leads to full codebook usage, effectively utilizing the compact codebook while avoiding the problem of collapse. Thirdly, LooC can serve as a plug-and-play module for existing methods for different downstream tasks based on VQ. Finally, extensive evaluations on different tasks, datasets, and architectures demonstrate that LooC outperforms existing VQ methods, achieving state-of-the-art performance with a significantly smaller codebook.",
      "url": "http://arxiv.org/abs/2601.00222",
      "author": "Jie Li, Kwan-Yee K. Wong, Kai Han",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Introduces LooC, a parameter-efficient vector quantization method using low-dimensional compositional codebooks that expands solution space while reducing parameters. Addresses the tension between codebook capacity and compactness.",
      "importance_score": 52,
      "reasoning": "Technical improvement in VQ methods with practical benefits for compression, but relatively narrow scope and incremental advancement.",
      "themes": [
        "Vector Quantization",
        "Computer Vision",
        "Compression"
      ],
      "continuation": null
    },
    {
      "id": "b66d1c37cb6a",
      "title": "HarmoniAD: Harmonizing Local Structures and Global Semantics for Anomaly Detection",
      "content": "Anomaly detection is crucial in industrial product quality inspection. Failing to detect tiny defects often leads to serious consequences. Existing methods face a structure-semantics trade-off: structure-oriented models (such as frequency-based filters) are noise-sensitive, while semantics-oriented models (such as CLIP-based encoders) often miss fine details. To address this, we propose HarmoniAD, a frequency-guided dual-branch framework. Features are first extracted by the CLIP image encoder, then transformed into the frequency domain, and finally decoupled into high- and low-frequency paths for complementary modeling of structure and semantics. The high-frequency branch is equipped with a fine-grained structural attention module (FSAM) to enhance textures and edges for detecting small anomalies, while the low-frequency branch uses a global structural context module (GSCM) to capture long-range dependencies and preserve semantic consistency. Together, these branches balance fine detail and global semantics. HarmoniAD further adopts a multi-class joint training strategy, and experiments on MVTec-AD, VisA, and BTAD show state-of-the-art performance with both sensitivity and robustness.",
      "url": "http://arxiv.org/abs/2601.00327",
      "author": "Naiqi Zhang, Chuancheng Shi, Jingtong Dou, Wenhua Wu, Fei Shen, Jianhua Cao",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes HarmoniAD for industrial anomaly detection using frequency-guided dual-branch architecture with CLIP encoder, separately modeling high-frequency structures and low-frequency semantics.",
      "importance_score": 52,
      "reasoning": "Practical approach to industrial inspection combining CLIP with frequency analysis. Good application but limited novelty.",
      "themes": [
        "Anomaly Detection",
        "Industrial Inspection",
        "Computer Vision"
      ],
      "continuation": null
    },
    {
      "id": "e20c213ece9c",
      "title": "BHaRNet: Reliability-Aware Body-Hand Modality Expertized Networks for Fine-grained Skeleton Action Recognition",
      "content": "Skeleton-based human action recognition (HAR) has achieved remarkable progress with graph-based architectures. However, most existing methods remain body-centric, focusing on large-scale motions while neglecting subtle hand articulations that are crucial for fine-grained recognition. This work presents a probabilistic dual-stream framework that unifies reliability modeling and multi-modal integration, generalizing expertized learning under uncertainty across both intra-skeleton and cross-modal domains. The framework comprises three key components: (1) a calibration-free preprocessing pipeline that removes canonical-space transformations and learns directly from native coordinates; (2) a probabilistic Noisy-OR fusion that stabilizes reliability-aware dual-stream learning without requiring explicit confidence supervision; and (3) an intra- to cross-modal ensemble that couples four skeleton modalities (Joint, Bone, Joint Motion, and Bone Motion) to RGB representations, bridging structural and visual motion cues in a unified cross-modal formulation. Comprehensive evaluations across multiple benchmarks (NTU RGB+D~60/120, PKU-MMD, N-UCLA) and a newly defined hand-centric benchmark exhibit consistent improvements and robustness under noisy and heterogeneous conditions.",
      "url": "http://arxiv.org/abs/2601.00369",
      "author": "Seungyeon Cho and Tae-kyun Kim",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes BHaRNet for skeleton-based action recognition integrating body and hand articulations with probabilistic Noisy-OR fusion for reliability-aware dual-stream learning.",
      "importance_score": 52,
      "reasoning": "Addresses gap in fine-grained action recognition but incremental over existing approaches.",
      "themes": [
        "Action Recognition",
        "Skeleton Analysis",
        "Computer Vision"
      ],
      "continuation": null
    },
    {
      "id": "60a0fbd61cd4",
      "title": "Engineering Attack Vectors and Detecting Anomalies in Additive Manufacturing",
      "content": "Additive manufacturing (AM) is rapidly integrating into critical sectors such as aerospace, automotive, and healthcare. However, this cyber-physical convergence introduces new attack surfaces, especially at the interface between computer-aided design (CAD) and machine execution layers. In this work, we investigate targeted cyberattacks on two widely used fused deposition modeling (FDM) systems, Creality's flagship model K1 Max, and Ender 3. Our threat model is a multi-layered Man-in-the-Middle (MitM) intrusion, where the adversary intercepts and manipulates G-code files during upload from the user interface to the printer firmware. The MitM intrusion chain enables several stealthy sabotage scenarios. These attacks remain undetectable by conventional slicer software or runtime interfaces, resulting in structurally defective yet externally plausible printed parts. To counter these stealthy threats, we propose an unsupervised Intrusion Detection System (IDS) that analyzes structured machine logs generated during live printing. Our defense mechanism uses a frozen Transformer-based encoder (a BERT variant) to extract semantic representations of system behavior, followed by a contrastively trained projection head that learns anomaly-sensitive embeddings. Later, a clustering-based approach and a self-attention autoencoder are used for classification. Experimental results demonstrate that our approach effectively distinguishes between benign and compromised executions.",
      "url": "http://arxiv.org/abs/2601.00384",
      "author": "Md Mahbub Hasan, Marcus Sternhagen, and Krishna Chandra Roy",
      "published": "2026-01-05",
      "source": "arXiv (cs.CR)",
      "source_type": "arxiv",
      "tags": [
        "cs.CR"
      ],
      "summary": "Investigates Man-in-the-Middle attacks on FDM 3D printers (K1 Max, Ender 3) through G-code manipulation, demonstrating stealthy sabotage scenarios undetectable by standard interfaces.",
      "importance_score": 52,
      "reasoning": "Important security analysis for manufacturing systems with practical threat demonstrations.",
      "themes": [
        "Cybersecurity",
        "Manufacturing Security",
        "Additive Manufacturing"
      ],
      "continuation": null
    },
    {
      "id": "f92b9c107638",
      "title": "Imitation from Observations with Trajectory-Level Generative Embeddings",
      "content": "We consider the offline imitation learning from observations (LfO) where the expert demonstrations are scarce and the available offline suboptimal data are far from the expert behavior. Many existing distribution-matching approaches struggle in this regime because they impose strict support constraints and rely on brittle one-step models, making it hard to extract useful signal from imperfect data. To tackle this challenge, we propose TGE, a trajectory-level generative embedding for offline LfO that constructs a dense, smooth surrogate reward by estimating expert state density in the latent space of a temporal diffusion model trained on offline trajectory data. By leveraging the smooth geometry of the learned diffusion embedding, TGE captures long-horizon temporal dynamics and effectively bridges the gap between disjoint supports, ensuring a robust learning signal even when offline data is distributionally distinct from the expert. Empirically, the proposed approach consistently matches or outperforms prior offline LfO methods across a range of D4RL locomotion and manipulation benchmarks.",
      "url": "http://arxiv.org/abs/2601.00452",
      "author": "Yongtao Qu and Shangzhe Li and Weitong Zhang",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces TGE, a trajectory-level generative embedding for offline imitation learning from observations using diffusion model latent spaces to construct surrogate rewards when expert demonstrations are scarce.",
      "importance_score": 52,
      "reasoning": "Novel combination of diffusion models and imitation learning. Addresses important scarce-data regime. Reasonable methodology but needs broader validation.",
      "themes": [
        "Imitation Learning",
        "Diffusion Models",
        "Reinforcement Learning"
      ],
      "continuation": null
    },
    {
      "id": "154e8777a497",
      "title": "Improving LLM-Assisted Secure Code Generation through Retrieval-Augmented-Generation and Multi-Tool Feedback",
      "content": "Large Language Models (LLMs) can generate code but often introduce security vulnerabilities, logical inconsistencies, and compilation errors. Prior work demonstrates that LLMs benefit substantially from structured feedback, static analysis, retrieval augmentation, and execution-based refinement. We propose a retrieval-augmented, multi-tool repair workflow in which a single code-generating LLM iteratively refines its outputs using compiler diagnostics, CodeQL security scanning, and KLEE symbolic execution. A lightweight embedding model is used for semantic retrieval of previously successful repairs, providing security-focused examples that guide generation. Evaluated on a combined dataset of 3,242 programs generated by DeepSeek-Coder-1.3B and CodeLlama-7B, the system demonstrates significant improvements in robustness. For DeepSeek, security vulnerabilities were reduced by 96%. For the larger CodeLlama model, the critical security defect rate was decreased from 58.55% to 22.19%, highlighting the efficacy of tool-assisted self-repair even on \"stubborn\" models.",
      "url": "http://arxiv.org/abs/2601.00509",
      "author": "Vidyut Sriram, Sawan Pandita, Achintya Lakshmanan, Aneesh Shamraj, Suman Saha",
      "published": "2026-01-05",
      "source": "arXiv (cs.CR)",
      "source_type": "arxiv",
      "tags": [
        "cs.CR"
      ],
      "summary": "Proposes RAG-augmented multi-tool repair workflow for secure code generation, combining compiler diagnostics, CodeQL scanning, and KLEE symbolic execution to iteratively refine LLM outputs.",
      "importance_score": 52,
      "reasoning": "Practical contribution to LLM code security. Multi-tool integration is sensible but not novel. Useful empirical validation on 3,242 programs.",
      "themes": [
        "Code Generation",
        "Security",
        "Language Models",
        "RAG"
      ],
      "continuation": null
    },
    {
      "id": "94cba952effa",
      "title": "Variable Elimination in Hybrid Factor Graphs for Discrete-Continuous Inference & Estimation",
      "content": "Many hybrid problems in robotics involve both continuous and discrete components, and modeling them together for estimation tasks has been a long standing and difficult problem. Hybrid Factor Graphs give us a mathematical framework to model these types of problems, however existing approaches for solving them are based on approximations. In this work, we propose an efficient Hybrid Factor Graph framework alongwith a variable elimination algorithm to produce a hybrid Bayes network, which can then be used for exact Maximum A Posteriori estimation and marginalization over both sets of variables. Our approach first develops a novel hybrid Gaussian factor which can connect to both discrete and continuous variables, and a hybrid conditional which can represent multiple continuous hypotheses conditioned on the discrete variables. Using these representations, we derive the process of hybrid variable elimination under the Conditional Linear Gaussian scheme, giving us exact posteriors as hybrid Bayes network. To bound the number of discrete hypotheses, we use a tree-structured representation of the factors coupled with a simple pruning and probabilistic assignment scheme, which allows for tractable inference. We demonstrate the applicability of our framework on a SLAM dataset with ambiguous measurements, where discrete choices for the most likely measurement have to be made. Our demonstrated results showcase the accuracy, generality, and simplicity of our hybrid factor graph framework.",
      "url": "http://arxiv.org/abs/2601.00545",
      "author": "Varun Agrawal, Frank Dellaert",
      "published": "2026-01-05",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Proposes efficient Hybrid Factor Graph framework with variable elimination algorithm for exact MAP estimation and marginalization over both discrete and continuous variables in robotics.",
      "importance_score": 52,
      "reasoning": "Solid theoretical contribution to probabilistic inference in robotics. Novel hybrid Gaussian factor enables principled discrete-continuous reasoning.",
      "themes": [
        "Robotics",
        "Probabilistic Inference",
        "Factor Graphs"
      ],
      "continuation": null
    },
    {
      "id": "c97a416bbaa5",
      "title": "A Language-Agnostic Hierarchical LoRA-MoE Architecture for CTC-based Multilingual ASR",
      "content": "Large-scale multilingual ASR (mASR) models such as Whisper achieve strong performance but incur high computational and latency costs, limiting their deployment on resource-constrained edge devices. In this study, we propose a lightweight and language-agnostic multilingual ASR system based on a CTC architecture with domain adaptation. Specifically, we introduce a Language-agnostic Hierarchical LoRA-MoE (HLoRA) framework integrated into an mHuBERT-CTC model, enabling end-to-end decoding via LID-posterior-driven LoRA routing. The hierarchical design consists of a multilingual shared LoRA for learning language-invariant acoustic representations and language-specific LoRA experts for modeling language-dependent characteristics. The proposed routing mechanism removes the need for prior language identity information or explicit language labels during inference, achieving true language-agnostic decoding. Experiments on MSR-86K and the MLC-SLM 2025 Challenge datasets demonstrate that HLoRA achieves competitive performance with state-of-the-art two-stage inference methods using only single-pass decoding, significantly improving decoding efficiency for low-resource mASR applications.",
      "url": "http://arxiv.org/abs/2601.00557",
      "author": "Yuang Zheng, Yuxiang Mei, Dongxing Xu, Jie Chen, Yanhua Long",
      "published": "2026-01-05",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes HLoRA, a language-agnostic hierarchical LoRA-MoE architecture for CTC-based multilingual ASR with LID-posterior-driven routing and shared/language-specific LoRA experts.",
      "importance_score": 52,
      "reasoning": "Novel architecture combining LoRA with MoE for efficient multilingual ASR. Removes need for prior language knowledge. Practical for edge deployment.",
      "themes": [
        "Speech Recognition",
        "Multilingual AI",
        "Efficient AI",
        "MoE"
      ],
      "continuation": null
    },
    {
      "id": "45efc2dd6b3c",
      "title": "SafeMo: Linguistically Grounded Unlearning for Trustworthy Text-to-Motion Generation",
      "content": "Text-to-motion (T2M) generation with diffusion backbones achieves strong realism and alignment. Safety concerns in T2M methods have been raised in recent years; existing methods replace discrete VQ-VAE codebook entries to steer the model away from unsafe behaviors. However, discrete codebook replacement-based methods have two critical flaws: firstly, replacing codebook entries which are reused by benign prompts leads to drifts on everyday tasks, degrading the model's benign performance; secondly, discrete token-based methods introduce quantization and smoothness loss, resulting in artifacts and jerky transitions. Moreover, existing text-to-motion datasets naturally contain unsafe intents and corresponding motions, making them unsuitable for safety-driven machine learning. To address these challenges, we propose SafeMo, a trustworthy motion generative framework integrating Minimal Motion Unlearning (MMU), a two-stage machine unlearning strategy, enabling safe human motion generation in continuous space, preserving continuous kinematics without codebook loss and delivering strong safety-utility trade-offs compared to current baselines. Additionally, we present the first safe text-to-motion dataset SafeMoVAE-29K integrating rewritten safe text prompts and continuous refined motion for trustworthy human motion unlearning. Built upon DiP, SafeMo efficiently generates safe human motions with natural transitions. Experiments demonstrate effective unlearning performance of SafeMo by showing strengthened forgetting on unsafe prompts, reaching 2.5x and 14.4x higher forget-set FID on HumanML3D and Motion-X respectively, compared to the previous SOTA human motion unlearning method LCR, with benign performance on safe prompts being better or comparable. Code: https://github.com/AIGeeksGroup/SafeMo. Website: https://aigeeksgroup.github.io/SafeMo.",
      "url": "http://arxiv.org/abs/2601.00590",
      "author": "Yiling Wang, Zeyu Zhang, Yiran Wang, Hao Tang",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes SafeMo for trustworthy text-to-motion generation using machine unlearning to remove unsafe motions while avoiding artifacts from discrete codebook replacement methods.",
      "importance_score": 52,
      "reasoning": "Important safety-focused work for generative motion models. Novel unlearning approach avoiding quantization issues. Addresses emerging safety concern.",
      "themes": [
        "AI Safety",
        "Motion Generation",
        "Machine Unlearning"
      ],
      "continuation": null
    },
    {
      "id": "497b999c079b",
      "title": "Pixel-to-4D: Camera-Controlled Image-to-Video Generation with Dynamic 3D Gaussians",
      "content": "Humans excel at forecasting the future dynamics of a scene given just a single image. Video generation models that can mimic this ability are an essential component for intelligent systems. Recent approaches have improved temporal coherence and 3D consistency in single-image-conditioned video generation. However, these methods often lack robust user controllability, such as modifying the camera path, limiting their applicability in real-world applications. Most existing camera-controlled image-to-video models struggle with accurately modeling camera motion, maintaining temporal consistency, and preserving geometric integrity. Leveraging explicit intermediate 3D representations offers a promising solution by enabling coherent video generation aligned with a given camera trajectory. Although these methods often use 3D point clouds to render scenes and introduce object motion in a later stage, this two-step process still falls short in achieving full temporal consistency, despite allowing precise control over camera movement. We propose a novel framework that constructs a 3D Gaussian scene representation and samples plausible object motion, given a single image in a single forward pass. This enables fast, camera-guided video generation without the need for iterative denoising to inject object motion into render frames. Extensive experiments on the KITTI, Waymo, RealEstate10K and DL3DV-10K datasets demonstrate that our method achieves state-of-the-art video quality and inference efficiency. The project page is available at https://melonienimasha.github.io/Pixel-to-4D-Website.",
      "url": "http://arxiv.org/abs/2601.00678",
      "author": "Melonie de Almeida, Daniela Ivanova, Tong Shi, John H. Williamson, Paul Henderson",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Presents Pixel-to-4D, a camera-controlled image-to-video generation method using dynamic 3D Gaussians for maintaining temporal consistency and geometric integrity while allowing user-specified camera trajectories.",
      "importance_score": 52,
      "reasoning": "Addresses important controllability gap in video generation. Combination of 3D Gaussians with video generation is timely. However, the field is crowded and this appears to be an incremental contribution.",
      "themes": [
        "Video Generation",
        "3D Gaussian Splatting",
        "Camera Control"
      ],
      "continuation": null
    },
    {
      "id": "ae26543599c6",
      "title": "Detecting Performance Degradation under Data Shift in Pathology Vision-Language Model",
      "content": "Vision-Language Models have demonstrated strong potential in medical image analysis and disease diagnosis. However, after deployment, their performance may deteriorate when the input data distribution shifts from that observed during development. Detecting such performance degradation is essential for clinical reliability, yet remains challenging for large pre-trained VLMs operating without labeled data. In this study, we investigate performance degradation detection under data shift in a state-of-the-art pathology VLM. We examine both input-level data shift and output-level prediction behavior to understand their respective roles in monitoring model reliability. To facilitate systematic analysis of input data shift, we develop DomainSAT, a lightweight toolbox with a graphical interface that integrates representative shift detection algorithms and enables intuitive exploration of data shift. Our analysis shows that while input data shift detection is effective at identifying distributional changes and providing early diagnostic signals, it does not always correspond to actual performance degradation. Motivated by this observation, we further study output-based monitoring and introduce a label-free, confidence-based degradation indicator that directly captures changes in model prediction confidence. We find that this indicator exhibits a close relationship with performance degradation and serves as an effective complement to input shift detection. Experiments on a large-scale pathology dataset for tumor classification demonstrate that combining input data shift detection and output confidence-based indicators enables more reliable detection and interpretation of performance degradation in VLMs under data shift. These findings provide a practical and complementary framework for monitoring the reliability of foundation models in digital pathology.",
      "url": "http://arxiv.org/abs/2601.00716",
      "author": "Hao Guan, Li Zhou",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Investigates performance degradation detection in pathology vision-language models under data shift, developing DomainSAT toolbox for systematic analysis. Examines both input-level data shift and output-level prediction behavior for clinical reliability.",
      "importance_score": 52,
      "reasoning": "Important practical concern for medical AI deployment. Provides useful toolbox for domain shift analysis. Relevant for clinical reliability but limited methodological novelty.",
      "themes": [
        "Medical AI",
        "Vision-Language Models",
        "Distribution Shift",
        "AI Safety"
      ],
      "continuation": null
    },
    {
      "id": "0be404b3f87d",
      "title": "An Agentic Framework for Neuro-Symbolic Programming",
      "content": "Integrating symbolic constraints into deep learning models could make them more robust, interpretable, and data-efficient. Still, it remains a time-consuming and challenging task. Existing frameworks like DomiKnowS help this integration by providing a high-level declarative programming interface, but they still assume the user is proficient with the library's specific syntax. We propose AgenticDomiKnowS (ADS) to eliminate this dependency. ADS translates free-form task descriptions into a complete DomiKnowS program using an agentic workflow that creates and tests each DomiKnowS component separately. The workflow supports optional human-in-the-loop intervention, enabling users familiar with DomiKnowS to refine intermediate outputs. We show how ADS enables experienced DomiKnowS users and non-users to rapidly construct neuro-symbolic programs, reducing development time from hours to 10-15 minutes.",
      "url": "http://arxiv.org/abs/2601.00743",
      "author": "Aliakbar Nafar, Chetan Chigurupati, Danial Kamali, Hamid Karimian, Parisa Kordjamshidi",
      "published": "2026-01-05",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Introduces AgenticDomiKnowS (ADS), using agentic LLM workflows to translate natural language task descriptions into neuro-symbolic programs, with optional human-in-the-loop intervention.",
      "importance_score": 52,
      "reasoning": "Interesting application of agentic AI to lower barrier for neuro-symbolic programming. Addresses real usability gap. However, dependent on specific framework (DomiKnowS) limits broader impact.",
      "themes": [
        "Neuro-Symbolic AI",
        "LLM Agents",
        "Program Synthesis",
        "Human-AI Collaboration"
      ],
      "continuation": null
    },
    {
      "id": "af7a1f47a184",
      "title": "FedHypeVAE: Federated Learning with Hypernetwork Generated Conditional VAEs for Differentially Private Embedding Sharing",
      "content": "Federated data sharing promises utility without centralizing raw data, yet existing embedding-level generators struggle under non-IID client heterogeneity and provide limited formal protection against gradient leakage. We propose FedHypeVAE, a differentially private, hypernetwork-driven framework for synthesizing embedding-level data across decentralized clients. Building on a conditional VAE backbone, we replace the single global decoder and fixed latent prior with client-aware decoders and class-conditional priors generated by a shared hypernetwork from private, trainable client codes. This bi-level design personalizes the generative layerrather than the downstream modelwhile decoupling local data from communicated parameters. The shared hypernetwork is optimized under differential privacy, ensuring that only noise-perturbed, clipped gradients are aggregated across clients. A local MMD alignment between real and synthetic embeddings and a Lipschitz regularizer on hypernetwork outputs further enhance stability and distributional coherence under non-IID conditions. After training, a neutral meta-code enables domain agnostic synthesis, while mixtures of meta-codes provide controllable multi-domain coverage. FedHypeVAE unifies personalization, privacy, and distribution alignment at the generator level, establishing a principled foundation for privacy-preserving data synthesis in federated settings. Code: github.com/sunnyinAI/FedHypeVAE",
      "url": "http://arxiv.org/abs/2601.00785",
      "author": "Sunny Gupta, Amit Sethi",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes FedHypeVAE, combining hypernetwork-generated conditional VAEs with differential privacy for federated embedding-level data synthesis. Uses client codes for personalization while decoupling local data from communicated parameters.",
      "importance_score": 52,
      "reasoning": "Addresses important problem of federated learning under non-IID data with privacy. Combines several techniques in novel way. However, complexity of approach may limit practical adoption.",
      "themes": [
        "Federated Learning",
        "Differential Privacy",
        "VAEs",
        "Hypernetworks"
      ],
      "continuation": null
    },
    {
      "id": "bdea70afafd4",
      "title": "The economy is a graph, not a pipeline",
      "content": "Summary: Analysis claiming that automating X% of the economy can only boost GDP by 1/(1-X) assumes all sectors must scale proportionally. The economy is a graph of processes, not a pipeline. Subgraphs can grow independently if they don't bottleneck on inputs from non-growing sectors. AI-driven automation of physical production could create a nearly self-contained subgraph that grows at rates bounded only by raw material availability and speed of production equipment.Models being challenged:This post is a response to Thoughts (by a non-economist) on AI and economics and the broader framing it represents. Related claims appear across LessWrong discussions of AI economic impact:Amdahl's Law for economics: Automating a sector that represents X% of GDP can boost output by at most 1/(1-X). Automating software (2% of GDP) gives ~2% boost; automating all cognitive labor (30% of GDP) gives ~42%.Bottleneck tasks determine growth rate: \"Suppose there are three stages in the production process for making a cheese sandwich: make the bread, make the cheese, combine the two together. If the first two stages are automated and can proceed much more quickly, the third stage can still bottleneck the speed of sandwich production.\" (Davidson 2021)Baumol effects bind: \"If bottlenecks persist—and I believe strongly that they will—we will have Baumol issues... 100% is a really big number. It's radically bigger than 80%, 95%, or 99%.\" (Twitter thread quoted on LW)These framings share an implicit assumption: the economy is a single integrated production function where unautomated sectors constrain growth of automated sectors. I argue this assumption breaks when an automatable subgraph can grow without requiring inputs from non-automated sectors.There's no rule in economics that says if you grow a sector of your economy by 10x, farm fields, lawyers and doctors must then produce 10x more corn, lawsuits and medical care respectively. The industrial revolution was a shift from mostly growing foo...",
      "url": "https://www.lesswrong.com/posts/bBmaDRG8XkoHpkrwx/the-economy-is-a-graph-not-a-pipeline",
      "author": "anithite",
      "published": "2026-01-04T16:48:48.652000",
      "source": "LessWrong",
      "source_type": "research_blog",
      "tags": [],
      "summary": "Challenges the economic model that AI automation benefits are bounded by Amdahl's Law, arguing the economy is a graph where AI-automated subgraphs can grow independently without proportional scaling of non-automated sectors.",
      "importance_score": 52,
      "reasoning": "Substantive critique of common AI economic impact modeling. Provides alternative framework for thinking about automation effects. Relevant for AI impact forecasting but speculative.",
      "themes": [
        "AI Economics",
        "AI Impact",
        "Economic Modeling"
      ],
      "continuation": null
    },
    {
      "id": "725781f284c1",
      "title": "Depth-Synergized Mamba Meets Memory Experts for All-Day Image Reflection Separation",
      "content": "Image reflection separation aims to disentangle the transmission layer and the reflection layer from a blended image. Existing methods rely on limited information from a single image, tending to confuse the two layers when their contrasts are similar, a challenge more severe at night. To address this issue, we propose the Depth-Memory Decoupling Network (DMDNet). It employs the Depth-Aware Scanning (DAScan) to guide Mamba toward salient structures, promoting information flow along semantic coherence to construct stable states. Working in synergy with DAScan, the Depth-Synergized State-Space Model (DS-SSM) modulates the sensitivity of state activations by depth, suppressing the spread of ambiguous features that interfere with layer disentanglement. Furthermore, we introduce the Memory Expert Compensation Module (MECM), leveraging cross-image historical knowledge to guide experts in providing layer-specific compensation. To address the lack of datasets for nighttime reflection separation, we construct the Nighttime Image Reflection Separation (NightIRS) dataset. Extensive experiments demonstrate that DMDNet outperforms state-of-the-art methods in both daytime and nighttime.",
      "url": "http://arxiv.org/abs/2601.00322",
      "author": "Siyan Fang, Long Peng, Yuntao Wang, Ruonan Wei, Yuehuan Wang",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes DMDNet for all-day image reflection separation using depth-aware scanning for Mamba guidance and depth-synergized state-space models for layer disentanglement.",
      "importance_score": 51,
      "reasoning": "Technical improvement for reflection separation using modern Mamba architecture. Moderate contribution.",
      "themes": [
        "Image Processing",
        "State-Space Models",
        "Computer Vision"
      ],
      "continuation": null
    },
    {
      "id": "34c9480cae55",
      "title": "RoLID-11K: A Dashcam Dataset for Small-Object Roadside Litter Detection",
      "content": "Roadside litter poses environmental, safety and economic challenges, yet current monitoring relies on labour-intensive surveys and public reporting, providing limited spatial coverage. Existing vision datasets for litter detection focus on street-level still images, aerial scenes or aquatic environments, and do not reflect the unique characteristics of dashcam footage, where litter appears extremely small, sparse and embedded in cluttered road-verge backgrounds. We introduce RoLID-11K, the first large-scale dataset for roadside litter detection from dashcams, comprising over 11k annotated images spanning diverse UK driving conditions and exhibiting pronounced long-tail and small-object distributions. We benchmark a broad spectrum of modern detectors, from accuracy-oriented transformer architectures to real-time YOLO models, and analyse their strengths and limitations on this challenging task. Our results show that while CO-DETR and related transformers achieve the best localisation accuracy, real-time models remain constrained by coarse feature hierarchies. RoLID-11K establishes a challenging benchmark for extreme small-object detection in dynamic driving scenes and aims to support the development of scalable, low-cost systems for roadside-litter monitoring. The dataset is available at https://github.com/xq141839/RoLID-11K.",
      "url": "http://arxiv.org/abs/2601.00398",
      "author": "Tao Wu, Qing Xu, Xiangjian He, Oakleigh Weekes, James Brown, Wenting Duan",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Introduces RoLID-11K, first large-scale dataset for roadside litter detection from dashcams with 11K images exhibiting small-object and long-tail distributions, with detector benchmarks.",
      "importance_score": 51,
      "reasoning": "New dataset for environmental monitoring application. Addresses specific gap in litter detection.",
      "themes": [
        "Datasets",
        "Object Detection",
        "Environmental AI"
      ],
      "continuation": null
    },
    {
      "id": "d55d300560de",
      "title": "CoCo-Fed: A Unified Framework for Memory- and Communication-Efficient Federated Learning at the Wireless Edge",
      "content": "The deployment of large-scale neural networks within the Open Radio Access Network (O-RAN) architecture is pivotal for enabling native edge intelligence. However, this paradigm faces two critical bottlenecks: the prohibitive memory footprint required for local training on resource-constrained gNBs, and the saturation of bandwidth-limited backhaul links during the global aggregation of high-dimensional model updates. To address these challenges, we propose CoCo-Fed, a novel Compression and Combination-based Federated learning framework that unifies local memory efficiency and global communication reduction. Locally, CoCo-Fed breaks the memory wall by performing a double-dimension down-projection of gradients, adapting the optimizer to operate on low-rank structures without introducing additional inference parameters/latency. Globally, we introduce a transmission protocol based on orthogonal subspace superposition, where layer-wise updates are projected and superimposed into a single consolidated matrix per gNB, drastically reducing the backhaul traffic. Beyond empirical designs, we establish a rigorous theoretical foundation, proving the convergence of CoCo-Fed even under unsupervised learning conditions suitable for wireless sensing tasks. Extensive simulations on an angle-of-arrival estimation task demonstrate that CoCo-Fed significantly outperforms state-of-the-art baselines in both memory and communication efficiency while maintaining robust convergence under non-IID settings.",
      "url": "http://arxiv.org/abs/2601.00549",
      "author": "Zhiheng Guo, Zhaoyang Liu, Zihan Cen, Chenyuan Feng, Xinghua Sun, Xiang Chen, Tony Q. S. Quek, and Xijun Wang",
      "published": "2026-01-05",
      "source": "arXiv (cs.IT)",
      "source_type": "arxiv",
      "tags": [
        "cs.IT"
      ],
      "summary": "Proposes CoCo-Fed for federated learning combining local memory efficiency through gradient down-projection with global communication reduction for large-scale neural networks in O-RAN architecture.",
      "importance_score": 51,
      "reasoning": "Addresses two critical bottlenecks in FL simultaneously. Practical for edge deployment. Architecture-specific but important for 6G/O-RAN applications.",
      "themes": [
        "Federated Learning",
        "Efficient AI",
        "Wireless Communications"
      ],
      "continuation": null
    },
    {
      "id": "1ed827224384",
      "title": "Noise-Robust Tiny Object Localization with Flows",
      "content": "Despite significant advances in generic object detection, a persistent performance gap remains for tiny objects compared to normal-scale objects. We demonstrate that tiny objects are highly sensitive to annotation noise, where optimizing strict localization objectives risks noise overfitting. To address this, we propose Tiny Object Localization with Flows (TOLF), a noise-robust localization framework leveraging normalizing flows for flexible error modeling and uncertainty-guided optimization. Our method captures complex, non-Gaussian prediction distributions through flow-based error modeling, enabling robust learning under noisy supervision. An uncertainty-aware gradient modulation mechanism further suppresses learning from high-uncertainty, noise-prone samples, mitigating overfitting while stabilizing training. Extensive experiments across three datasets validate our approach's effectiveness. Especially, TOLF boosts the DINO baseline by 1.2% AP on the AI-TOD dataset.",
      "url": "http://arxiv.org/abs/2601.00617",
      "author": "Huixin Sun, Linlin Yang, Ronyu Chen, Kerui Gu, Baochang Zhang, Angela Yao, Xianbin Cao",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes TOLF for noise-robust tiny object localization using normalizing flows for flexible error modeling and uncertainty-guided optimization to handle annotation noise.",
      "importance_score": 51,
      "reasoning": "Addresses important challenge of annotation noise for tiny objects. Novel application of normalizing flows for localization. Solid methodology.",
      "themes": [
        "Object Detection",
        "Normalizing Flows",
        "Robust Learning"
      ],
      "continuation": null
    },
    {
      "id": "51b1dc2f400c",
      "title": "Finetuning Large Language Models for Automated Depression Screening in Nigerian Pidgin English: GENSCORE Pilot Study",
      "content": "Depression is a major contributor to the mental-health burden in Nigeria, yet screening coverage remains limited due to low access to clinicians, stigma, and language barriers. Traditional tools like the Patient Health Questionnaire-9 (PHQ-9) were validated in high-income countries but may be linguistically or culturally inaccessible for low- and middle-income countries and communities such as Nigeria where people communicate in Nigerian Pidgin and more than 520 local languages. This study presents a novel approach to automated depression screening using fine-tuned large language models (LLMs) adapted for conversational Nigerian Pidgin. We collected a dataset of 432 Pidgin-language audio responses from Nigerian young adults aged 18-40 to prompts assessing psychological experiences aligned with PHQ-9 items, performed transcription, rigorous preprocessing and annotation, including semantic labeling, slang and idiom interpretation, and PHQ-9 severity scoring. Three LLMs - Phi-3-mini-4k-instruct, Gemma-3-4B-it, and GPT-4.1 - were fine-tuned on this annotated dataset, and their performance was evaluated quantitatively (accuracy, precision and semantic alignment) and qualitatively (clarity, relevance, and cultural appropriateness). GPT-4.1 achieved the highest quantitative performance, with 94.5% accuracy in PHQ-9 severity scoring prediction, outperforming Gemma-3-4B-it and Phi-3-mini-4k-instruct. Qualitatively, GPT-4.1 also produced the most culturally appropriate, clear, and contextually relevant responses. AI-mediated depression screening for underserved Nigerian communities. This work provides a foundation for deploying conversational mental-health tools in linguistically diverse, resource-constrained environments.",
      "url": "http://arxiv.org/abs/2601.00004",
      "author": "Isaac Iyinoluwa Olufadewa, Miracle Ayomikun Adesina, Ezekiel Ayodeji Oladejo, Uthman Babatunde Usman, Owen Kolade Adeniyi, Matthew Tolulope Olawoyin",
      "published": "2026-01-05",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Fine-tunes LLMs for automated depression screening in Nigerian Pidgin English, addressing barriers of language, stigma, and clinician access. Collected 432 Pidgin audio responses aligned with PHQ-9 assessment framework.",
      "importance_score": 50,
      "reasoning": "Important application for mental health in underserved populations. Novel dataset contribution but limited scale and validation against clinical outcomes.",
      "themes": [
        "Language Models",
        "Healthcare AI",
        "Low-Resource Languages",
        "Mental Health"
      ],
      "continuation": null
    },
    {
      "id": "89ff94ec163a",
      "title": "Reinforcement learning with timed constraints for robotics motion planning",
      "content": "Robotic systems operating in dynamic and uncertain environments increasingly require planners that satisfy complex task sequences while adhering to strict temporal constraints. Metric Interval Temporal Logic (MITL) offers a formal and expressive framework for specifying such time-bounded requirements; however, integrating MITL with reinforcement learning (RL) remains challenging due to stochastic dynamics and partial observability. This paper presents a unified automata-based RL framework for synthesizing policies in both Markov Decision Processes (MDPs) and Partially Observable Markov Decision Processes (POMDPs) under MITL specifications. MITL formulas are translated into Timed Limit-Deterministic Generalized B\\\"uchi Automata (Timed-LDGBA) and synchronized with the underlying decision process to construct product timed models suitable for Q-learning. A simple yet expressive reward structure enforces temporal correctness while allowing additional performance objectives. The approach is validated in three simulation studies: a $5 \\times 5$ grid-world formulated as an MDP, a $10 \\times 10$ grid-world formulated as a POMDP, and an office-like service-robot scenario. Results demonstrate that the proposed framework consistently learns policies that satisfy strict time-bounded requirements under stochastic transitions, scales to larger state spaces, and remains effective in partially observable environments, highlighting its potential for reliable robotic planning in time-critical and uncertain settings.",
      "url": "http://arxiv.org/abs/2601.00087",
      "author": "Zhaoan Wang, Junchao Li, Mahdi Mohammad and Shaoping Xiao",
      "published": "2026-01-05",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Presents unified automata-based RL framework for synthesizing policies under Metric Interval Temporal Logic specifications in MDPs and POMDPs. Translates MITL to Timed-LDGBA and synchronizes with decision processes.",
      "importance_score": 50,
      "reasoning": "Addresses important problem of temporal constraints in robot planning. Solid technical contribution combining formal methods with RL.",
      "themes": [
        "Reinforcement Learning",
        "Temporal Logic",
        "Robotics",
        "Motion Planning"
      ],
      "continuation": null
    },
    {
      "id": "be6683835859",
      "title": "Toward Large-Scale Photonics-Empowered AI Systems: From Physical Design Automation to System-Algorithm Co-Exploration",
      "content": "In this work, we identify three considerations that are essential for realizing practical photonic AI systems at scale: (1) dynamic tensor operation support for modern models rather than only weight-static kernels, especially for attention/Transformer-style workloads; (2) systematic management of conversion, control, and data-movement overheads, where multiplexing and dataflow must amortize electronic costs instead of letting ADC/DAC and I/O dominate; and (3) robustness under hardware non-idealities that become more severe as integration density grows. To study these coupled tradeoffs quantitatively, and to ensure they remain meaningful under real implementation constraints, we build a cross-layer toolchain that supports photonic AI design from early exploration to physical realization. SimPhony provides implementation-aware modeling and rapid cross-layer evaluation, translating physical costs into system-level metrics so architectural decisions are grounded in realistic assumptions. ADEPT and ADEPT-Z enable end-to-end circuit and topology exploration, connecting system objectives to feasible photonic fabrics under practical device and circuit constraints. Finally, Apollo and LiDAR provide scalable photonic physical design automation, turning candidate circuits into manufacturable layouts while accounting for routing, thermal, and crosstalk constraints.",
      "url": "http://arxiv.org/abs/2601.00129",
      "author": "Ziang Yin, Hongjian Zhou, Nicholas Gangi, Meng Zhang, Jeff Zhang, Zhaoran Rena Huang, Jiaqi Gu",
      "published": "2026-01-05",
      "source": "arXiv (physics.optics)",
      "source_type": "arxiv",
      "tags": [
        "physics.optics"
      ],
      "summary": "Identifies three essential considerations for practical photonic AI: dynamic tensor operations, overhead management, and robustness under non-idealities. Builds cross-layer toolchain supporting design from exploration to physical realization.",
      "importance_score": 50,
      "reasoning": "Comprehensive analysis of photonic AI system requirements. Important for emerging hardware but specialized audience.",
      "themes": [
        "Photonic Computing",
        "AI Hardware",
        "System Design"
      ],
      "continuation": null
    },
    {
      "id": "56bd177b3bf6",
      "title": "An AI Monkey Gets Grapes for Sure -- Sphere Neural Networks for Reliable Decision-Making",
      "content": "This paper compares three methodological categories of neural reasoning: LLM reasoning, supervised learning-based reasoning, and explicit model-based reasoning. LLMs remain unreliable and struggle with simple decision-making that animals can master without extensive corpora training. Through disjunctive syllogistic reasoning testing, we show that reasoning via supervised learning is less appealing than reasoning via explicit model construction. Concretely, we show that an Euler Net trained to achieve 100.00% in classic syllogistic reasoning can be trained to reach 100.00% accuracy in disjunctive syllogistic reasoning. However, the retrained Euler Net suffers severely from catastrophic forgetting (its performance drops to 6.25% on already-learned classic syllogistic reasoning), and its reasoning competence is limited to the pattern level. We propose a new version of Sphere Neural Networks that embeds concepts as circles on the surface of an n-dimensional sphere. These Sphere Neural Networks enable the representation of the negation operator via complement circles and achieve reliable decision-making by filtering out illogical statements that form unsatisfiable circular configurations. We demonstrate that the Sphere Neural Network can master 16 syllogistic reasoning tasks, including rigorous disjunctive syllogistic reasoning, while preserving the rigour of classical syllogistic reasoning. We conclude that neural reasoning with explicit model construction is the most reliable among the three methodological categories of neural reasoning.",
      "url": "http://arxiv.org/abs/2601.00142",
      "author": "Tiansi Dong, Henry He, Pietro Li\\`o, Mateja Jamnik",
      "published": "2026-01-05",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Compares LLM reasoning, supervised learning, and explicit model-based reasoning through disjunctive syllogistic testing. Shows Euler Net suffers severe catastrophic forgetting when retrained, dropping from 100% to 6.25% accuracy.",
      "importance_score": 50,
      "reasoning": "Useful empirical comparison of reasoning paradigms. Highlights important limitations in neural reasoning approaches.",
      "themes": [
        "Neural Reasoning",
        "Symbolic AI",
        "Catastrophic Forgetting"
      ],
      "continuation": null
    },
    {
      "id": "20da94ca84c4",
      "title": "Pat-DEVAL: Chain-of-Legal-Thought Evaluation for Patent Description",
      "content": "Patent descriptions must deliver comprehensive technical disclosure while meeting strict legal standards such as enablement and written description requirements. Although large language models have enabled end-to-end automated patent drafting, existing evaluation approaches fail to assess long-form structural coherence and statutory compliance specific to descriptions. We propose Pat-DEVAL, the first multi-dimensional evaluation framework dedicated to patent description bodies. Leveraging the LLM-as-a-judge paradigm, Pat-DEVAL introduces Chain-of-Legal-Thought (CoLT), a legally-constrained reasoning mechanism that enforces sequential patent-law-specific analysis. Experiments validated by patent expert on our Pap2Pat-EvalGold dataset demonstrate that Pat-DEVAL achieves a Pearson correlation of 0.69, significantly outperforming baseline metrics and existing LLM evaluators. Notably, the framework exhibits a superior correlation of 0.73 in Legal-Professional Compliance, proving that the explicit injection of statutory constraints is essential for capturing nuanced legal validity. By establishing a new standard for ensuring both technical soundness and legal compliance, Pat-DEVAL provides a robust methodological foundation for the practical deployment of automated patent drafting systems.",
      "url": "http://arxiv.org/abs/2601.00166",
      "author": "Yongmin Yoo, Kris W Pan",
      "published": "2026-01-05",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes Pat-DEVAL, first evaluation framework for patent descriptions using Chain-of-Legal-Thought (CoLT) reasoning. Achieves high correlation with patent expert evaluations on structural coherence and statutory compliance.",
      "importance_score": 50,
      "reasoning": "Novel evaluation framework for specialized domain. Addresses gap in patent AI evaluation with domain expertise integration.",
      "themes": [
        "Legal AI",
        "Patent Analysis",
        "Evaluation Metrics",
        "Language Models"
      ],
      "continuation": null
    },
    {
      "id": "386bd1fb8850",
      "title": "From Evidence-Based Medicine to Knowledge Graph: Retrieval-Augmented Generation for Sports Rehabilitation and a Domain Benchmark",
      "content": "In medicine, large language models (LLMs) increasingly rely on retrieval-augmented generation (RAG) to ground outputs in up-to-date external evidence. However, current RAG approaches focus primarily on performance improvements while overlooking evidence-based medicine (EBM) principles. This study addresses two key gaps: (1) the lack of PICO alignment between queries and retrieved evidence, and (2) the absence of evidence hierarchy considerations during reranking. We present a generalizable strategy for adapting EBM to graph-based RAG, integrating the PICO framework into knowledge graph construction and retrieval, and proposing a Bayesian-inspired reranking algorithm to calibrate ranking scores by evidence grade without introducing predefined weights. We validated this framework in sports rehabilitation, a literature-rich domain currently lacking RAG systems and benchmarks. We released a knowledge graph (357,844 nodes and 371,226 edges) and a reusable benchmark of 1,637 QA pairs. The system achieved 0.830 nugget coverage, 0.819 answer faithfulness, 0.882 semantic similarity, and 0.788 PICOT match accuracy. In a 5-point Likert evaluation, five expert clinicians rated the system 4.66-4.84 across factual accuracy, faithfulness, relevance, safety, and PICO alignment. These findings demonstrate that the proposed EBM adaptation strategy improves retrieval and answer quality and is transferable to other clinical domains. The released resources also help address the scarcity of RAG datasets in sports rehabilitation.",
      "url": "http://arxiv.org/abs/2601.00216",
      "author": "Jinning Zhang, Jie Song, Wenhui Tu, Zecheng Li, Jingxuan Li, Jin Li, Xuan Liu, Taole Sha, Zichen Wei, and Yan Li",
      "published": "2026-01-05",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes EBM-aligned RAG for sports rehabilitation integrating PICO framework into knowledge graph construction and Bayesian-inspired reranking by evidence grade. Creates domain benchmark for validation.",
      "importance_score": 50,
      "reasoning": "Novel integration of evidence-based medicine principles into RAG. Addresses important gap in medical AI methodology.",
      "themes": [
        "Retrieval-Augmented Generation",
        "Healthcare AI",
        "Knowledge Graphs",
        "Evidence-Based Medicine"
      ],
      "continuation": null
    },
    {
      "id": "df0a149fad08",
      "title": "Latent Flow Matching for Expressive Singing Voice Synthesis",
      "content": "Conditional variational autoencoder (cVAE)-based singing voice synthesis provides efficient inference and strong audio quality by learning a score-conditioned prior and a recording-conditioned posterior latent space. However, because synthesis relies on prior samples while training uses posterior latents inferred from real recordings, imperfect distribution matching can cause a prior-posterior mismatch that degrades fine-grained expressiveness such as vibrato and micro-prosody. We propose FM-Singer, which introduces conditional flow matching (CFM) in latent space to learn a continuous vector field transporting prior latents toward posterior latents along an optimal-transport-inspired path. At inference time, the learned latent flow refines a prior sample by solving an ordinary differential equation (ODE) before waveform generation, improving expressiveness while preserving the efficiency of parallel decoding. Experiments on Korean and Chinese singing datasets demonstrate consistent improvements over strong baselines, including lower mel-cepstral distortion and fundamental-frequency error and higher perceptual scores on the Korean dataset. Code, pretrained checkpoints, and audio demos are available at https://github.com/alsgur9368/FM-Singer",
      "url": "http://arxiv.org/abs/2601.00217",
      "author": "Minhyeok Yun, Yong-Hoon Choi",
      "published": "2026-01-05",
      "source": "arXiv (cs.SD)",
      "source_type": "arxiv",
      "tags": [
        "cs.SD"
      ],
      "summary": "Proposes FM-Singer using conditional flow matching in latent space to address prior-posterior mismatch in singing voice synthesis. Learns vector field transporting prior to posterior latents for improved expressiveness.",
      "importance_score": 50,
      "reasoning": "Novel application of flow matching to singing synthesis. Addresses specific limitation in cVAE-based approaches with principled solution.",
      "themes": [
        "Speech Synthesis",
        "Flow Matching",
        "Singing Voice Synthesis"
      ],
      "continuation": null
    },
    {
      "id": "1fab75825dd1",
      "title": "TimeColor: Flexible Reference Colorization via Temporal Concatenation",
      "content": "Most colorization models condition only on a single reference, typically the first frame of the scene. However, this approach ignores other sources of conditional data, such as character sheets, background images, or arbitrary colorized frames. We propose TimeColor, a sketch-based video colorization model that supports heterogeneous, variable-count references with the use of explicit per-reference region assignment. TimeColor encodes references as additional latent frames which are concatenated temporally, permitting them to be processed concurrently in each diffusion step while keeping the model's parameter count fixed. TimeColor also uses spatiotemporal correspondence-masked attention to enforce subject-reference binding in addition to modality-disjoint RoPE indexing. These mechanisms mitigate shortcutting and cross-identity palette leakage. Experiments on SAKUGA-42M under both single- and multi-reference protocols show that TimeColor improves color fidelity, identity consistency, and temporal stability over prior baselines.",
      "url": "http://arxiv.org/abs/2601.00296",
      "author": "Bryan Constantine Sadihin, Yihao Meng, Michael Hua Wang, Matteo Jiahao Chen, Hang Su",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes TimeColor for sketch-based video colorization supporting heterogeneous references via temporal concatenation of encoded reference frames with per-reference region assignment.",
      "importance_score": 50,
      "reasoning": "Technical contribution to video colorization with practical animation applications. Moderate novelty.",
      "themes": [
        "Video Processing",
        "Colorization",
        "Diffusion Models"
      ],
      "continuation": null
    },
    {
      "id": "de8170e94629",
      "title": "NOS-Gate: Queue-Aware Streaming IDS for Consumer Gateways under Timing-Controlled Evasion",
      "content": "Timing and burst patterns can leak through encryption, and an adaptive adversary can exploit them. This undermines metadata-only detection in a stand-alone consumer gateway. Therefore, consumer gateways need streaming intrusion detection on encrypted traffic using metadata only, under tight CPU and latency budgets. We present a streaming IDS for stand-alone gateways that instantiates a lightweight two-state unit derived from Network-Optimised Spiking (NOS) dynamics per flow, named NOS-Gate. NOS-Gate scores fixed-length windows of metadata features and, under a $K$-of-$M$ persistence rule, triggers a reversible mitigation that temporarily reduces the flow's weight under weighted fair queueing (WFQ). We evaluate NOS-Gate under timing-controlled evasion using an executable 'worlds' benchmark that specifies benign device processes, auditable attacker budgets, contention structure, and packet-level WFQ replay to quantify queue impact. All methods are calibrated label-free via burn-in quantile thresholding. Across multiple reproducible worlds and malicious episodes, at an achieved $0.1%$ false-positive operating point, NOS-Gate attains 0.952 incident recall versus 0.857 for the best baseline in these runs. Under gating, it reduces p99.9 queueing delay and p99.9 collateral delay with a mean scoring cost of ~ 2.09 {\\mu}s per flow-window on CPU.",
      "url": "http://arxiv.org/abs/2601.00389",
      "author": "Muhammad Bilal, Omer Tariq, Hasan Ahmed",
      "published": "2026-01-05",
      "source": "arXiv (cs.CR)",
      "source_type": "arxiv",
      "tags": [
        "cs.CR"
      ],
      "summary": "Proposes NOS-Gate, a streaming intrusion detection system for consumer gateways using spiking dynamics with persistence rules and WFQ mitigation under timing-controlled evasion attacks.",
      "importance_score": 50,
      "reasoning": "Novel neuromorphic approach to practical security problem but narrow application.",
      "themes": [
        "Intrusion Detection",
        "Network Security",
        "Neuromorphic Computing"
      ],
      "continuation": null
    },
    {
      "id": "f573ececd149",
      "title": "Secure, Verifiable, and Scalable Multi-Client Data Sharing via Consensus-Based Privacy-Preserving Data Distribution",
      "content": "We propose the Consensus-Based Privacy-Preserving Data Distribution (CPPDD) framework, a lightweight and post-setup autonomous protocol for secure multi-client data aggregation. The framework enforces unanimous-release confidentiality through a dual-layer protection mechanism that combines per-client affine masking with priority-driven sequential consensus locking. Decentralized integrity is verified via step (sigma_S) and data (sigma_D) checksums, facilitating autonomous malicious deviation detection and atomic abort without requiring persistent coordination. The design supports scalar, vector, and matrix payloads with O(N*D) computation and communication complexity, optional edge-server offloading, and resistance to collusion under N-1 corruptions. Formal analysis proves correctness, Consensus-Dependent Integrity and Fairness (CDIF) with overwhelming-probability abort on deviation, and IND-CPA security assuming a pseudorandom function family. Empirical evaluations on MNIST-derived vectors demonstrate linear scalability up to N = 500 with sub-millisecond per-client computation times. The framework achieves 100% malicious deviation detection, exact data recovery, and three-to-four orders of magnitude lower FLOPs compared to MPC and HE baselines. CPPDD enables atomic collaboration in secure voting, consortium federated learning, blockchain escrows, and geo-information capacity building, addressing critical gaps in scalability, trust minimization, and verifiable multi-party computation for regulated and resource-constrained environments.",
      "url": "http://arxiv.org/abs/2601.00418",
      "author": "Prajwal Panth, Sahaj Raj Malla",
      "published": "2026-01-05",
      "source": "arXiv (cs.CR)",
      "source_type": "arxiv",
      "tags": [
        "cs.CR"
      ],
      "summary": "Proposes CPPDD framework for secure multi-client data aggregation using dual-layer affine masking with priority-driven consensus locking, supporting O(N*D) complexity.",
      "importance_score": 50,
      "reasoning": "Practical privacy-preserving protocol but incremental over existing secure aggregation methods.",
      "themes": [
        "Privacy-Preserving ML",
        "Secure Aggregation",
        "Cryptography"
      ],
      "continuation": null
    },
    {
      "id": "fbdf78744bde",
      "title": "All-in-One Video Restoration under Smoothly Evolving Unknown Weather Degradations",
      "content": "All-in-one image restoration aims to recover clean images from diverse unknown degradations using a single model. But extending this task to videos faces unique challenges. Existing approaches primarily focus on frame-wise degradation variation, overlooking the temporal continuity that naturally exists in real-world degradation processes. In practice, degradation types and intensities evolve smoothly over time, and multiple degradations may coexist or transition gradually. In this paper, we introduce the Smoothly Evolving Unknown Degradations (SEUD) scenario, where both the active degradation set and degradation intensity change continuously over time. To support this scenario, we design a flexible synthesis pipeline that generates temporally coherent videos with single, compound, and evolving degradations. To address the challenges in the SEUD scenario, we propose an all-in-One Recurrent Conditional and Adaptive prompting Network (ORCANet). First, a Coarse Intensity Estimation Dehazing (CIED) module estimates haze intensity using physical priors and provides coarse dehazed features as initialization. Second, a Flow Prompt Generation (FPG) module extracts degradation features. FPG generates both static prompts that capture segment-level degradation types and dynamic prompts that adapt to frame-level intensity variations. Furthermore, a label-aware supervision mechanism improves the discriminability of static prompt representations under different degradations. Extensive experiments show that ORCANet achieves superior restoration quality, temporal consistency, and robustness over image and video-based baselines. Code is available at https://github.com/Friskknight/ORCANet-SEUD.",
      "url": "http://arxiv.org/abs/2601.00533",
      "author": "Wenrui Li, Hongtao Chen, Yao Xiao, Wangmeng Zuo, Jiantao Zhou, Yonghong Tian, Xiaopeng Fan",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Introduces Smoothly Evolving Unknown Degradations (SEUD) scenario for video restoration where degradation types and intensities change continuously over time, with flexible synthesis pipeline for temporally coherent degradation.",
      "importance_score": 50,
      "reasoning": "Novel and realistic problem formulation for video restoration. Addresses important temporal coherence gap. Methodology contribution is solid.",
      "themes": [
        "Video Restoration",
        "Computer Vision",
        "Temporal Modeling"
      ],
      "continuation": null
    },
    {
      "id": "1780766a675c",
      "title": "DynaDrag: Dynamic Drag-Style Image Editing by Motion Prediction",
      "content": "To achieve pixel-level image manipulation, drag-style image editing which edits images using points or trajectories as conditions is attracting widespread attention. Most previous methods follow move-and-track framework, in which miss tracking and ambiguous tracking are unavoidable challenging issues. Other methods under different frameworks suffer from various problems like the huge gap between source image and target edited image as well as unreasonable intermediate point which can lead to low editability. To avoid these problems, we propose DynaDrag, the first dragging method under predict-and-move framework. In DynaDrag, Motion Prediction and Motion Supervision are performed iteratively. In each iteration, Motion Prediction first predicts where the handle points should move, and then Motion Supervision drags them accordingly. We also propose to dynamically adjust the valid handle points to further improve the performance. Experiments on face and human datasets showcase the superiority over previous works.",
      "url": "http://arxiv.org/abs/2601.00542",
      "author": "Jiacheng Sui and Yujie Zhou and Li Niu",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes DynaDrag, first drag-style image editing method under predict-and-move framework using Motion Prediction and Motion Supervision to avoid tracking issues in previous methods.",
      "importance_score": 50,
      "reasoning": "Novel framework paradigm for drag-based editing. Addresses fundamental issues with move-and-track approaches. Good problem formulation.",
      "themes": [
        "Image Editing",
        "Computer Vision",
        "Generative Models"
      ],
      "continuation": null
    },
    {
      "id": "ca71d844d98b",
      "title": "Learning to be Reproducible: Custom Loss Design for Robust Neural Networks",
      "content": "To enhance the reproducibility and reliability of deep learning models, we address a critical gap in current training methodologies: the lack of mechanisms that ensure consistent and robust performance across runs. Our empirical analysis reveals that even under controlled initialization and training conditions, the accuracy of the model can exhibit significant variability. To address this issue, we propose a Custom Loss Function (CLF) that reduces the sensitivity of training outcomes to stochastic factors such as weight initialization and data shuffling. By fine-tuning its parameters, CLF explicitly balances predictive accuracy with training stability, leading to more consistent and reliable model performance. Extensive experiments across diverse architectures for both image classification and time series forecasting demonstrate that our approach significantly improves training robustness without sacrificing predictive performance. These results establish CLF as an effective and efficient strategy for developing more stable, reliable and trustworthy neural networks.",
      "url": "http://arxiv.org/abs/2601.00578",
      "author": "Waqas Ahmed, Sheeba Samuel, Kevin Coakley, Birgitta Koenig-Ries, Odd Erik Gundersen",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes Custom Loss Function (CLF) to reduce sensitivity of training to stochastic factors like initialization and shuffling, balancing accuracy with stability for more reproducible models.",
      "importance_score": 50,
      "reasoning": "Addresses important reproducibility challenge. Novel loss design for training stability. Extensive experiments but focused on single approach.",
      "themes": [
        "Reproducibility",
        "Neural Network Training",
        "Optimization"
      ],
      "continuation": null
    },
    {
      "id": "e57116db8887",
      "title": "DefVINS: Visual-Inertial Odometry for Deformable Scenes",
      "content": "Deformable scenes violate the rigidity assumptions underpinning classical visual-inertial odometry (VIO), often leading to over-fitting to local non-rigid motion or severe drift when deformation dominates visual parallax. We introduce DefVINS, a visual-inertial odometry framework that explicitly separates a rigid, IMU-anchored state from a non--rigid warp represented by an embedded deformation graph. The system is initialized using a standard VIO procedure that fixes gravity, velocity, and IMU biases, after which non-rigid degrees of freedom are activated progressively as the estimation becomes well conditioned. An observability analysis is included to characterize how inertial measurements constrain the rigid motion and render otherwise unobservable modes identifiable in the presence of deformation. This analysis motivates the use of IMU anchoring and informs a conditioning-based activation strategy that prevents ill-posed updates under poor excitation. Ablation studies demonstrate the benefits of combining inertial constraints with observability-aware deformation activation, resulting in improved robustness under non-rigid environments.",
      "url": "http://arxiv.org/abs/2601.00702",
      "author": "Samuel Cerezo and Javier Civera",
      "published": "2026-01-05",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Introduces DefVINS, a visual-inertial odometry framework that separates rigid IMU-anchored state from non-rigid scene deformation represented by embedded deformation graphs. Includes observability analysis for identifiability in deformable scenes.",
      "importance_score": 50,
      "reasoning": "Addresses challenging and understudied problem of VIO in deformable environments. Solid theoretical grounding with observability analysis. Important for robotics in real-world settings but specialized audience.",
      "themes": [
        "Robotics",
        "Visual-Inertial Odometry",
        "SLAM",
        "Deformable Scenes"
      ],
      "continuation": null
    },
    {
      "id": "de9a157a3240",
      "title": "Investigating the Viability of Employing Multi-modal Large Language Models in the Context of Audio Deepfake Detection",
      "content": "While Vision-Language Models (VLMs) and Multimodal Large Language Models (MLLMs) have shown strong generalisation in detecting image and video deepfakes, their use for audio deepfake detection remains largely unexplored. In this work, we aim to explore the potential of MLLMs for audio deepfake detection. Combining audio inputs with a range of text prompts as queries to find out the viability of MLLMs to learn robust representations across modalities for audio deepfake detection. Therefore, we attempt to explore text-aware and context-rich, question-answer based prompts with binary decisions. We hypothesise that such a feature-guided reasoning will help in facilitating deeper multimodal understanding and enable robust feature learning for audio deepfake detection. We evaluate the performance of two MLLMs, Qwen2-Audio-7B-Instruct and SALMONN, in two evaluation modes: (a) zero-shot and (b) fine-tuned. Our experiments demonstrate that combining audio with a multi-prompt approach could be a viable way forward for audio deepfake detection. Our experiments show that the models perform poorly without task-specific training and struggle to generalise to out-of-domain data. However, they achieve good performance on in-domain data with minimal supervision, indicating promising potential for audio deepfake detection.",
      "url": "http://arxiv.org/abs/2601.00777",
      "author": "Akanksha Chuchra, Shukesh Reddy, Sudeepta Mishra, Abhijit Das, Abhinav Dhall",
      "published": "2026-01-05",
      "source": "arXiv (cs.SD)",
      "source_type": "arxiv",
      "tags": [
        "cs.SD"
      ],
      "summary": "Explores using multimodal LLMs for audio deepfake detection through text prompts and question-answer based reasoning, hypothesizing that feature-guided reasoning improves cross-modal understanding for this task.",
      "importance_score": 50,
      "reasoning": "Novel exploration of MLLMs for audio deepfakes, an underexplored area. Interesting cross-modal application. However, appears to be exploratory study rather than definitive methodology.",
      "themes": [
        "Audio Deepfake Detection",
        "Multimodal LLMs",
        "AI Safety"
      ],
      "continuation": null
    },
    {
      "id": "1dbc8110ef8b",
      "title": "Fusion-SSAT: Unleashing the Potential of Self-supervised Auxiliary Task by Feature Fusion for Generalized Deepfake Detection",
      "content": "In this work, we attempted to unleash the potential of self-supervised learning as an auxiliary task that can optimise the primary task of generalised deepfake detection. To explore this, we examined different combinations of the training schemes for these tasks that can be most effective. Our findings reveal that fusing the feature representation from self-supervised auxiliary tasks is a powerful feature representation for the problem at hand. Such a representation can leverage the ultimate potential and bring in a unique representation of both the self-supervised and primary tasks, achieving better performance for the primary task. We experimented on a large set of datasets, which includes DF40, FaceForensics++, Celeb-DF, DFD, FaceShifter, UADFV, and our results showed better generalizability on cross-dataset evaluation when compared with current state-of-the-art detectors.",
      "url": "http://arxiv.org/abs/2601.00789",
      "author": "Shukesh Reddy, Srijan Das, Abhijit Das",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes fusing self-supervised auxiliary task representations with primary task features for improved generalized deepfake detection, experimenting across multiple training schemes and datasets including DF40.",
      "importance_score": 50,
      "reasoning": "Solid empirical study showing value of self-supervised features for deepfake generalization. Tested on comprehensive benchmark suite. Practical contribution but limited novelty.",
      "themes": [
        "Deepfake Detection",
        "Self-Supervised Learning",
        "Computer Vision"
      ],
      "continuation": null
    },
    {
      "id": "2a6594931bb7",
      "title": "Semantic Topological Spaces",
      "content": "[ Edit 1, Correction: Originally I incorrectly used the term \"subspace\" while meaning \"quotient topology\". Thanks to AprilSR for pointing out the original version of Claim 2 was false with the original wording. ][ Edit 2, Correction: I had used the term \"monotonic\" instead of \"strictly monotonic\". Thanks to silentbob for pointing out the error. ]This post continues from the concepts in Zoom Out: Distributions in Semantic Spaces. I will be considering semantic spaces (input, output, and latent) from an informal topological perspective.Topology and geometryAn extremely terse explanation of topology is that it is the math focused on what it means for a space to be continuous, abstracted from familiar geometric properties. You may be familiar with the example that the surface of a doughnut is homeomorphic to the surface of a coffee mug. What this means is that any image you could put on the surface of a doughnut could be put on the surface of a mug without changing which points of the image connect to which others. The image will be warped, parts of it getting stretched, scaled, or squished, but those are all geometric properties, not topological properties.Applying this idea to semantic spaces gives the hypothetical idea that, for a neural network, the input space may be homeomorphic to the output space.For example, looking at the cat-dog-labeling net again, the input is the space of possible images, and within that space is the continuous distribution of images of cats and/or dogs. The distribution is continuous because some images may contain both cats and dogs, while other images may contain animals that look ambiguous, maybe a cat, maybe a dog. It is possible that this same distribution from the net's input space is also found in the net's output space.Geometrically the distribution would be different, since the geometry of the input space maps dimensions to rgb pixels while the output space maps the dimensions to whether the image is of a cat or a dog. But these a...",
      "url": "https://www.lesswrong.com/posts/QG3xpjRBNDnLCS6LP/semantic-topological-spaces",
      "author": "TristanTrim",
      "published": "2026-01-03T19:58:17.675000",
      "source": "LessWrong",
      "source_type": "research_blog",
      "tags": [],
      "summary": "Develops mathematical framework treating semantic spaces topologically, exploring how neural network operations preserve or break topological properties like continuity across input, output, and latent spaces.",
      "importance_score": 50,
      "reasoning": "Interesting theoretical framework connecting topology to semantic spaces. Continues from prior work on distributional semantics. Novel perspective but early-stage development.",
      "themes": [
        "Theoretical ML",
        "Semantics",
        "Neural Network Theory"
      ],
      "continuation": null
    },
    {
      "id": "cb03b42ff3ee",
      "title": "ReMA: A Training-Free Plug-and-Play Mixing Augmentation for Video Behavior Recognition",
      "content": "Video behavior recognition demands stable and discriminative representations under complex spatiotemporal variations. However, prevailing data augmentation strategies for videos remain largely perturbation-driven, often introducing uncontrolled variations that amplify non-discriminative factors, which finally weaken intra-class distributional structure and representation drift with inconsistent gains across temporal scales. To address these problems, we propose Representation-aware Mixing Augmentation (ReMA), a plug-and-play augmentation strategy that formulates mixing as a controlled replacement process to expand representations while preserving class-conditional stability. ReMA integrates two complementary mechanisms. Firstly, the Representation Alignment Mechanism (RAM) performs structured intra-class mixing under distributional alignment constraints, suppressing irrelevant intra-class drift while enhancing statistical reliability. Then, the Dynamic Selection Mechanism (DSM) generates motion-aware spatiotemporal masks to localize perturbations, guiding them away from discrimination-sensitive regions and promoting temporal coherence. By jointly controlling how and where mixing is applied, ReMA improves representation robustness without additional supervision or trainable parameters. Extensive experiments on diverse video behavior benchmarks demonstrate that ReMA consistently enhances generalization and robustness across different spatiotemporal granularities.",
      "url": "http://arxiv.org/abs/2601.00311",
      "author": "Feng-Qi Cui, Jinyang Huang, Sirui Zhao, Jinglong Guo, Qifan Cai, Xin Yan, Zhi Liu",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes ReMA, a plug-and-play mixing augmentation for video behavior recognition that formulates mixing as controlled replacement with representation alignment mechanism.",
      "importance_score": 49,
      "reasoning": "Practical augmentation method for video recognition but incremental contribution to existing mixing techniques.",
      "themes": [
        "Video Understanding",
        "Data Augmentation",
        "Action Recognition"
      ],
      "continuation": null
    },
    {
      "id": "7813e48e187b",
      "title": "Do LLMs Judge Distantly Supervised Named Entity Labels Well? Constructing the JudgeWEL Dataset",
      "content": "We present judgeWEL, a dataset for named entity recognition (NER) in Luxembourgish, automatically labelled and subsequently verified using large language models (LLM) in a novel pipeline. Building datasets for under-represented languages remains one of the major bottlenecks in natural language processing, where the scarcity of resources and linguistic particularities make large-scale annotation costly and potentially inconsistent. To address these challenges, we propose and evaluate a novel approach that leverages Wikipedia and Wikidata as structured sources of weak supervision. By exploiting internal links within Wikipedia articles, we infer entity types based on their corresponding Wikidata entries, thereby generating initial annotations with minimal human intervention. Because such links are not uniformly reliable, we mitigate noise by employing and comparing several LLMs to identify and retain only high-quality labelled sentences. The resulting corpus is approximately five times larger than the currently available Luxembourgish NER dataset and offers broader and more balanced coverage across entity categories, providing a substantial new resource for multilingual and low-resource NER research.",
      "url": "http://arxiv.org/abs/2601.00411",
      "author": "Alistair Plum, Laura Bernardy, Tharindu Ranasinghe",
      "published": "2026-01-05",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Presents JudgeWEL, a NER dataset for Luxembourgish using Wikipedia/Wikidata weak supervision followed by LLM verification, addressing low-resource language annotation challenges.",
      "importance_score": 49,
      "reasoning": "Useful methodology for low-resource NER but narrow language scope.",
      "themes": [
        "Low-Resource NLP",
        "Named Entity Recognition",
        "Data Annotation"
      ],
      "continuation": null
    },
    {
      "id": "289cf84fc5d4",
      "title": "Modality Dominance-Aware Optimization for Embodied RGB-Infrared Perception",
      "content": "RGB-Infrared (RGB-IR) multimodal perception is fundamental to embodied multimedia systems operating in complex physical environments. Although recent cross-modal fusion methods have advanced RGB-IR detection, the optimization dynamics caused by asymmetric modality characteristics remain underexplored. In practice, disparities in information density and feature quality introduce persistent optimization bias, leading training to overemphasize a dominant modality and hindering effective fusion. To quantify this phenomenon, we propose the Modality Dominance Index (MDI), which measures modality dominance by jointly modeling feature entropy and gradient contribution. Based on MDI, we develop a Modality Dominance-Aware Cross-modal Learning (MDACL) framework that regulates cross-modal optimization. MDACL incorporates Hierarchical Cross-modal Guidance (HCG) to enhance feature alignment and Adversarial Equilibrium Regularization (AER) to balance optimization dynamics during fusion. Extensive experiments on three RGB-IR benchmarks demonstrate that MDACL effectively mitigates optimization bias and achieves SOTA performance.",
      "url": "http://arxiv.org/abs/2601.00598",
      "author": "Xianhui Liu, Siqi Jiang, Yi Xie, Yuqing Lin, Siao Liu",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes Modality Dominance Index (MDI) quantifying dominance via feature entropy and gradient contribution, with MDACL framework regulating cross-modal optimization for RGB-IR multimodal perception.",
      "importance_score": 49,
      "reasoning": "Addresses real optimization challenge in multimodal fusion. Novel metric for modality dominance. Solid empirical analysis.",
      "themes": [
        "Multimodal Learning",
        "RGB-IR Fusion",
        "Optimization"
      ],
      "continuation": null
    },
    {
      "id": "bb00333864d9",
      "title": "The Role of Touch: Towards Optimal Tactile Sensing Distribution in Anthropomorphic Hands for Dexterous In-Hand Manipulation",
      "content": "In-hand manipulation tasks, particularly in human-inspired robotic systems, must rely on distributed tactile sensing to achieve precise control across a wide variety of tasks. However, the optimal configuration of this network of sensors is a complex problem, and while the fingertips are a common choice for placing sensors, the contribution of tactile information from other regions of the hand is often overlooked. This work investigates the impact of tactile feedback from various regions of the fingers and palm in performing in-hand object reorientation tasks. We analyze how sensory feedback from different parts of the hand influences the robustness of deep reinforcement learning control policies and investigate the relationship between object characteristics and optimal sensor placement. We identify which tactile sensing configurations contribute to improving the efficiency and accuracy of manipulation. Our results provide valuable insights for the design and use of anthropomorphic end-effectors with enhanced manipulation capabilities.",
      "url": "http://arxiv.org/abs/2509.14984",
      "author": "Jo\\~ao Dami\\~ao Almeida, Egidio Falotico, Cecilia Laschi, Jos\\'e Santos-Victor",
      "published": "2026-01-05",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Investigates how tactile feedback from different finger and palm regions affects deep RL policies for robotic in-hand manipulation. Analyzes relationship between object characteristics and optimal sensor placement beyond just fingertips.",
      "importance_score": 48,
      "reasoning": "Useful empirical study for robotic manipulation research. Provides practical insights for sensor placement in dexterous manipulation systems.",
      "themes": [
        "Robotics",
        "Tactile Sensing",
        "Reinforcement Learning",
        "Dexterous Manipulation"
      ],
      "continuation": null
    },
    {
      "id": "e446aa735ed1",
      "title": "Exploration in the Limit",
      "content": "In fixed-confidence best arm identification (BAI), the objective is to quickly identify the optimal option while controlling the probability of error below a desired threshold. Despite the plethora of BAI algorithms, existing methods typically fall short in practical settings, as stringent exact error control requires using loose tail inequalities and/or parametric restrictions. To overcome these limitations, we introduce a relaxed formulation that requires valid error control asymptotically with respect to a minimum sample size. This aligns with many real-world settings that often involve weak signals, high desired significance, and post-experiment inference requirements, all of which necessitate long horizons. This allows us to achieve tighter optimality, while better handling flexible nonparametric outcome distributions and fully leveraging individual-level contexts. We develop a novel asymptotic anytime-valid confidence sequences over arm indices, and we use it to design a new BAI algorithm for our asymptotic framework. Our method flexibly incorporates covariates for variance reduction and ensures approximate error control in fully nonparametric settings. Under mild convergence assumptions, we provide asymptotic bounds on the sample complexity and show the worst-case sample complexity of our approach matches the best-case sample complexity of Gaussian BAI under exact error guarantees and known variances. Experiments suggest our approach reduces average sample complexities while maintaining error control.",
      "url": "http://arxiv.org/abs/2601.00084",
      "author": "Brian M. Cho, Nathan Kallus",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces relaxed formulation for best arm identification requiring valid error control asymptotically rather than exactly. Enables tighter optimality for settings with weak signals, high significance requirements, and long horizons.",
      "importance_score": 48,
      "reasoning": "Theoretical contribution to multi-armed bandits with practical motivations. Novel formulation but limited empirical validation.",
      "themes": [
        "Multi-Armed Bandits",
        "Statistical Learning Theory",
        "Exploration"
      ],
      "continuation": null
    },
    {
      "id": "603c4794e4d9",
      "title": "Mortar: Evolving Mechanics for Automatic Game Design",
      "content": "We present Mortar, a system for autonomously evolving game mechanics for automatic game design. Game mechanics define the rules and interactions that govern gameplay, and designing them manually is a time-consuming and expert-driven process. Mortar combines a quality-diversity algorithm with a large language model to explore a diverse set of mechanics, which are evaluated by synthesising complete games that incorporate both evolved mechanics and those drawn from an archive. The mechanics are evaluated by composing complete games through a tree search procedure, where the resulting games are evaluated by their ability to preserve a skill-based ordering over players -- that is, whether stronger players consistently outperform weaker ones. We assess the mechanics based on their contribution towards the skill-based ordering score in the game. We demonstrate that Mortar produces games that appear diverse and playable, and mechanics that contribute more towards the skill-based ordering score in the game. We perform ablation studies to assess the role of each system component and a user study to evaluate the games based on human feedback.",
      "url": "http://arxiv.org/abs/2601.00105",
      "author": "Muhammad U. Nasir, Yuchen Li, Steven James and Julian Togelius",
      "published": "2026-01-05",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Presents Mortar, a system for autonomously evolving game mechanics using quality-diversity algorithms combined with LLMs. Evaluates mechanics by whether resulting games preserve skill-based player ordering.",
      "importance_score": 48,
      "reasoning": "Novel application of LLMs to procedural game design. Creative approach but limited evaluation of generated content quality.",
      "themes": [
        "Game AI",
        "Procedural Generation",
        "Language Models",
        "Quality-Diversity"
      ],
      "continuation": null
    },
    {
      "id": "077913c1ef25",
      "title": "Democratizing Electronic-Photonic AI Systems: An Open-Source AI-Infused Cross-Layer Co-Design and Design Automation Toolflow",
      "content": "Photonics is becoming a cornerstone technology for high-performance AI systems and scientific computing, offering unparalleled speed, parallelism, and energy efficiency. Despite this promise, the design and deployment of electronic-photonic AI systems remain highly challenging due to a steep learning curve across multiple layers, spanning device physics, circuit design, system architecture, and AI algorithms. The absence of a mature electronic-photonic design automation (EPDA) toolchain leads to long, inefficient design cycles and limits cross-disciplinary innovation and co-evolution. In this work, we present a cross-layer co-design and automation framework aimed at democratizing photonic AI system development. We begin by introducing our architecture designs for scalable photonic edge AI and Transformer inference, followed by SimPhony, an open-source modeling tool for rapid EPIC AI system evaluation and design-space exploration. We then highlight advances in AI-enabled photonic design automation, including physical AI-based Maxwell solvers, a fabrication-aware inverse design framework, and a scalable inverse training algorithm for meta-optical neural networks, enabling a scalable EPDA stack for next-generation electronic-photonic AI systems.",
      "url": "http://arxiv.org/abs/2601.00130",
      "author": "Hongjian Zhou, Ziang Yin, Jiaqi Gu",
      "published": "2026-01-05",
      "source": "arXiv (physics.optics)",
      "source_type": "arxiv",
      "tags": [
        "physics.optics"
      ],
      "summary": "Presents open-source cross-layer co-design framework for electronic-photonic AI systems, addressing the steep learning curve across device physics, circuit design, architecture, and algorithms.",
      "importance_score": 48,
      "reasoning": "Useful open-source contribution for photonic AI development. Complements hardware advances but limited novelty in methodology.",
      "themes": [
        "Photonic Computing",
        "Design Automation",
        "Open Source"
      ],
      "continuation": null
    },
    {
      "id": "a179a7beb50e",
      "title": "Understanding Emotion in Discourse: Recognition Insights and Linguistic Patterns for Generation",
      "content": "While Emotion Recognition in Conversation (ERC) has achieved high accuracy, two critical gaps remain: a limited understanding of \\textit{which} architectural choices actually matter, and a lack of linguistic analysis connecting recognition to generation. We address both gaps through a systematic analysis of the IEMOCAP dataset.   For recognition, we conduct a rigorous ablation study with 10-seed evaluation and report three key findings. First, conversational context is paramount, with performance saturating rapidly -- 90\\% of the total gain achieved within just the most recent 10--30 preceding turns (depending on the label set). Second, hierarchical sentence representations help at utterance-level, but this benefit disappears once conversational context is provided, suggesting that context subsumes intra-utterance structure. Third, external affective lexicons (SenticNet) provide no gain, indicating that pre-trained encoders already capture necessary emotional semantics. With simple architectures using strictly causal context, we achieve 82.69\\% (4-way) and 67.07\\% (6-way) weighted F1, outperforming prior text-only methods including those using bidirectional context.   For linguistic analysis, we analyze 5,286 discourse marker occurrences and find a significant association between emotion and marker positioning ($p < .0001$). Notably, \"sad\" utterances exhibit reduced left-periphery marker usage (21.9\\%) compared to other emotions (28--32\\%), consistent with theories linking left-periphery markers to active discourse management. This connects to our recognition finding that sadness benefits most from context (+22\\%p): lacking explicit pragmatic signals, sad utterances require conversational history for disambiguation.",
      "url": "http://arxiv.org/abs/2601.00181",
      "author": "Cheonkam Jeong, Adeline Nyamathi",
      "published": "2026-01-05",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Conducts systematic ablation study on Emotion Recognition in Conversation finding that conversational context is paramount, with 90% of gain achieved within 10-30 preceding turns. Hierarchical representations help at utterance-level but not with context.",
      "importance_score": 48,
      "reasoning": "Useful empirical findings for ERC research. Rigorous methodology with practical insights for architecture design.",
      "themes": [
        "Emotion Recognition",
        "Dialogue Systems",
        "Natural Language Processing"
      ],
      "continuation": null
    },
    {
      "id": "358dbc9457d8",
      "title": "Knowledge Distillation for Temporal Knowledge Graph Reasoning with Large Language Models",
      "content": "Reasoning over temporal knowledge graphs (TKGs) is fundamental to improving the efficiency and reliability of intelligent decision-making systems and has become a key technological foundation for future artificial intelligence applications. Despite recent progress, existing TKG reasoning models typically rely on large parameter sizes and intensive computation, leading to high hardware costs and energy consumption. These constraints hinder their deployment on resource-constrained, low-power, and distributed platforms that require real-time inference. Moreover, most existing model compression and distillation techniques are designed for static knowledge graphs and fail to adequately capture the temporal dependencies inherent in TKGs, often resulting in degraded reasoning performance. To address these challenges, we propose a distillation framework specifically tailored for temporal knowledge graph reasoning. Our approach leverages large language models as teacher models to guide the distillation process, enabling effective transfer of both structural and temporal reasoning capabilities to lightweight student models. By integrating large-scale public knowledge with task-specific temporal information, the proposed framework enhances the student model's ability to model temporal dynamics while maintaining a compact and efficient architecture. Extensive experiments on multiple publicly available benchmark datasets demonstrate that our method consistently outperforms strong baselines, achieving a favorable trade-off between reasoning accuracy, computational efficiency, and practical deployability.",
      "url": "http://arxiv.org/abs/2601.00202",
      "author": "Wang Xing, Wei Song, Siyu Lin, Chen Wu, Zhesi Li, Man Wang",
      "published": "2026-01-05",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Develops LLM-based knowledge distillation for temporal knowledge graph reasoning to reduce computational costs while capturing temporal dependencies. Addresses deployment constraints on resource-limited platforms.",
      "importance_score": 48,
      "reasoning": "Addresses practical deployment challenge for TKG reasoning. Combines knowledge distillation with LLMs for compression.",
      "themes": [
        "Knowledge Graphs",
        "Knowledge Distillation",
        "Language Models",
        "Temporal Reasoning"
      ],
      "continuation": null
    },
    {
      "id": "42f626c40dce",
      "title": "SLAP: Slapband-based Autonomous Perching Drone with Failure Recovery for Vertical Tree Trunks",
      "content": "Perching allows unmanned aerial vehicles (UAVs) to reduce energy consumption, remain anchored for surface sampling operations, or stably survey their surroundings. Previous efforts for perching on vertical surfaces have predominantly focused on lightweight mechanical design solutions with relatively scant system-level integration. Furthermore, perching strategies for vertical surfaces commonly require high-speed, aggressive landing operations that are dangerous for a surveyor drone with sensitive electronics onboard. This work presents the preliminary investigation of a perching approach suitable for larger drones that both gently perches on vertical tree trunks and reacts and recovers from perch failures. The system in this work, called SLAP, consists of vision-based perch site detector, an IMU (inertial-measurement-unit)-based perch failure detector, an attitude controller for soft perching, an optical close-range detection system, and a fast active elastic gripper with microspines made from commercially-available slapbands. We validated this approach on a modified 1.2 kg commercial quadrotor with component and system analysis. Initial human-in-the-loop autonomous indoor flight experiments achieved a 75% perch success rate on a real oak tree segment across 20 flights, and 100% perch failure recovery across 2 flights with induced failures.",
      "url": "http://arxiv.org/abs/2601.00238",
      "author": "Julia Di, Kenneth A. W. Hoffmann, Tony G. Chen, Tian-Ao Ren, Mark R. Cutkosky",
      "published": "2026-01-05",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Presents SLAP, a drone perching system for vertical tree trunks using slapband-based mechanism with vision-based site detection and failure recovery capabilities.",
      "importance_score": 48,
      "reasoning": "Practical robotics engineering with novel mechanism design, but narrow application scope.",
      "themes": [
        "Robotics",
        "Autonomous Drones",
        "Manipulation"
      ],
      "continuation": null
    },
    {
      "id": "fe5a905ba833",
      "title": "Benchmarking Preprocessing and Integration Methods in Single-Cell Genomics",
      "content": "Single-cell data analysis has the potential to revolutionize personalized medicine by characterizing disease-associated molecular changes at the single-cell level. Advanced single-cell multimodal assays can now simultaneously measure various molecules (e.g., DNA, RNA, Protein) across hundreds of thousands of individual cells, providing a comprehensive molecular readout. A significant analytical challenge is integrating single-cell measurements across different modalities. Various methods have been developed to address this challenge, but there has been no systematic evaluation of these techniques with different preprocessing strategies. This study examines a general pipeline for single-cell data analysis, which includes normalization, data integration, and dimensionality reduction. The performance of different algorithm combinations often depends on the dataset sizes and characteristics. We evaluate six datasets across diverse modalities, tissues, and organisms using three metrics: Silhouette Coefficient Score, Adjusted Rand Index, and Calinski-Harabasz Index. Our experiments involve combinations of seven normalization methods, four dimensional reduction methods, and five integration methods. The results show that Seurat and Harmony excel in data integration, with Harmony being more time-efficient, especially for large datasets. UMAP is the most compatible dimensionality reduction method with the integration techniques, and the choice of normalization method varies depending on the integration method used.",
      "url": "http://arxiv.org/abs/2601.00277",
      "author": "Ali Anaissi, Seid Miad Zandavi, Weidong Huang, Junaid Akram, Basem Suleiman, Ali Braytee, Jie Hua",
      "published": "2026-01-05",
      "source": "arXiv (q-bio.QM)",
      "source_type": "arxiv",
      "tags": [
        "q-bio.QM"
      ],
      "summary": "Benchmarks preprocessing and integration methods for single-cell multimodal genomics data, evaluating normalization, integration, and dimensionality reduction techniques.",
      "importance_score": 48,
      "reasoning": "Useful benchmarking study for bioinformatics community but limited ML novelty.",
      "themes": [
        "Bioinformatics",
        "Single-Cell Analysis",
        "Benchmarks"
      ],
      "continuation": null
    },
    {
      "id": "d627df10cb38",
      "title": "Mask-Conditioned Voxel Diffusion for Joint Geometry and Color Inpainting",
      "content": "We present a lightweight two-stage framework for joint geometry and color inpainting of damaged 3D objects, motivated by the digital restoration of cultural heritage artifacts. The pipeline separates damage localization from reconstruction. In the first stage, a 2D convolutional network predicts damage masks on RGB slices extracted from a voxelized object, and these predictions are aggregated into a volumetric mask. In the second stage, a diffusion-based 3D U-Net performs mask-conditioned inpainting directly on voxel grids, reconstructing geometry and color while preserving observed regions. The model jointly predicts occupancy and color using a composite objective that combines occupancy reconstruction with masked color reconstruction and perceptual regularization. We evaluate the approach on a curated set of textured artifacts with synthetically generated damage using standard geometric and color metrics. Compared to symmetry-based baselines, our method produces more complete geometry and more coherent color reconstructions at a fixed 32^3 resolution. Overall, the results indicate that explicit mask conditioning is a practical way to guide volumetric diffusion models for joint 3D geometry and color inpainting.",
      "url": "http://arxiv.org/abs/2601.00368",
      "author": "Aarya Sumuk",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Presents two-stage framework for joint geometry and color inpainting of damaged 3D objects using mask prediction on RGB slices followed by diffusion-based voxel inpainting.",
      "importance_score": 48,
      "reasoning": "Interesting application for cultural heritage but narrow scope.",
      "themes": [
        "3D Reconstruction",
        "Cultural Heritage",
        "Diffusion Models"
      ],
      "continuation": null
    },
    {
      "id": "2764a20cef18",
      "title": "Progressive Ideation using an Agentic AI Framework for Human-AI Co-Creation",
      "content": "The generation of truly novel and diverse ideas is important for contemporary engineering design, yet it remains a significant cognitive challenge for novice designers. Current 'single-spurt' AI systems exacerbate this challenge by producing a high volume of semantically clustered ideas. We propose MIDAS (Meta-cognitive Ideation through Distributed Agentic AI System), a novel framework that replaces the single-AI paradigm with a distributed 'team' of specialized AI agents designed to emulate the human meta-cognitive ideation workflow. This agentic system progressively refines ideas and assesses each one for both global novelty (against existing solutions) and local novelty (against previously generated ideas). MIDAS, therefore, demonstrates a viable and progressive paradigm for true human-AI co-creation, elevating the human designer from a passive filterer to a participatory, active, collaborative partner.",
      "url": "http://arxiv.org/abs/2601.00475",
      "author": "Sankar B, Srinidhi Ranjini Girish, Aadya Bharti, Dibakar Sen",
      "published": "2026-01-05",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Proposes MIDAS, a multi-agent framework for engineering design ideation where specialized AI agents emulate human meta-cognitive workflow to progressively refine ideas while assessing global and local novelty.",
      "importance_score": 48,
      "reasoning": "Novel application of multi-agent systems to design ideation. Addresses important human-AI collaboration scenario but evaluation methodology needs strengthening.",
      "themes": [
        "Multi-Agent Systems",
        "Human-AI Collaboration",
        "Design Automation"
      ],
      "continuation": null
    },
    {
      "id": "3f8c3b3c0ae5",
      "title": "Retrieval--Reasoning Processes for Multi-hop Question Answering: A Four-Axis Design Framework and Empirical Trends",
      "content": "Multi-hop question answering (QA) requires systems to iteratively retrieve evidence and reason across multiple hops. While recent RAG and agentic methods report strong results, the underlying retrieval--reasoning \\emph{process} is often left implicit, making procedural choices hard to compare across model families. This survey takes the execution procedure as the unit of analysis and introduces a four-axis framework covering (A) overall execution plan, (B) index structure, (C) next-step control (strategies and triggers), and (D) stop/continue criteria. Using this schema, we map representative multi-hop QA systems and synthesize reported ablations and tendencies on standard benchmarks (e.g., HotpotQA, 2WikiMultiHopQA, MuSiQue), highlighting recurring trade-offs among effectiveness, efficiency, and evidence faithfulness. We conclude with open challenges for retrieval--reasoning agents, including structure-aware planning, transferable control policies, and robust stopping under distribution shift.",
      "url": "http://arxiv.org/abs/2601.00536",
      "author": "Yuelyu Ji, Zhuochun Li, Rui Meng, Daqing He",
      "published": "2026-01-05",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Survey paper introducing four-axis framework for analyzing multi-hop QA systems covering execution plan, index structure, control strategies, and stopping criteria. Maps representative systems and synthesizes trends.",
      "importance_score": 48,
      "reasoning": "Useful systematization of multi-hop QA methods. Framework provides common vocabulary for comparison. Survey nature limits novelty.",
      "themes": [
        "Question Answering",
        "RAG",
        "Survey",
        "Information Retrieval"
      ],
      "continuation": null
    },
    {
      "id": "c769693cb451",
      "title": "Improving Scientific Document Retrieval with Academic Concept Index",
      "content": "Adapting general-domain retrievers to scientific domains is challenging due to the scarcity of large-scale domain-specific relevance annotations and the substantial mismatch in vocabulary and information needs. Recent approaches address these issues through two independent directions that leverage large language models (LLMs): (1) generating synthetic queries for fine-tuning, and (2) generating auxiliary contexts to support relevance matching. However, both directions overlook the diverse academic concepts embedded within scientific documents, often producing redundant or conceptually narrow queries and contexts. To address this limitation, we introduce an academic concept index, which extracts key concepts from papers and organizes them guided by an academic taxonomy. This structured index serves as a foundation for improving both directions. First, we enhance the synthetic query generation with concept coverage-based generation (CCQGen), which adaptively conditions LLMs on uncovered concepts to generate complementary queries with broader concept coverage. Second, we strengthen the context augmentation with concept-focused auxiliary contexts (CCExpand), which leverages a set of document snippets that serve as concise responses to the concept-aware CCQGen queries. Extensive experiments show that incorporating the academic concept index into both query generation and context augmentation leads to higher-quality queries, better conceptual alignment, and improved retrieval performance.",
      "url": "http://arxiv.org/abs/2601.00567",
      "author": "Jeyun Lee, Junhyoung Lee, Wonbin Kweon, Bowen Jin, Yu Zhang, Susik Yoon, Dongha Lee, Hwanjo Yu, Jiawei Han, Seongku Kang",
      "published": "2026-01-05",
      "source": "arXiv (cs.IR)",
      "source_type": "arxiv",
      "tags": [
        "cs.IR"
      ],
      "summary": "Introduces academic concept index for scientific document retrieval, extracting key concepts from papers organized by academic taxonomy to improve query and context generation beyond redundant LLM outputs.",
      "importance_score": 48,
      "reasoning": "Addresses practical limitation in scientific retrieval. Novel use of taxonomy-guided concept extraction. Multiple author team including Jiawei Han.",
      "themes": [
        "Information Retrieval",
        "Scientific Documents",
        "Knowledge Organization"
      ],
      "continuation": null
    },
    {
      "id": "595f3ccae4c4",
      "title": "HyperPriv-EPN: Hypergraph Learning with Privileged Knowledge for Ependymoma Prognosis",
      "content": "Preoperative prognosis of Ependymoma is critical for treatment planning but challenging due to the lack of semantic insights in MRI compared to post-operative surgical reports. Existing multimodal methods fail to leverage this privileged text data when it is unavailable during inference. To bridge this gap, we propose HyperPriv-EPN, a hypergraph-based Learning Using Privileged Information (LUPI) framework. We introduce a Severed Graph Strategy, utilizing a shared encoder to process both a Teacher graph (enriched with privileged post-surgery information) and a Student graph (restricted to pre-operation data). Through dual-stream distillation, the Student learns to hallucinate semantic community structures from visual features alone. Validated on a multi-center cohort of 311 patients, HyperPriv-EPN achieves state-of-the-art diagnostic accuracy and survival stratification. This effectively transfers expert knowledge to the preoperative setting, unlocking the value of historical post-operative data to guide the diagnosis of new patients without requiring text at inference.",
      "url": "http://arxiv.org/abs/2601.00626",
      "author": "Shuren Gabriel Yu, Sikang Ren, Yongji Tian",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes HyperPriv-EPN using hypergraph-based Learning Using Privileged Information for ependymoma prognosis, enabling student model to learn from teacher with post-surgery information unavailable at inference.",
      "importance_score": 48,
      "reasoning": "Novel application of LUPI paradigm to medical imaging. Addresses practical clinical constraint. Validated on multi-center cohort.",
      "themes": [
        "Medical AI",
        "Privileged Information",
        "Graph Learning"
      ],
      "continuation": null
    },
    {
      "id": "b24c5624d8f1",
      "title": "Exploring the Performance of Large Language Models on Subjective Span Identification Tasks",
      "content": "Identifying relevant text spans is important for several downstream tasks in NLP, as it contributes to model explainability. While most span identification approaches rely on relatively smaller pre-trained language models like BERT, a few recent approaches have leveraged the latest generation of Large Language Models (LLMs) for the task. Current work has focused on explicit span identification like Named Entity Recognition (NER), while more subjective span identification with LLMs in tasks like Aspect-based Sentiment Analysis (ABSA) has been underexplored. In this paper, we fill this important gap by presenting an evaluation of the performance of various LLMs on text span identification in three popular tasks, namely sentiment analysis, offensive language identification, and claim verification. We explore several LLM strategies like instruction tuning, in-context learning, and chain of thought. Our results indicate underlying relationships within text aid LLMs in identifying precise text spans.",
      "url": "http://arxiv.org/abs/2601.00736",
      "author": "Alphaeus Dmonte, Roland Oruche, Tharindu Ranasinghe, Marcos Zampieri, Prasad Calyam",
      "published": "2026-01-05",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Evaluates LLM performance on subjective span identification tasks including aspect-based sentiment analysis, comparing against BERT-class models. Addresses gap in understanding LLM capabilities for implicit span identification.",
      "importance_score": 48,
      "reasoning": "Fills useful evaluation gap for LLMs on span identification. Multiple task evaluation provides broader picture. However, primarily an evaluation study without major methodological contribution.",
      "themes": [
        "Large Language Models",
        "Natural Language Processing",
        "Evaluation"
      ],
      "continuation": null
    },
    {
      "id": "33481e1b5863",
      "title": "Unified Primitive Proxies for Structured Shape Completion",
      "content": "Structured shape completion recovers missing geometry as primitives rather than as unstructured points, which enables primitive-based surface reconstruction. Instead of following the prevailing cascade, we rethink how primitives and points should interact, and find it more effective to decode primitives in a dedicated pathway that attends to shared shape features. Following this principle, we present UniCo, which in a single feed-forward pass predicts a set of primitives with complete geometry, semantics, and inlier membership. To drive this unified representation, we introduce primitive proxies, learnable queries that are contextualized to produce assembly-ready outputs. To ensure consistent optimization, our training strategy couples primitives and points with online target updates. Across synthetic and real-world benchmarks with four independent assembly solvers, UniCo consistently outperforms recent baselines, lowering Chamfer distance by up to 50% and improving normal consistency by up to 7%. These results establish an attractive recipe for structured 3D understanding from incomplete data. Project page: https://unico-completion.github.io.",
      "url": "http://arxiv.org/abs/2601.00759",
      "author": "Zhaiyu Chen, Yuqing Wang, Xiao Xiang Zhu",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Presents UniCo for structured shape completion using primitive proxies, learnable queries that produce assembly-ready primitives with geometry, semantics, and inlier membership in single feed-forward pass.",
      "importance_score": 48,
      "reasoning": "Novel architecture for primitive-based shape completion. Clean single-pass design is attractive. Moderate contribution to 3D vision but specialized application.",
      "themes": [
        "3D Vision",
        "Shape Completion",
        "Point Cloud Processing"
      ],
      "continuation": null
    },
    {
      "id": "23d1980859d4",
      "title": "Identification and Estimation under Multiple Versions of Treatment: Mixture-of-Experts Approach",
      "content": "The Stable Unit Treatment Value Assumption (SUTVA) includes the condition that there are no multiple versions of treatment in causal inference. Though we could not control the implementation of treatment in observational studies, multiple versions may exist in the treatment. It has been pointed out that ignoring such multiple versions of treatment can lead to biased estimates of causal effects, but a causal inference framework that explicitly deals with the unbiased identification and estimation of version-specific causal effects has not been fully developed yet. Thus, obtaining a deeper understanding for mechanisms of the complex treatments is difficult. In this paper, we introduce the Mixture-of-Experts framework into causal inference and develop a methodology for estimating the causal effects of latent versions. This approach enables explicit estimation of version-specific causal effects even if the versions are not observed. Numerical experiments demonstrate the effectiveness of the proposed method.",
      "url": "http://arxiv.org/abs/2601.00287",
      "author": "Kohei Yoshikawa, Shuichi Kawano",
      "published": "2026-01-05",
      "source": "arXiv (stat.ME)",
      "source_type": "arxiv",
      "tags": [
        "stat.ME"
      ],
      "summary": "Introduces Mixture-of-Experts framework for causal inference with multiple treatment versions, addressing unbiased identification and estimation when treatment implementation varies in observational studies.",
      "importance_score": 48,
      "reasoning": "Novel application of MoE to causal inference for multiple treatment versions. Addresses real methodological gap. Relevant for observational studies but specialized audience.",
      "themes": [
        "Causal Inference",
        "Mixture of Experts",
        "Statistical Methods"
      ],
      "continuation": null
    },
    {
      "id": "b27565a4a0bb",
      "title": "U-Net-Like Spiking Neural Networks for Single Image Dehazing",
      "content": "Image dehazing is a critical challenge in computer vision, essential for enhancing image clarity in hazy conditions. Traditional methods often rely on atmospheric scattering models, while recent deep learning techniques, specifically Convolutional Neural Networks (CNNs) and Transformers, have improved performance by effectively analyzing image features. However, CNNs struggle with long-range dependencies, and Transformers demand significant computational resources. To address these limitations, we propose DehazeSNN, an innovative architecture that integrates a U-Net-like design with Spiking Neural Networks (SNNs). DehazeSNN captures multi-scale image features while efficiently managing local and long-range dependencies. The introduction of the Orthogonal Leaky-Integrate-and-Fire Block (OLIFBlock) enhances cross-channel communication, resulting in superior dehazing performance with reduced computational burden. Our extensive experiments show that DehazeSNN is highly competitive to state-of-the-art methods on benchmark datasets, delivering high-quality haze-free images with a smaller model size and less multiply-accumulate operations. The proposed dehazing method is publicly available at https://github.com/HaoranLiu507/DehazeSNN.",
      "url": "http://arxiv.org/abs/2512.23950",
      "author": "Huibin Li, Haoran Liu, Mingzhe Liu, Yulong Xiao, Peng Li, Guibin Zan",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes DehazeSNN, combining U-Net architecture with Spiking Neural Networks for image dehazing. Introduces Orthogonal Leaky-Integrate-and-Fire Block to capture multi-scale features while managing local and long-range dependencies efficiently.",
      "importance_score": 47,
      "reasoning": "Novel architecture combining SNNs with U-Net for low-level vision task. Interesting for neuromorphic computing but limited comparison with SOTA and unclear efficiency gains.",
      "themes": [
        "Computer Vision",
        "Spiking Neural Networks",
        "Image Restoration"
      ],
      "continuation": null
    },
    {
      "id": "b2a4a545e0f2",
      "title": "Focal-RegionFace: Generating Fine-Grained Multi-attribute Descriptions for Arbitrarily Selected Face Focal Regions",
      "content": "In this paper, we introduce an underexplored problem in facial analysis: generating and recognizing multi-attribute natural language descriptions, containing facial action units (AUs), emotional states, and age estimation, for arbitrarily selected face regions (termed FaceFocalDesc). We argue that the system's ability to focus on individual facial areas leads to better understanding and control. To achieve this capability, we construct a new multi-attribute description dataset for arbitrarily selected face regions, providing rich region-level annotations and natural language descriptions. Further, we propose a fine-tuned vision-language model based on Qwen2.5-VL, called Focal-RegionFace for facial state analysis, which incrementally refines its focus on localized facial features through multiple progressively fine-tuning stages, resulting in interpretable age estimation, FAU and emotion detection. Experimental results show that Focal-RegionFace achieves the best performance on the new benchmark in terms of traditional and widely used metrics, as well as new proposed metrics. This fully verifies its effectiveness and versatility in fine-grained multi-attribute face region-focal analysis scenarios.",
      "url": "http://arxiv.org/abs/2601.00156",
      "author": "Kaiwen Zheng, Junchen Fu, Songpei Xu, Yaoqing He, Joemon M.Jose, Han Hu, Xuri Ge",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Introduces Focal-RegionFace for generating multi-attribute descriptions (AUs, emotions, age) for arbitrarily selected face regions. Fine-tunes Qwen2.5-VL with new dataset of region-level annotations.",
      "importance_score": 47,
      "reasoning": "Novel task formulation for fine-grained facial analysis. Dataset contribution with practical applications but limited novelty in methodology.",
      "themes": [
        "Vision-Language Models",
        "Facial Analysis",
        "Region-Level Understanding"
      ],
      "continuation": null
    },
    {
      "id": "321f0842b8fd",
      "title": "VisNet: Efficient Person Re-Identification via Alpha-Divergence Loss, Feature Fusion and Dynamic Multi-Task Learning",
      "content": "Person re-identification (ReID) is an extremely important area in both surveillance and mobile applications, requiring strong accuracy with minimal computational cost. State-of-the-art methods give good accuracy but with high computational budgets. To remedy this, this paper proposes VisNet, a computationally efficient and effective re-identification model suitable for real-world scenarios. It is the culmination of conceptual contributions, including feature fusion at multiple scales with automatic attention on each, semantic clustering with anatomical body partitioning, a dynamic weight averaging technique to balance classification semantic regularization, and the use of loss function FIDI for improved metric learning tasks. The multiple scales fuse ResNet50's stages 1 through 4 without the use of parallel paths, with semantic clustering introducing spatial constraints through the use of rule-based pseudo-labeling. VisNet achieves 87.05% Rank-1 and 77.65% mAP on the Market-1501 dataset, having 32.41M parameters and 4.601 GFLOPs, hence, proposing a practical approach for real-time deployment in surveillance and mobile applications where computational resources are limited.",
      "url": "http://arxiv.org/abs/2601.00307",
      "author": "Anns Ijaz, Muhammad Azeem Javed",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes VisNet for efficient person re-identification using multi-scale feature fusion, anatomical body partitioning, dynamic weight averaging, and FIDI loss function.",
      "importance_score": 47,
      "reasoning": "Combines multiple techniques for efficient person ReID but limited novelty in individual components.",
      "themes": [
        "Person Re-Identification",
        "Computer Vision",
        "Efficiency"
      ],
      "continuation": null
    },
    {
      "id": "ec6d7d5836a8",
      "title": "Solving nonlinear subsonic compressible flow in infinite domain via multi-stage neural networks",
      "content": "In aerodynamics, accurately modeling subsonic compressible flow over airfoils is critical for aircraft design. However, solving the governing nonlinear perturbation velocity potential equation presents computational challenges. Traditional approaches often rely on linearized equations or finite, truncated domains, which introduce non-negligible errors and limit applicability in real-world scenarios. In this study, we propose a novel framework utilizing Physics-Informed Neural Networks (PINNs) to solve the full nonlinear compressible potential equation in an unbounded (infinite) domain. We address the unbounded-domain and convergence challenges inherent in standard PINNs by incorporating a coordinate transformation and embedding physical asymptotic constraints directly into the network architecture. Furthermore, we employ a Multi-Stage PINN (MS-PINN) approach to iteratively minimize residuals, achieving solution accuracy approaching machine precision. We validate this framework by simulating flow over circular and elliptical geometries, comparing our results against traditional finite-domain and linearized solutions. Our findings quantify the noticeable discrepancies introduced by domain truncation and linearization, particularly at higher Mach numbers, and demonstrate that this new framework is a robust, high-fidelity tool for computational fluid dynamics.",
      "url": "http://arxiv.org/abs/2601.00342",
      "author": "Xuehui Qian, Hongkai Tao, Yongji Wang",
      "published": "2026-01-05",
      "source": "arXiv (physics.flu-dyn)",
      "source_type": "arxiv",
      "tags": [
        "physics.flu-dyn"
      ],
      "summary": "Proposes multi-stage PINN framework for solving nonlinear compressible potential equation in unbounded domain using coordinate transformation and asymptotic constraints.",
      "importance_score": 47,
      "reasoning": "Solid application of PINNs to aerodynamics with practical engineering value.",
      "themes": [
        "Physics-Informed Neural Networks",
        "Computational Fluid Dynamics"
      ],
      "continuation": null
    },
    {
      "id": "89ff0ad59a0f",
      "title": "Boosting Segment Anything Model to Generalize Visually Non-Salient Scenarios",
      "content": "Segment Anything Model (SAM), known for its remarkable zero-shot segmentation capabilities, has garnered significant attention in the community. Nevertheless, its performance is challenged when dealing with what we refer to as visually non-salient scenarios, where there is low contrast between the foreground and background. In these cases, existing methods often cannot capture accurate contours and fail to produce promising segmentation results. In this paper, we propose Visually Non-Salient SAM (VNS-SAM), aiming to enhance SAM's perception of visually non-salient scenarios while preserving its original zero-shot generalizability. We achieve this by effectively exploiting SAM's low-level features through two designs: Mask-Edge Token Interactive decoder and Non-Salient Feature Mining module. These designs help the SAM decoder gain a deeper understanding of non-salient characteristics with only marginal parameter increments and computational requirements. The additional parameters of VNS-SAM can be optimized within 4 hours, demonstrating its feasibility and practicality. In terms of data, we established VNS-SEG, a unified dataset for various VNS scenarios, with more than 35K images, in contrast to previous single-task adaptations. It is designed to make the model learn more robust VNS features and comprehensively benchmark the model's segmentation performance and generalizability on VNS scenarios. Extensive experiments across various VNS segmentation tasks demonstrate the superior performance of VNS-SAM, particularly under zero-shot settings, highlighting its potential for broad real-world applications. Codes and datasets are publicly available at https://guangqian-guo.github.io/VNS-SAM.",
      "url": "http://arxiv.org/abs/2601.00537",
      "author": "Guangqian Guo, Pengfei Chen, Yong Guo, Huafeng Chen, Boqiang Zhang, Shan Gao",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes VNS-SAM to enhance SAM's performance on visually non-salient scenarios (low foreground-background contrast) through Mask-Edge Token Interactive decoder and Non-Salient Feature Mining module.",
      "importance_score": 47,
      "reasoning": "Addresses real limitation of SAM. Reasonable architectural contributions. Practical improvement but incremental over SAM.",
      "themes": [
        "Segmentation",
        "SAM",
        "Computer Vision"
      ],
      "continuation": null
    },
    {
      "id": "0db46c315f5b",
      "title": "Cracking IoT Security: Can LLMs Outsmart Static Analysis Tools?",
      "content": "Smart home IoT platforms such as openHAB rely on Trigger Action Condition (TAC) rules to automate device behavior, but the interplay among these rules can give rise to interaction threats, unintended or unsafe behaviors emerging from implicit dependencies, conflicting triggers, or overlapping conditions. Identifying these threats requires semantic understanding and structural reasoning that traditionally depend on symbolic, constraint-driven static analysis. This work presents the first comprehensive evaluation of Large Language Models (LLMs) across a multi-category interaction threat taxonomy, assessing their performance on both the original openHAB (oHC/IoTB) dataset and a structurally challenging Mutation dataset designed to test robustness under rule transformations. We benchmark Llama 3.1 8B, Llama 70B, GPT-4o, Gemini-2.5-Pro, and DeepSeek-R1 across zero-, one-, and two-shot settings, comparing their results against oHIT's manually validated ground truth. Our findings show that while LLMs exhibit promising semantic understanding, particularly on action- and condition-related threats, their accuracy degrades significantly for threats requiring cross-rule structural reasoning, especially under mutated rule forms. Model performance varies widely across threat categories and prompt settings, with no model providing consistent reliability. In contrast, the symbolic reasoning baseline maintains stable detection across both datasets, unaffected by rule rewrites or structural perturbations. These results underscore that LLMs alone are not yet dependable for safety critical interaction-threat detection in IoT environments. We discuss the implications for tool design and highlight the potential of hybrid architectures that combine symbolic analysis with LLM-based semantic interpretation to reduce false positives while maintaining structural rigor.",
      "url": "http://arxiv.org/abs/2601.00559",
      "author": "Jason Quantrill, Noura Khajehnouri, Zihan Guo, Manar H. Alalfi",
      "published": "2026-01-05",
      "source": "arXiv (cs.CR)",
      "source_type": "arxiv",
      "tags": [
        "cs.CR"
      ],
      "summary": "Evaluates LLMs on detecting interaction threats in IoT smart home platforms across original and mutation datasets, benchmarking Llama, GPT, DeepSeek families against static analysis tools.",
      "importance_score": 47,
      "reasoning": "Novel application of LLMs to IoT security analysis. Comprehensive benchmark across multiple threat categories. Practical security implications.",
      "themes": [
        "IoT Security",
        "Language Models",
        "Static Analysis"
      ],
      "continuation": null
    },
    {
      "id": "005668c2f5bf",
      "title": "GranAlign: Granularity-Aware Alignment Framework for Zero-Shot Video Moment Retrieval",
      "content": "Zero-shot video moment retrieval (ZVMR) is the task of localizing a temporal moment within an untrimmed video using a natural language query without relying on task-specific training data. The primary challenge in this setting lies in the mismatch in semantic granularity between textual queries and visual content. Previous studies in ZVMR have attempted to achieve alignment by leveraging high-quality pre-trained knowledge that represents video and language in a joint space. However, these approaches failed to balance the semantic granularity between the pre-trained knowledge provided by each modality for a given scene. As a result, despite the high quality of each modality's representations, the mismatch in granularity led to inaccurate retrieval. In this paper, we propose a training-free framework, called Granularity-Aware Alignment (GranAlign), that bridges this gap between coarse and fine semantic representations. Our approach introduces two complementary techniques: granularity-based query rewriting to generate varied semantic granularities, and query-aware caption generation to embed query intent into video content. By pairing multi-level queries with both query-agnostic and query-aware captions, we effectively resolve semantic mismatches. As a result, our method sets a new state-of-the-art across all three major benchmarks (QVHighlights, Charades-STA, ActivityNet-Captions), with a notable 3.23% mAP@avg improvement on the challenging QVHighlights dataset.",
      "url": "http://arxiv.org/abs/2601.00584",
      "author": "Mingyu Jeon, Sunjae Yoon, Jonghee Kim, Junyeoung Kim",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes GranAlign for zero-shot video moment retrieval addressing granularity mismatch between text queries and visual content through training-free alignment of pre-trained multimodal representations.",
      "importance_score": 47,
      "reasoning": "Addresses important alignment challenge in video understanding. Training-free approach is practical. Incremental improvement methodology.",
      "themes": [
        "Video Understanding",
        "Zero-Shot Learning",
        "Multimodal Learning"
      ],
      "continuation": null
    },
    {
      "id": "3eaca5d8b1e1",
      "title": "Active learning for data-driven reduced models of parametric differential systems with Bayesian operator inference",
      "content": "This work develops an active learning framework to intelligently enrich data-driven reduced-order models (ROMs) of parametric dynamical systems, which can serve as the foundation of virtual assets in a digital twin. Data-driven ROMs are explainable, computationally efficient scientific machine learning models that aim to preserve the underlying physics of complex dynamical simulations. Since the quality of data-driven ROMs is sensitive to the quality of the limited training data, we seek to identify training parameters for which using the associated training data results in the best possible parametric ROM. Our approach uses the operator inference methodology, a regression-based strategy which can be tailored to particular parametric structure for a large class of problems. We establish a probabilistic version of parametric operator inference, casting the learning problem as a Bayesian linear regression. Prediction uncertainties stemming from the resulting probabilistic ROM solutions are used to design a sequential adaptive sampling scheme to select new training parameter vectors that promote ROM stability and accuracy globally in the parameter domain. We conduct numerical experiments for several nonlinear parametric systems of partial differential equations and compare the results to ROMs trained on random parameter samples. The results demonstrate that the proposed adaptive sampling strategy consistently yields more stable and accurate ROMs than random sampling does under the same computational budget.",
      "url": "http://arxiv.org/abs/2601.00038",
      "author": "Shane A. McQuarrie, Mengwu Guo, Anirban Chaudhuri",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning (Statistics))",
      "source_type": "arxiv",
      "tags": [
        "stat.ML"
      ],
      "summary": "Develops active learning framework for Bayesian operator inference to intelligently enrich data-driven reduced-order models of parametric dynamical systems. Identifies optimal training parameters for best parametric ROM quality.",
      "importance_score": 46,
      "reasoning": "Solid methodology for scientific computing with digital twin applications. Technical contribution but specialized audience.",
      "themes": [
        "Active Learning",
        "Reduced-Order Models",
        "Digital Twins",
        "Scientific Machine Learning"
      ],
      "continuation": null
    },
    {
      "id": "24cd3a675088",
      "title": "MethConvTransformer: A Deep Learning Framework for Cross-Tissue Alzheimer's Disease Detection",
      "content": "Alzheimer's disease (AD) is a multifactorial neurodegenerative disorder characterized by progressive cognitive decline and widespread epigenetic dysregulation in the brain. DNA methylation, as a stable yet dynamic epigenetic modification, holds promise as a noninvasive biomarker for early AD detection. However, methylation signatures vary substantially across tissues and studies, limiting reproducibility and translational utility. To address these challenges, we develop MethConvTransformer, a transformer-based deep learning framework that integrates DNA methylation profiles from both brain and peripheral tissues to enable biomarker discovery. The model couples a CpG-wise linear projection with convolutional and self-attention layers to capture local and long-range dependencies among CpG sites, while incorporating subject-level covariates and tissue embeddings to disentangle shared and region-specific methylation effects. In experiments across six GEO datasets and an independent ADNI validation cohort, our model consistently outperforms conventional machine-learning baselines, achieving superior discrimination and generalization. Moreover, interpretability analyses using linear projection, SHAP, and Grad-CAM++ reveal biologically meaningful methylation patterns aligned with AD-associated pathways, including immune receptor signaling, glycosylation, lipid metabolism, and endomembrane (ER/Golgi) organization. Together, these results indicate that MethConvTransformer delivers robust, cross-tissue epigenetic biomarkers for AD while providing multi-resolution interpretability, thereby advancing reproducible methylation-based diagnostics and offering testable hypotheses on disease mechanisms.",
      "url": "http://arxiv.org/abs/2601.00143",
      "author": "Gang Qu, Guanghao Li, Zhongming Zhao (for the Alzheimer's Disease Neuroimaging Initiative)",
      "published": "2026-01-05",
      "source": "arXiv (q-bio.GN)",
      "source_type": "arxiv",
      "tags": [
        "q-bio.GN"
      ],
      "summary": "Develops MethConvTransformer, combining CpG-wise projections with convolutional and self-attention layers to capture local and long-range DNA methylation dependencies for Alzheimer's biomarker discovery across brain and peripheral tissues.",
      "importance_score": 46,
      "reasoning": "Domain-specific architecture for important biomedical application. Addresses tissue variability challenge in AD biomarkers.",
      "themes": [
        "Healthcare AI",
        "Genomics",
        "Alzheimer's Disease",
        "Transformers"
      ],
      "continuation": null
    },
    {
      "id": "c0c4602ca1cc",
      "title": "Early Prediction of Liver Cirrhosis Up to Three Years in Advance: A Machine Learning Study Benchmarking Against the FIB-4 Score",
      "content": "Objective: Develop and evaluate machine learning (ML) models for predicting incident liver cirrhosis one, two, and three years prior to diagnosis using routinely collected electronic health record (EHR) data, and to benchmark their performance against the FIB-4 score. Methods: We conducted a retrospective cohort study using de-identified EHR data from a large academic health system. Patients with fatty liver disease were identified and categorized into cirrhosis and non-cirrhosis cohorts based on ICD-9/10 codes. Prediction scenarios were constructed using observation and prediction windows to emulate real-world clinical use. Demographics, diagnoses, laboratory results, vital signs, and comorbidity indices were aggregated from the observation window. XGBoost models were trained for 1-, 2-, and 3-year prediction horizons and evaluated on held-out test sets. Model performance was compared with FIB-4 using area under the receiver operating characteristic curve (AUC). Results: Final cohorts included 3,043 patients for the 1-year prediction, 1,981 for the 2-year prediction, and 1,470 for the 3-year prediction. Across all prediction windows, ML models consistently outperformed FIB-4. The XGBoost models achieved AUCs of 0.81, 0.73, and 0.69 for 1-, 2-, and 3-year predictions, respectively, compared with 0.71, 0.63, and 0.57 for FIB-4. Performance gains persisted with longer prediction horizons, indicating improved early risk discrimination. Conclusions: Machine learning models leveraging routine EHR data substantially outperform the traditional FIB-4 score for early prediction of liver cirrhosis. These models enable earlier and more accurate risk stratification and can be integrated into clinical workflows as automated decision-support tools to support proactive cirrhosis prevention and management.",
      "url": "http://arxiv.org/abs/2601.00175",
      "author": "Zhuqi Miao, Sujan Ravi, Abdulaziz Ahmed",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Develops XGBoost models for predicting liver cirrhosis 1-3 years before diagnosis using EHR data. Benchmarks against FIB-4 score using demographics, diagnoses, labs, and vitals.",
      "importance_score": 46,
      "reasoning": "Clinically relevant prediction task with practical evaluation against standard clinical score. Standard methodology but useful validation.",
      "themes": [
        "Healthcare AI",
        "Predictive Medicine",
        "Electronic Health Records"
      ],
      "continuation": null
    },
    {
      "id": "ee02c5ea829d",
      "title": "StockBot 2.0: Vanilla LSTMs Outperform Transformer-based Forecasting for Stock Prices",
      "content": "Accurate forecasting of financial markets remains a long-standing challenge due to complex temporal and often latent dependencies, non-linear dynamics, and high volatility. Building on our earlier recurrent neural network framework, we present an enhanced StockBot architecture that systematically evaluates modern attention-based, convolutional, and recurrent time-series forecasting models within a unified experimental setting. While attention-based and transformer-inspired models offer increased modeling flexibility, extensive empirical evaluation reveals that a carefully constructed vanilla LSTM consistently achieves superior predictive accuracy and more stable buy/sell decision-making when trained under a common set of default hyperparameters. These results highlight the robustness and data efficiency of recurrent sequence models for financial time-series forecasting, particularly in the absence of extensive hyperparameter tuning or the availability of sufficient data when discretized to single-day intervals. Additionally, these results underscore the importance of architectural inductive bias in data-limited market prediction tasks.",
      "url": "http://arxiv.org/abs/2601.00197",
      "author": "Shaswat Mohanty",
      "published": "2026-01-05",
      "source": "arXiv (cs.CE)",
      "source_type": "arxiv",
      "tags": [
        "cs.CE"
      ],
      "summary": "Compares attention-based, convolutional, and recurrent models for stock price forecasting finding that carefully constructed vanilla LSTMs consistently outperform transformer-based models under default hyperparameters.",
      "importance_score": 46,
      "reasoning": "Useful negative result for financial forecasting. Challenges assumption that transformers are always better, with practical implications.",
      "themes": [
        "Time Series Forecasting",
        "Financial Prediction",
        "Model Comparison"
      ],
      "continuation": null
    },
    {
      "id": "50da4cb0e90a",
      "title": "IntraStyler: Exemplar-based Style Synthesis for Cross-modality Domain Adaptation",
      "content": "Image-level domain alignment is the de facto approach for unsupervised domain adaptation, where unpaired image translation is used to minimize the domain gap. Prior studies mainly focus on the domain shift between the source and target domains, whereas the intra-domain variability remains under-explored. To address the latter, an effective strategy is to diversify the styles of the synthetic target domain data during image translation. However, previous methods typically require intra-domain variations to be pre-specified for style synthesis, which may be impractical. In this paper, we propose an exemplar-based style synthesis method named IntraStyler, which can capture diverse intra-domain styles without any prior knowledge. Specifically, IntraStyler uses an exemplar image to guide the style synthesis such that the output style matches the exemplar style. To extract the style-only features, we introduce a style encoder to learn styles discriminatively based on contrastive learning. We evaluate the proposed method on the largest public dataset for cross-modality domain adaptation, CrossMoDA 2023. Our experiments show the efficacy of our method in controllable style synthesis and the benefits of diverse synthetic data for downstream segmentation. Code is available at https://github.com/han-liu/IntraStyler.",
      "url": "http://arxiv.org/abs/2601.00212",
      "author": "Han Liu, Yubo Fan, Hao Li, Dewei Hu, Daniel Moyer, Zhoubing Xu, Benoit M. Dawant, Ipek Oguz",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes IntraStyler for exemplar-based style synthesis in domain adaptation, capturing diverse intra-domain styles without prior specification. Uses exemplar images to guide style transfer during training.",
      "importance_score": 46,
      "reasoning": "Addresses underexplored intra-domain variability in domain adaptation. Practical approach with medical imaging applications.",
      "themes": [
        "Domain Adaptation",
        "Style Transfer",
        "Medical Imaging"
      ],
      "continuation": null
    },
    {
      "id": "b0051b52711e",
      "title": "The Impact of Lesion Focus on the Performance of AI-Based Melanoma Classification",
      "content": "Melanoma is the most lethal subtype of skin cancer, and early and accurate detection of this disease can greatly improve patients' outcomes. Although machine learning models, especially convolutional neural networks (CNNs), have shown great potential in automating melanoma classification, their diagnostic reliability still suffers due to inconsistent focus on lesion areas. In this study, we analyze the relationship between lesion attention and diagnostic performance, involving masked images, bounding box detection, and transfer learning. We used multiple explainability and sensitivity analysis approaches to investigate how well models aligned their attention with lesion areas and how this alignment correlated with precision, recall, and F1-score. Results showed that models with a higher focus on lesion areas achieved better diagnostic performance, suggesting the potential of interpretable AI in medical diagnostics. This study provides a foundation for developing more accurate and trustworthy melanoma classification models in the future.",
      "url": "http://arxiv.org/abs/2601.00355",
      "author": "Tanay Donde",
      "published": "2026-01-05",
      "source": "arXiv (eess.IV)",
      "source_type": "arxiv",
      "tags": [
        "eess.IV"
      ],
      "summary": "Analyzes relationship between lesion focus and melanoma classification performance using explainability methods, showing correlation between model attention alignment and diagnostic accuracy.",
      "importance_score": 46,
      "reasoning": "Useful analysis for medical AI interpretability but limited novelty.",
      "themes": [
        "Medical AI",
        "Explainability",
        "Dermatology"
      ],
      "continuation": null
    },
    {
      "id": "264507957098",
      "title": "ECR: Manifold-Guided Semantic Cues for Compact Language Models",
      "content": "Compact models often lose the structure of their embedding space. The issue shows up when the capacity is tight or the data spans several languages. Such collapse makes it difficult for downstream tasks to build on the resulting representation. Existing compression methods focus on aligning model outputs at a superficial level but fail to preserve the underlying manifold structure. This mismatch often leads to semantic drift in the compact model, causing both task behavior and linguistic properties to deviate from the reference model.   To address those issues, we provide a new framework called Embedding Consistency Regulation (ECR). This framework first derives a set of semantic anchors from teacher embeddings (computed once offline). Then, the compact model learns to maintain consistent geometry around these anchors, without relying on matching logits or internal features. ECR adds only a small projection step at inference, without altering the decoding architecture or its runtime behavior.   In experiments on a 100K multilingual corpus, ECR consistently stabilizes training and preserves semantic structure across tasks and languages. It also produces a more compact and task-aligned representation space, enabling low-capacity models to learn cleaner manifolds than conventional baselines. ECR works without teacher outputs and is compatible with, but independent of, distillation. Taken together, our results show that ECR helps compact models better follow task requirements and makes them easier to deploy under strict efficiency or privacy limits.",
      "url": "http://arxiv.org/abs/2601.00543",
      "author": "Chung-Wei Victor Yuan",
      "published": "2026-01-05",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes Embedding Consistency Regulation (ECR) framework using semantic anchors from teacher embeddings to maintain manifold structure during model compression, preventing semantic drift.",
      "importance_score": 46,
      "reasoning": "Addresses real issue of embedding collapse in compression. Novel anchor-based approach. Single author work with reasonable methodology.",
      "themes": [
        "Model Compression",
        "Knowledge Distillation",
        "Language Models"
      ],
      "continuation": null
    },
    {
      "id": "655a32f69513",
      "title": "LLM-Based Agentic Exploration for Robot Navigation & Manipulation with Skill Orchestration",
      "content": "This paper presents an end-to-end LLM-based agentic exploration system for an indoor shopping task, evaluated in both Gazebo simulation and a corresponding real-world corridor layout. The robot incrementally builds a lightweight semantic map by detecting signboards at junctions and storing direction-to-POI relations together with estimated junction poses, while AprilTags provide repeatable anchors for approach and alignment. Given a natural-language shopping request, an LLM produces a constrained discrete action at each junction (direction and whether to enter a store), and a ROS finite-state main controller executes the decision by gating modular motion primitives, including local-costmap-based obstacle avoidance, AprilTag approaching, store entry, and grasping. Qualitative results show that the integrated stack can perform end-to-end task execution from user instruction to multi-store navigation and object retrieval, while remaining modular and debuggable through its text-based map and logged decision history.",
      "url": "http://arxiv.org/abs/2601.00555",
      "author": "Abu Hanif Muhammad Syarubany, Farhan Zaki Rahmani, Trio Widianto",
      "published": "2026-01-05",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Presents end-to-end LLM-based agentic system for indoor shopping navigation using semantic mapping, AprilTag anchors, and LLM-driven decision making at junctions with ROS-based motion primitives.",
      "importance_score": 46,
      "reasoning": "Practical integration of LLMs into robot navigation. End-to-end system demonstration. Incremental over existing LLM-robot integration work.",
      "themes": [
        "Robotics",
        "LLM Agents",
        "Navigation"
      ],
      "continuation": null
    },
    {
      "id": "27de979da31d",
      "title": "NMPC-Augmented Visual Navigation and Safe Learning Control for Large-Scale Mobile Robots",
      "content": "A large-scale mobile robot (LSMR) is a high-order multibody system that often operates on loose, unconsolidated terrain, which reduces traction. This paper presents a comprehensive navigation and control framework for an LSMR that ensures stability and safety-defined performance, delivering robust operation on slip-prone terrain by jointly leveraging high-performance techniques. The proposed architecture comprises four main modules: (1) a visual pose-estimation module that fuses onboard sensors and stereo cameras to provide an accurate, low-latency robot pose, (2) a high-level nonlinear model predictive control that updates the wheel motion commands to correct robot drift from the robot reference pose on slip-prone terrain, (3) a low-level deep neural network control policy that approximates the complex behavior of the wheel-driven actuation mechanism in LSMRs, augmented with robust adaptive control to handle out-of-distribution disturbances, ensuring that the wheels accurately track the updated commands issued by high-level control module, and (4) a logarithmic safety module to monitor the entire robot stack and guarantees safe operation. The proposed low-level control framework guarantees uniform exponential stability of the actuation subsystem, while the safety module ensures the whole system-level safety during operation. Comparative experiments on a 6,000 kg LSMR actuated by two complex electro-hydrostatic drives, while synchronizing modules operating at different frequencies.",
      "url": "http://arxiv.org/abs/2601.00609",
      "author": "Mehdi Heydari Shahna, Pauli Mustalahti, Jouni Mattila",
      "published": "2026-01-05",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Presents comprehensive navigation and control framework for large-scale mobile robots combining visual pose estimation, NMPC for drift correction, and DNN control policy for slip-prone terrain.",
      "importance_score": 46,
      "reasoning": "Comprehensive system integration for challenging robot control. Practical for real-world deployment. Multiple established techniques combined.",
      "themes": [
        "Robotics",
        "Navigation",
        "Control",
        "Deep Learning"
      ],
      "continuation": null
    },
    {
      "id": "4d3c93903be9",
      "title": "MICACL: Multi-Instance Category-Aware Contrastive Learning for Long-Tailed Dynamic Facial Expression Recognition",
      "content": "Dynamic facial expression recognition (DFER) faces significant challenges due to long-tailed category distributions and complexity of spatio-temporal feature modeling. While existing deep learning-based methods have improved DFER performance, they often fail to address these issues, resulting in severe model induction bias. To overcome these limitations, we propose a novel multi-instance learning framework called MICACL, which integrates spatio-temporal dependency modeling and long-tailed contrastive learning optimization. Specifically, we design the Graph-Enhanced Instance Interaction Module (GEIIM) to capture intricate spatio-temporal between adjacent instances relationships through adaptive adjacency matrices and multiscale convolutions. To enhance instance-level feature aggregation, we develop the Weighted Instance Aggregation Network (WIAN), which dynamically assigns weights based on instance importance. Furthermore, we introduce a Multiscale Category-aware Contrastive Learning (MCCL) strategy to balance training between major and minor categories. Extensive experiments on in-the-wild datasets (i.e., DFEW and FERV39k) demonstrate that MICACL achieves state-of-the-art performance with superior robustness and generalization.",
      "url": "http://arxiv.org/abs/2509.04344",
      "author": "Feng-Qi Cui, Zhen Lin, Xinlong Rao, Anyang Tong, Shiyao Li, Fei Wang, Changlin Chen, Bin Liu",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes MICACL, a multi-instance learning framework for dynamic facial expression recognition that addresses long-tailed distributions through spatio-temporal dependency modeling and contrastive learning. Uses graph-enhanced instance interaction and category-aware contrastive loss.",
      "importance_score": 45,
      "reasoning": "Addresses relevant problem of class imbalance in DFER with reasonable technical approach. Incremental improvements over existing methods.",
      "themes": [
        "Computer Vision",
        "Facial Expression Recognition",
        "Contrastive Learning"
      ],
      "continuation": null
    },
    {
      "id": "e731b061d9ca",
      "title": "Reinforcement Learning with Function Approximation for Non-Markov Processes",
      "content": "We study reinforcement learning methods with linear function approximation under non-Markov state and cost processes. We first consider the policy evaluation method and show that the algorithm converges under suitable ergodicity conditions on the underlying non-Markov processes. Furthermore, we show that the limit corresponds to the fixed point of a joint operator composed of an orthogonal projection and the Bellman operator of an auxiliary \\emph{Markov} decision process.   For Q-learning with linear function approximation, as in the Markov setting, convergence is not guaranteed in general. We show, however, that for the special case where the basis functions are chosen based on quantization maps, the convergence can be shown under similar ergodicity conditions. Finally, we apply our results to partially observed Markov decision processes, where finite-memory variables are used as state representations, and we derive explicit error bounds for the limits of the resulting learning algorithms.",
      "url": "http://arxiv.org/abs/2601.00151",
      "author": "Ali Devran Kara",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Studies RL with linear function approximation for non-Markov processes, proving convergence under ergodicity conditions. Shows convergence for Q-learning with quantization-based basis functions.",
      "importance_score": 45,
      "reasoning": "Theoretical extension of RL theory to non-Markov settings. Solid mathematical contribution but limited practical applications shown.",
      "themes": [
        "Reinforcement Learning",
        "Function Approximation",
        "Non-Markov Processes"
      ],
      "continuation": null
    },
    {
      "id": "e8b37e1b5d3f",
      "title": "CropNeRF: A Neural Radiance Field-Based Framework for Crop Counting",
      "content": "Rigorous crop counting is crucial for effective agricultural management and informed intervention strategies. However, in outdoor field environments, partial occlusions combined with inherent ambiguity in distinguishing clustered crops from individual viewpoints poses an immense challenge for image-based segmentation methods. To address these problems, we introduce a novel crop counting framework designed for exact enumeration via 3D instance segmentation. Our approach utilizes 2D images captured from multiple viewpoints and associates independent instance masks for neural radiance field (NeRF) view synthesis. We introduce crop visibility and mask consistency scores, which are incorporated alongside 3D information from a NeRF model. This results in an effective segmentation of crop instances in 3D and highly-accurate crop counts. Furthermore, our method eliminates the dependence on crop-specific parameter tuning. We validate our framework on three agricultural datasets consisting of cotton bolls, apples, and pears, and demonstrate consistent counting performance despite major variations in crop color, shape, and size. A comparative analysis against the state of the art highlights superior performance on crop counting tasks. Lastly, we contribute a cotton plant dataset to advance further research on this topic.",
      "url": "http://arxiv.org/abs/2601.00207",
      "author": "Md Ahmed Al Muzaddid, William J. Beksi",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Introduces CropNeRF for exact crop enumeration via 3D instance segmentation using NeRF-based view synthesis. Uses crop visibility and mask consistency scores with multi-view images.",
      "importance_score": 45,
      "reasoning": "Creative application of NeRF to agricultural monitoring. Addresses practical challenge of occluded crop counting.",
      "themes": [
        "Computer Vision",
        "Neural Radiance Fields",
        "Agriculture AI"
      ],
      "continuation": null
    },
    {
      "id": "006816db7f0e",
      "title": "JP-TL-Bench: Anchored Pairwise LLM Evaluation for Bidirectional Japanese-English Translation",
      "content": "We introduce JP-TL-Bench, a lightweight, open benchmark designed to guide the iterative development of Japanese-English translation systems. In this context, the challenge is often \"which of these two good translations is better?\" rather than \"is this translation acceptable?\" This distinction matters for Japanese-English, where subtle choices in politeness, implicature, ellipsis, and register strongly affect perceived naturalness. JP-TL-Bench uses a protocol built to make LLM judging both reliable and affordable: it evaluates a candidate model via reference-free, pairwise LLM comparisons against a fixed, versioned anchor set. Pairwise results are aggregated with a Bradley-Terry model and reported as win rates plus a normalized 0-10 \"LT\" score derived from a logistic transform of fitted log-strengths. Because each candidate is scored against the same frozen anchor set, scores are structurally stable given the same base set, judge, and aggregation code.",
      "url": "http://arxiv.org/abs/2601.00223",
      "author": "Leonard Lin, Adam Lensenmayer (Shisa.AI)",
      "published": "2026-01-05",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Presents JP-TL-Bench, a benchmark for Japanese-English translation using pairwise LLM comparisons against anchor translations, with Bradley-Terry aggregation. Addresses subtle translation quality differences in politeness and register.",
      "importance_score": 45,
      "reasoning": "Useful benchmark for a specific language pair, but narrow scope. From smaller research group (Shisa.AI).",
      "themes": [
        "Machine Translation",
        "Benchmarks",
        "Multilingual NLP"
      ],
      "continuation": null
    },
    {
      "id": "cd78da5892a3",
      "title": "Pure Inertial Navigation in Challenging Environments with Wheeled and Chassis Mounted Inertial Sensors",
      "content": "Autonomous vehicles and wheeled robots are widely used in many applications in both indoor and outdoor settings. In practical situations with limited GNSS signals or degraded lighting conditions, the navigation solution may rely only on inertial sensors and as result drift in time due to errors in the inertial measurement. In this work, we propose WiCHINS, a wheeled and chassis inertial navigation system by combining wheel-mounted-inertial sensors with a chassis-mounted inertial sensor for accurate pure inertial navigation. To that end, we derive a three-stage framework, each with a dedicated extended Kalman filter. This framework utilizes the benefits of each location (wheel/body) during the estimation process. To evaluate our proposed approach, we employed a dataset with five inertial measurement units with a total recording time of 228.6 minutes. We compare our approach with four other inertial baselines and demonstrate an average position error of 11.4m, which is $2.4\\%$ of the average traveled distance, using two wheels and one body inertial measurement units. As a consequence, our proposed method enables robust navigation in challenging environments and helps bridge the pure-inertial performance gap.",
      "url": "http://arxiv.org/abs/2601.00275",
      "author": "Dusan Nemec, Gal Versano, Itai Savin, Vojtech Simak, Juraj Kekelak, Itzik Klein",
      "published": "2026-01-05",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Proposes WiCHINS combining wheel-mounted and chassis-mounted inertial sensors for pure inertial navigation in GNSS-denied environments using a three-stage EKF framework.",
      "importance_score": 45,
      "reasoning": "Practical navigation solution for autonomous vehicles in challenging conditions. Solid engineering contribution.",
      "themes": [
        "Autonomous Navigation",
        "Sensor Fusion",
        "Robotics"
      ],
      "continuation": null
    },
    {
      "id": "0044666f6841",
      "title": "Can Semantic Methods Enhance Team Sports Tactics? A Methodology for Football with Broader Applications",
      "content": "This paper explores how semantic-space reasoning, traditionally used in computational linguistics, can be extended to tactical decision-making in team sports. Building on the analogy between texts and teams -- where players act as words and collective play conveys meaning -- the proposed methodology models tactical configurations as compositional semantic structures. Each player is represented as a multidimensional vector integrating technical, physical, and psychological attributes; team profiles are aggregated through contextual weighting into a higher-level semantic representation. Within this shared vector space, tactical templates such as high press, counterattack, or possession build-up are encoded analogously to linguistic concepts. Their alignment with team profiles is evaluated using vector-distance metrics, enabling the computation of tactical ``fit'' and opponent-exploitation potential. A Python-based prototype demonstrates how these methods can generate interpretable, dynamically adaptive strategy recommendations, accompanied by fine-grained diagnostic insights at the attribute level. Beyond football, the approach offers a generalizable framework for collective decision-making and performance optimization in team-based domains -- ranging from basketball and hockey to cooperative robotics and human-AI coordination systems. The paper concludes by outlining future directions toward real-world data integration, predictive simulation, and hybrid human-machine tactical intelligence.",
      "url": "http://arxiv.org/abs/2601.00421",
      "author": "Alessio Di Rubbo and Mattia Neri and Remo Pareschi and Marco Pedroni and Roberto Valtancoli and Paolino Zica",
      "published": "2026-01-05",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Extends semantic-space reasoning from computational linguistics to football tactics, representing players as multidimensional vectors and tactical configurations as compositional structures.",
      "importance_score": 45,
      "reasoning": "Creative interdisciplinary application but limited technical novelty.",
      "themes": [
        "Sports Analytics",
        "Semantic Representations",
        "NLP Applications"
      ],
      "continuation": null
    },
    {
      "id": "d666e66fea0c",
      "title": "Neural Chains and Discrete Dynamical Systems",
      "content": "We inspect the analogy between machine-learning (ML) applications based on the transformer architecture without self-attention, {\\it neural chains} hereafter, and discrete dynamical systems associated with discretised versions of neural integral and partial differential equations (NIE, PDE). A comparative analysis of the numerical solution of the (viscid and inviscid) Burgers and Eikonal equations via standard numerical discretization (also cast in terms of neural chains) and via PINN's learning is presented and commented on. It is found that standard numerical discretization and PINN learning provide two different paths to acquire essentially the same knowledge about the dynamics of the system. PINN learning proceeds through random matrices which bear no direct relation to the highly structured matrices associated with finite-difference (FD) procedures. Random matrices leading to acceptable solutions are far more numerous than the unique tridiagonal form in matrix space, which explains why the PINN search typically lands on the random ensemble. The price is a much larger number of parameters, causing lack of physical transparency (explainability) as well as large training costs with no counterpart in the FD procedure. However, our results refer to one-dimensional dynamic problems, hence they don't rule out the possibility that PINNs and ML in general, may offer better strategies for high-dimensional problems.",
      "url": "http://arxiv.org/abs/2601.00473",
      "author": "Sauro Succi and Abhisek Ganguly and Santosh Ansumali",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Analyzes analogy between transformers without self-attention (neural chains) and discrete dynamical systems from neural PDEs, comparing standard discretization with PINN learning approaches.",
      "importance_score": 45,
      "reasoning": "Interesting theoretical perspective connecting neural architectures to dynamical systems. Comparative analysis is informative but conceptual contribution limited.",
      "themes": [
        "Deep Learning Theory",
        "Physics-Informed ML",
        "Dynamical Systems"
      ],
      "continuation": null
    },
    {
      "id": "da883779078f",
      "title": "Multi-Agent Coordinated Rename Refactoring",
      "content": "The primary value of AI agents in software development lies in their ability to extend the developer's capacity for reasoning and action, not to supplant human involvement. To showcase how to use agents working in tandem with developers, we designed a novel approach for carrying out coordinated renaming. Coordinated renaming, where a single rename refactoring triggers refactorings in multiple, related identifiers, is a frequent yet challenging task. Developers must manually propagate these rename refactorings across numerous files and contexts, a process that is both tedious and highly error-prone. State-of-the-art heuristic-based approaches produce an overwhelming number of false positives, while vanilla Large Language Models (LLMs) provide incomplete suggestions due to their limited context and inability to interact with refactoring tools. This leaves developers with incomplete refactorings or burdens them with filtering too many false positives. Coordinated renaming is exactly the kind of repetitive task that agents can significantly reduce the developers' burden while keeping them in the driver's seat.   We designed, implemented, and evaluated the first multi-agent framework that automates coordinated renaming. It operates on a key insight: a developer's initial refactoring is a clue to infer the scope of related refactorings. Our Scope Inference Agent first transforms this clue into an explicit, natural-language Declared Scope. The Planned Execution Agent then uses this as a strict plan to identify program elements that should undergo refactoring and safely executes the changes by invoking the IDE's own trusted refactoring APIs. Finally, the Replication Agent uses it to guide the project-wide search. We first conducted a formative study on the practice of coordinated renaming in 609K commits in 100 open-source projects and surveyed 205 developers ...",
      "url": "http://arxiv.org/abs/2601.00482",
      "author": "Abhiram Bellur, Mohammed Raihan Ullah, Fraol Batole, Mohit Kansara, Masaharu Morimoto, Kai Ishikawa, Haifeng Chen, Yaroslav Zharov, Timofey Bryksin, Tien N. Nguyen, Hridesh Rajan, Danny Dig",
      "published": "2026-01-05",
      "source": "arXiv (cs.SE)",
      "source_type": "arxiv",
      "tags": [
        "cs.SE"
      ],
      "summary": "Presents multi-agent approach for coordinated rename refactoring where AI agents work with developers to propagate name changes across related identifiers, addressing limitations of heuristic-based approaches and vanilla LLMs.",
      "importance_score": 45,
      "reasoning": "Practical software engineering application of AI agents. Addresses real developer pain point but incremental technical contribution.",
      "themes": [
        "AI Agents",
        "Software Engineering",
        "Code Refactoring"
      ],
      "continuation": null
    },
    {
      "id": "30f4848f4d15",
      "title": "A Sparse-Attention Deep Learning Model Integrating Heterogeneous Multimodal Features for Parkinson's Disease Severity Profiling",
      "content": "Characterising the heterogeneous presentation of Parkinson's disease (PD) requires integrating biological and clinical markers within a unified predictive framework. While multimodal data provide complementary information, many existing computational models struggle with interpretability, class imbalance, or effective fusion of high-dimensional imaging and tabular clinical features. To address these limitations, we propose the Class-Weighted Sparse-Attention Fusion Network (SAFN), an interpretable deep learning framework for robust multimodal profiling. SAFN integrates MRI cortical thickness, MRI volumetric measures, clinical assessments, and demographic variables using modality-specific encoders and a symmetric cross-attention mechanism that captures nonlinear interactions between imaging and clinical representations. A sparsity-constrained attention-gating fusion layer dynamically prioritises informative modalities, while a class-balanced focal loss (beta = 0.999, gamma = 1.5) mitigates dataset imbalance without synthetic oversampling. Evaluated on 703 participants (570 PD, 133 healthy controls) from the Parkinson's Progression Markers Initiative using subject-wise five-fold cross-validation, SAFN achieves an accuracy of 0.98 plus or minus 0.02 and a PR-AUC of 1.00 plus or minus 0.00, outperforming established machine learning and deep learning baselines. Interpretability analysis shows a clinically coherent decision process, with approximately 60 percent of predictive weight assigned to clinical assessments, consistent with Movement Disorder Society diagnostic principles. SAFN provides a reproducible and transparent multimodal modelling paradigm for computational profiling of neurodegenerative disease.",
      "url": "http://arxiv.org/abs/2601.00519",
      "author": "Dristi Datta, Tanmoy Debnath, Minh Chau, Manoranjan Paul, Gourab Adhikary, and Md Geaur Rahman",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes SAFN, a sparse-attention fusion network for Parkinson's disease severity profiling integrating MRI features with clinical assessments using modality-specific encoders and cross-attention.",
      "importance_score": 45,
      "reasoning": "Well-designed multimodal architecture for medical application. Addresses class imbalance and interpretability. Domain-specific impact.",
      "themes": [
        "Medical AI",
        "Multimodal Learning",
        "Parkinson's Disease"
      ],
      "continuation": null
    },
    {
      "id": "6a4319f002ab",
      "title": "Priority-Aware Multi-Robot Coverage Path Planning",
      "content": "Multi-robot systems are widely used for coverage tasks that require efficient coordination across large environments. In Multi-Robot Coverage Path Planning (MCPP), the objective is typically to minimize the makespan by generating non-overlapping paths for full-area coverage. However, most existing methods assume uniform importance across regions, limiting their effectiveness in scenarios where some zones require faster attention. We introduce the Priority-Aware MCPP (PA-MCPP) problem, where a subset of the environment is designated as prioritized zones with associated weights. The goal is to minimize, in lexicographic order, the total priority-weighted latency of zone coverage and the overall makespan. To address this, we propose a scalable two-phase framework combining (1) greedy zone assignment with local search, spanning-tree-based path planning, and (2) Steiner-tree-guided residual coverage. Experiments across diverse scenarios demonstrate that our method significantly reduces priority-weighted latency compared to standard MCPP baselines, while maintaining competitive makespan. Sensitivity analyses further show that the method scales well with the number of robots and that zone coverage behavior can be effectively controlled by adjusting priority weights.",
      "url": "http://arxiv.org/abs/2601.00580",
      "author": "Kanghoon Lee, Hyeonjun Kim, Jiachen Li, Jinkyoo Park",
      "published": "2026-01-05",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Introduces Priority-Aware MCPP problem where some regions require faster coverage with associated weights, proposing scalable two-phase framework combining greedy zone assignment with path planning.",
      "importance_score": 45,
      "reasoning": "Novel problem formulation extending standard coverage planning. Practical for real-world scenarios with varying importance. Solid algorithmic contribution.",
      "themes": [
        "Multi-Robot Systems",
        "Path Planning",
        "Optimization"
      ],
      "continuation": null
    },
    {
      "id": "03b2befb0a7a",
      "title": "Vision-based Goal-Reaching Control for Mobile Robots Using a Hierarchical Learning Framework",
      "content": "Reinforcement learning (RL) is effective in many robotic applications, but it requires extensive exploration of the state-action space, during which behaviors can be unsafe. This significantly limits its applicability to large robots with complex actuators operating on unstable terrain. Hence, to design a safe goal-reaching control framework for large-scale robots, this paper decomposes the whole system into a set of tightly coupled functional modules. 1) A real-time visual pose estimation approach is employed to provide accurate robot states to 2) an RL motion planner for goal-reaching tasks that explicitly respects robot specifications. The RL module generates real-time smooth motion commands for the actuator system, independent of its underlying dynamic complexity. 3) In the actuation mechanism, a supervised deep learning model is trained to capture the complex dynamics of the robot and provide this model to 4) a model-based robust adaptive controller that guarantees the wheels track the RL motion commands even on slip-prone terrain. 5) Finally, to reduce human intervention, a mathematical safety supervisor monitors the robot, stops it on unsafe faults, and autonomously guides it back to a safe inspection area. The proposed framework guarantees uniform exponential stability of the actuation system and safety of the whole operation. Experiments on a 6,000 kg robot in different scenarios confirm the effectiveness of the proposed framework.",
      "url": "http://arxiv.org/abs/2601.00610",
      "author": "Mehdi Heydari Shahna, Pauli Mustalahti, Jouni Mattila",
      "published": "2026-01-05",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Proposes hierarchical learning framework for safe robot goal-reaching decomposing system into visual pose estimation, RL motion planner respecting robot specs, and safe learning control module.",
      "importance_score": 45,
      "reasoning": "Addresses safety in RL for large robots. Modular design is sensible. Practical but incremental over existing safe RL approaches.",
      "themes": [
        "Robotics",
        "Reinforcement Learning",
        "Safe Learning"
      ],
      "continuation": null
    },
    {
      "id": "6d8856857dba",
      "title": "Reconstructing Building Height from Spaceborne TomoSAR Point Clouds Using a Dual-Topology Network",
      "content": "Reliable building height estimation is essential for various urban applications. Spaceborne SAR tomography (TomoSAR) provides weather-independent, side-looking observations that capture facade-level structure, offering a promising alternative to conventional optical methods. However, TomoSAR point clouds often suffer from noise, anisotropic point distributions, and data voids on incoherent surfaces, all of which hinder accurate height reconstruction. To address these challenges, we introduce a learning-based framework for converting raw TomoSAR points into high-resolution building height maps. Our dual-topology network alternates between a point branch that models irregular scatterer features and a grid branch that enforces spatial consistency. By jointly processing these representations, the network denoises the input points and inpaints missing regions to produce continuous height estimates. To our knowledge, this is the first proof of concept for large-scale urban height mapping directly from TomoSAR point clouds. Extensive experiments on data from Munich and Berlin validate the effectiveness of our approach. Moreover, we demonstrate that our framework can be extended to incorporate optical satellite imagery, further enhancing reconstruction quality. The source code is available at https://github.com/zhu-xlab/tomosar2height.",
      "url": "http://arxiv.org/abs/2601.00658",
      "author": "Zhaiyu Chen, Yuanyuan Wang, Yilei Shi, Xiao Xiang Zhu",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes dual-topology network for reconstructing building heights from TomoSAR point clouds, alternating between point and grid branches to handle noise, anisotropic distributions, and data voids.",
      "importance_score": 45,
      "reasoning": "Novel architecture for challenging remote sensing task. Addresses practical data quality issues. Domain-specific but solid contribution.",
      "themes": [
        "Remote Sensing",
        "Point Cloud Processing",
        "Urban Computing"
      ],
      "continuation": null
    },
    {
      "id": "3a4a466275f7",
      "title": "Three factor delay learning rules for spiking neural networks",
      "content": "Spiking Neural Networks (SNNs) are dynamical systems that operate on spatiotemporal data, yet their learnable parameters are often limited to synaptic weights, contributing little to temporal pattern recognition. Learnable parameters that delay spike times can improve classification performance in temporal tasks, but existing methods rely on large networks and offline learning, making them unsuitable for real-time operation in resource-constrained environments. In this paper, we introduce synaptic and axonal delays to leaky integrate and fire (LIF)-based feedforward and recurrent SNNs, and propose three-factor learning rules to simultaneously learn delay parameters online. We employ a smooth Gaussian surrogate to approximate spike derivatives exclusively for the eligibility trace calculation, and together with a top-down error signal determine parameter updates. Our experiments show that incorporating delays improves accuracy by up to 20% over a weights-only baseline, and for networks with similar parameter counts, jointly learning weights and delays yields up to 14% higher accuracy. On the SHD speech recognition dataset, our method achieves similar accuracy to offline backpropagation-based approaches. Compared to state-of-the-art methods, it reduces model size by 6.6x and inference latency by 67%, with only a 2.4% drop in classification accuracy. Our findings benefit the design of power and area-constrained neuromorphic processors by enabling on-device learning and lowering memory requirements.",
      "url": "http://arxiv.org/abs/2601.00668",
      "author": "Luke Vassallo, Nima Taherinejad",
      "published": "2026-01-05",
      "source": "arXiv (Neural and Evolutionary Computing)",
      "source_type": "arxiv",
      "tags": [
        "cs.NE"
      ],
      "summary": "Introduces three-factor learning rules for spiking neural networks that enable online learning of both synaptic weights and temporal delays. Uses Gaussian surrogates for spike derivatives to improve temporal pattern recognition in resource-constrained settings.",
      "importance_score": 45,
      "reasoning": "Contributes to neuromorphic computing by enabling online delay learning in SNNs. Important for edge AI applications but niche audience. Incremental contribution to existing SNN learning methods.",
      "themes": [
        "Spiking Neural Networks",
        "Neuromorphic Computing",
        "Online Learning"
      ],
      "continuation": null
    },
    {
      "id": "ea98dc05c5b0",
      "title": "Uncertainty-Adjusted Sorting for Asset Pricing with Machine Learning",
      "content": "Machine learning is central to empirical asset pricing, but portfolio construction still relies on point predictions and largely ignores asset-specific estimation uncertainty. We propose a simple change: sort assets using uncertainty-adjusted prediction bounds instead of point predictions alone. Across a broad set of ML models and a U.S. equity panel, this approach improves portfolio performance relative to point-prediction sorting. These gains persist even when bounds are built from partial or misspecified uncertainty information. They arise mainly from reduced volatility and are strongest for flexible machine learning models. Identification and robustness exercises show that these improvements are driven by asset-level rather than time or aggregate predictive uncertainty.",
      "url": "http://arxiv.org/abs/2601.00593",
      "author": "Yan Liu, Ye Luo, Zigan Wang, Xiaowei Zhang",
      "published": "2026-01-05",
      "source": "arXiv (q-fin.PM)",
      "source_type": "arxiv",
      "tags": [
        "q-fin.PM"
      ],
      "summary": "Proposes uncertainty-adjusted sorting for portfolio construction using prediction bounds instead of point predictions, showing improved performance across ML models by reducing volatility through asset-level uncertainty incorporation.",
      "importance_score": 45,
      "reasoning": "Practical improvement to ML-based asset pricing. Simple but effective insight about uncertainty incorporation. Relevant for financial ML but incremental contribution.",
      "themes": [
        "Financial ML",
        "Uncertainty Quantification",
        "Portfolio Optimization"
      ],
      "continuation": null
    },
    {
      "id": "79ba48787276",
      "title": "The Thinking Machine",
      "content": "Book review: The Thinking Machine: Jensen Huang, Nvidia, and the World's Most Coveted Microchip, by Stephen Witt. This is a well-written book about the rise of deep learning, and the man who is the most responsible for building the hardware that it needs. Building the Foundations Nvidia was founded in 1993 by three engineers. They failed to articulate much of a business plan, but got funding anyway due to the reputation that Jensen had developed while working for LSI Logic. For 20 years, Nvidia was somewhat successful, but was an erratic performer in a small industry. Around 2004, Nvidia increased the resources it devoted to parallel processing. There was probably some foresight involved in this strategy, but for around a decade Nvidia's results created doubts about its wisdom. The market for such GPUs was tiny. Most experts believed it was too hard to make parallel software work. But Jensen excels at solving problems that most others would reject as impossible. The Most Important Decision Nvidia was sometimes less interested in neural networks than neural network researchers were interested in Nvidia. Geoffrey Hinton sometimes couldn't get Nvidia to respond to his emails (circa 2009?). In 2013, Bryan Catanzaro proposed that Nvidia support work on cuDNN (software to run deep learning on GPUs). The reaction from Nvidia's software team was negative. Catanzaro appealed to Jensen. Jensen quickly developed something like an expert understanding of deep learning, and soon announced that AI was a \"once in a lifetime opportunity\". He made AI Nvidia's top priority. It took a fair amount of skill to be positioned to profit from AI. But a large fraction of Nvidia's success depended on that one decision. I estimate it was worth a trillion dollars. Jensen ascribes Nvidia's success to \"luck, founded by vision\". Jensen's Character What drives Jensen? The book provides no clear answer. It doesn't seem to be money. I'm guessing it's some measure of business success along the lines o...",
      "url": "https://www.lesswrong.com/posts/NXW2QrKvhZmiGvkcd/the-thinking-machine",
      "author": "PeterMcCluskey",
      "published": "2026-01-04T13:24:54.059000",
      "source": "LessWrong",
      "source_type": "research_blog",
      "tags": [],
      "summary": "Book review of 'The Thinking Machine' about Jensen Huang and Nvidia's rise, covering the company's pivotal decisions around parallel processing and their eventual dominance in deep learning hardware.",
      "importance_score": 45,
      "reasoning": "Useful historical context on Nvidia's strategic decisions that enabled deep learning. No original research but valuable synthesis of important AI infrastructure history.",
      "themes": [
        "AI History",
        "Hardware",
        "Industry Analysis"
      ],
      "continuation": null
    },
    {
      "id": "a7e3faa672e2",
      "title": "Evaluating Anomaly Detectors for Simulated Highly Imbalanced Industrial Classification Problems",
      "content": "Machine learning offers potential solutions to current issues in industrial systems in areas such as quality control and predictive maintenance, but also faces unique barriers in industrial applications. An ongoing challenge is extreme class imbalance, primarily due to the limited availability of faulty data during training. This paper presents a comprehensive evaluation of anomaly detection algorithms using a problem-agnostic simulated dataset that reflects real-world engineering constraints. Using a synthetic dataset with a hyper-spherical based anomaly distribution in 2D and 10D, we benchmark 14 detectors across training datasets with anomaly rates between 0.05% and 20% and training sizes between 1 000 and 10 000 (with a testing dataset size of 40 000) to assess performance and generalization error. Our findings reveal that the best detector is highly dependant on the total number of faulty examples in the training dataset, with additional healthy examples offering insignificant benefits in most cases. With less than 20 faulty examples, unsupervised methods (kNN/LOF) dominate; but around 30-50 faulty examples, semi-supervised (XGBOD) and supervised (SVM/CatBoost) detectors, we see large performance increases. While semi-supervised methods do not show significant benefits with only two features, the improvements are evident at ten features. The study highlights the performance drop on generalization of anomaly detection methods on smaller datasets, and provides practical insights for deploying anomaly detection in industrial environments.",
      "url": "http://arxiv.org/abs/2601.00005",
      "author": "Lesley Wheat, Martin v. Mohrenschildt, Saeid Habibi",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Benchmarks 14 anomaly detection algorithms on synthetic datasets with extreme class imbalance (0.05%-20% anomaly rates) designed to reflect industrial constraints. Evaluates performance and generalization across varying dimensions and training sizes.",
      "importance_score": 44,
      "reasoning": "Comprehensive benchmarking study for industrial applications. Useful practical guidance but synthetic data limits real-world applicability conclusions.",
      "themes": [
        "Anomaly Detection",
        "Industrial Applications",
        "Machine Learning Benchmarking"
      ],
      "continuation": null
    },
    {
      "id": "50192559c469",
      "title": "The Agentic Leash: Extracting Causal Feedback Fuzzy Cognitive Maps with LLMs",
      "content": "We design a large-language-model (LLM) agent that extracts causal feedback fuzzy cognitive maps (FCMs) from raw text. The causal learning or extraction process is agentic both because of the LLM's semi-autonomy and because ultimately the FCM dynamical system's equilibria drive the LLM agents to fetch and process causal text. The fetched text can in principle modify the adaptive FCM causal structure and so modify the source of its quasi-autonomy--its equilibrium limit cycles and fixed-point attractors. This bidirectional process endows the evolving FCM dynamical system with a degree of autonomy while still staying on its agentic leash. We show in particular that a sequence of three finely tuned system instructions guide an LLM agent as it systematically extracts key nouns and noun phrases from text, as it extracts FCM concept nodes from among those nouns and noun phrases, and then as it extracts or infers partial or fuzzy causal edges between those FCM nodes. We test this FCM generation on a recent essay about the promise of AI from the late diplomat and political theorist Henry Kissinger and his colleagues. This three-step process produced FCM dynamical systems that converged to the same equilibrium limit cycles as did the human-generated FCMs even though the human-generated FCM differed in the number of nodes and edges. A final FCM mixed generated FCMs from separate Gemini and ChatGPT LLM agents. The mixed FCM absorbed the equilibria of its dominant mixture component but also created new equilibria of its own to better approximate the underlying causal dynamical system.",
      "url": "http://arxiv.org/abs/2601.00097",
      "author": "Akash Kumar Panda, Olaoluwa Adigun, and Bart Kosko",
      "published": "2026-01-05",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Designs LLM agent that extracts causal feedback fuzzy cognitive maps from text using system instructions. FCM equilibria drive agents to fetch and process causal text in bidirectional process.",
      "importance_score": 44,
      "reasoning": "Interesting combination of LLM agents with dynamical systems theory. Novel approach but limited validation of practical utility.",
      "themes": [
        "LLM Agents",
        "Causal Inference",
        "Knowledge Extraction"
      ],
      "continuation": null
    },
    {
      "id": "e81cc423b5a3",
      "title": "SLEI3D: Simultaneous Exploration and Inspection via Heterogeneous Fleets under Limited Communication",
      "content": "Robotic fleets such as unmanned aerial and ground vehicles have been widely used for routine inspections of static environments, where the areas of interest are known and planned in advance. However, in many applications, such areas of interest are unknown and should be identified online during exploration. Thus, this paper considers the problem of simultaneous exploration, inspection of unknown environments and then real-time communication to a mobile ground control station to report the findings. The heterogeneous robots are equipped with different sensors, e.g., long-range lidars for fast exploration and close-range cameras for detailed inspection. Furthermore, global communication is often unavailable in such environments, where the robots can only communicate with each other via ad-hoc wireless networks when they are in close proximity and free of obstruction. This work proposes a novel planning and coordination framework (SLEI3D) that integrates the online strategies for collaborative 3D exploration, adaptive inspection and timely communication (via the intermit-tent or proactive protocols). To account for uncertainties w.r.t. the number and location of features, a multi-layer and multi-rate planning mechanism is developed for inter-and-intra robot subgroups, to actively meet and coordinate their local plans. The proposed framework is validated extensively via high-fidelity simulations of numerous large-scale missions with up to 48 robots and 384 thousand cubic meters. Hardware experiments of 7 robots are also conducted. Project website is available at https://junfengchen-robotics.github.io/SLEI3D/.",
      "url": "http://arxiv.org/abs/2601.00163",
      "author": "Junfeng Chen, Yuxiao Zhu, Xintong Zhang, Bing Luo, Meng Guo",
      "published": "2026-01-05",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Addresses simultaneous exploration and inspection with heterogeneous robot fleets under limited communication. Robots with different sensors (lidars, cameras) coordinate via ad-hoc communication to mobile ground station.",
      "importance_score": 44,
      "reasoning": "Practical multi-robot coordination problem with realistic communication constraints. Solid systems contribution.",
      "themes": [
        "Multi-Robot Systems",
        "Exploration",
        "Communication Constraints"
      ],
      "continuation": null
    },
    {
      "id": "50f661071ed9",
      "title": "Reinforcement-Learned Unequal Error Protection for Quantized Semantic Embeddings",
      "content": "This paper tackles the pressing challenge of preserving semantic meaning in communication systems constrained by limited bandwidth. We introduce a novel reinforcement learning framework that achieves per-dimension unequal error protection via adaptive repetition coding. Central to our approach is a composite semantic distortion metric that balances global embedding similarity with entity-level preservation, empowering the reinforcement learning agent to allocate protection in a context-aware manner. Experiments show statistically significant gains over uniform protection, achieving 6.8% higher chrF scores and 9.3% better entity preservation at 1 dB SNR. The key innovation of our framework is the demonstration that simple, intelligently allocated repetition coding enables fine-grained semantic protection -- an advantage unattainable with conventional codes such as LDPC or Reed-Solomon. Our findings challenge traditional channel coding paradigms by establishing that code structure must align with semantic granularity. This approach is particularly suited to edge computing and IoT scenarios, where bandwidth is scarce, but semantic fidelity is critical, providing a practical pathway for next-generation semantic-aware networks.",
      "url": "http://arxiv.org/abs/2601.00186",
      "author": "Moirangthem Tiken Singh, Adnan Arif",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes RL framework for unequal error protection in semantic communication via adaptive repetition coding. Uses composite metric balancing global embedding similarity with entity-level preservation.",
      "importance_score": 44,
      "reasoning": "Novel application of RL to semantic communication protection. Shows statistically significant gains over uniform protection.",
      "themes": [
        "Semantic Communication",
        "Reinforcement Learning",
        "Error Protection"
      ],
      "continuation": null
    },
    {
      "id": "056464230f61",
      "title": "Towards Automated Differential Diagnosis of Skin Diseases Using Deep Learning and Imbalance-Aware Strategies",
      "content": "As dermatological conditions become increasingly common and the availability of dermatologists remains limited, there is a growing need for intelligent tools to support both patients and clinicians in the timely and accurate diagnosis of skin diseases. In this project, we developed a deep learning based model for the classification and diagnosis of skin conditions. By leveraging pretraining on publicly available skin disease image datasets, our model effectively extracted visual features and accurately classified various dermatological cases. Throughout the project, we refined the model architecture, optimized data preprocessing workflows, and applied targeted data augmentation techniques to improve overall performance. The final model, based on the Swin Transformer, achieved a prediction accuracy of 87.71 percent across eight skin lesion classes on the ISIC2019 dataset. These results demonstrate the model's potential as a diagnostic support tool for clinicians and a self assessment aid for patients.",
      "url": "http://arxiv.org/abs/2601.00286",
      "author": "Ali Anaissi, Ali Braytee, Weidong Huang, Junaid Akram, Alaa Farhat, Jie Hua",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Develops Swin Transformer-based model for skin disease classification with data augmentation and imbalance handling techniques, achieving high prediction accuracy.",
      "importance_score": 44,
      "reasoning": "Applied medical AI using existing architectures. Practical but limited novelty.",
      "themes": [
        "Medical AI",
        "Dermatology",
        "Image Classification"
      ],
      "continuation": null
    },
    {
      "id": "d645126f7766",
      "title": "Robust Assembly Progress Estimation via Deep Metric Learning",
      "content": "In recent years, the advancement of AI technologies has accelerated the development of smart factories. In particular, the automatic monitoring of product assembly progress is crucial for improving operational efficiency, minimizing the cost of discarded parts, and maximizing factory productivity. However, in cases where assembly tasks are performed manually over multiple days, implementing smart factory systems remains a challenge. Previous work has proposed Anomaly Triplet-Net, which estimates assembly progress by applying deep metric learning to the visual features of products. Nevertheless, when visual changes between consecutive tasks are subtle, misclassification often occurs. To address this issue, this paper proposes a robust system for estimating assembly progress, even in cases of occlusion or minimal visual change, using a small-scale dataset. Our method leverages a Quadruplet Loss-based learning approach for anomaly images and introduces a custom data loader that strategically selects training samples to enhance estimation accuracy. We evaluated our approach using a image datasets: captured during desktop PC assembly. The proposed Anomaly Quadruplet-Net outperformed existing methods on the dataset. Specifically, it improved the estimation accuracy by 1.3% and reduced misclassification between adjacent tasks by 1.9% in the desktop PC dataset and demonstrating the effectiveness of the proposed method.",
      "url": "http://arxiv.org/abs/2601.00422",
      "author": "Kazuma Miura, Sarthak Pathak, Kazunori Umeda",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes robust assembly progress estimation using deep metric learning with Anomaly Triplet-Net, addressing misclassification when visual changes between consecutive tasks are subtle.",
      "importance_score": 44,
      "reasoning": "Practical manufacturing AI application with incremental improvement over prior work.",
      "themes": [
        "Manufacturing AI",
        "Metric Learning",
        "Progress Estimation"
      ],
      "continuation": null
    },
    {
      "id": "9d272eb0e6a9",
      "title": "Optimal Transport-Based Decentralized Multi-Agent Distribution Matching",
      "content": "This paper presents a decentralized control framework for distribution matching in multi-agent systems (MAS), where agents collectively achieve a prescribed terminal spatial distribution. The problem is formulated using optimal transport (Wasserstein distance), which provides a principled measure of distributional discrepancy and serves as the basis for the control design. To avoid solving the global optimal transport problem directly, the distribution-matching objective is reformulated into a tractable per-agent decision process, enabling each agent to identify its desired terminal locations using only locally available information. A sequential weight-update rule is introduced to construct feasible local transport plans, and a memory-based correction mechanism is incorporated to maintain reliable operation under intermittent and range-limited communication. Convergence guarantees are established, showing cycle-wise improvement of a surrogate transport cost under both linear and nonlinear agent dynamics. Simulation results demonstrate that the proposed framework achieves effective and scalable distribution matching while operating fully in a decentralized manner.",
      "url": "http://arxiv.org/abs/2601.00548",
      "author": "Kooktae Lee",
      "published": "2026-01-05",
      "source": "arXiv (eess.SY)",
      "source_type": "arxiv",
      "tags": [
        "eess.SY"
      ],
      "summary": "Presents decentralized control framework for multi-agent distribution matching using optimal transport, reformulating global objective into tractable per-agent decisions with sequential weight updates.",
      "importance_score": 44,
      "reasoning": "Principled approach to multi-agent coordination using optimal transport. Solid theoretical grounding but limited experimental validation.",
      "themes": [
        "Multi-Agent Systems",
        "Optimal Transport",
        "Decentralized Control"
      ],
      "continuation": null
    },
    {
      "id": "d4b0b2f95ee7",
      "title": "Benchmarking ERP Analysis: Manual Features, Deep Learning, and Foundation Models",
      "content": "Event-related potential (ERP), a specialized paradigm of electroencephalographic (EEG), reflects neurological responses to external stimuli or events, generally associated with the brain's processing of specific cognitive tasks. ERP plays a critical role in cognitive analysis, the detection of neurological diseases, and the assessment of psychological states. Recent years have seen substantial advances in deep learning-based methods for spontaneous EEG and other non-time-locked task-related EEG signals. However, their effectiveness on ERP data remains underexplored, and many existing ERP studies still rely heavily on manually extracted features. In this paper, we conduct a comprehensive benchmark study that systematically compares traditional manual features (followed by a linear classifier), deep learning models, and pre-trained EEG foundation models for ERP analysis. We establish a unified data preprocessing and training pipeline and evaluate these approaches on two representative tasks, ERP stimulus classification and ERP-based brain disease detection, across 12 publicly available datasets. Furthermore, we investigate various patch-embedding strategies within advanced Transformer architectures to identify embedding designs that better suit ERP data. Our study provides a landmark framework to guide method selection and tailored model design for future ERP analysis. The code is available at https://github.com/DL4mHealth/ERP-Benchmark.",
      "url": "http://arxiv.org/abs/2601.00573",
      "author": "Yihe Wang, Zhiqiao Kang, Bohan Chen, Yu Zhang, Xiang Zhang",
      "published": "2026-01-05",
      "source": "arXiv (Neural and Evolutionary Computing)",
      "source_type": "arxiv",
      "tags": [
        "cs.NE"
      ],
      "summary": "Comprehensive benchmark comparing manual features, deep learning, and foundation models for ERP (event-related potential) EEG analysis across cognitive tasks.",
      "importance_score": 44,
      "reasoning": "Useful benchmark for neuroscience/BCI community. Fills gap in ERP-specific evaluation. Domain-specific but methodologically thorough.",
      "themes": [
        "EEG Analysis",
        "Benchmarks",
        "Foundation Models",
        "Neuroscience"
      ],
      "continuation": null
    },
    {
      "id": "268f84a5db86",
      "title": "RePose: A Real-Time 3D Human Pose Estimation and Biomechanical Analysis Framework for Rehabilitation",
      "content": "We propose a real-time 3D human pose estimation and motion analysis method termed RePose for rehabilitation training. It is capable of real-time monitoring and evaluation of patients'motion during rehabilitation, providing immediate feedback and guidance to assist patients in executing rehabilitation exercises correctly. Firstly, we introduce a unified pipeline for end-to-end real-time human pose estimation and motion analysis using RGB video input from multiple cameras which can be applied to the field of rehabilitation training. The pipeline can help to monitor and correct patients'actions, thus aiding them in regaining muscle strength and motor functions. Secondly, we propose a fast tracking method for medical rehabilitation scenarios with multiple-person interference, which requires less than 1ms for tracking for a single frame. Additionally, we modify SmoothNet for real-time posture estimation, effectively reducing pose estimation errors and restoring the patient's true motion state, making it visually smoother. Finally, we use Unity platform for real-time monitoring and evaluation of patients' motion during rehabilitation, and to display the muscle stress conditions to assist patients with their rehabilitation training.",
      "url": "http://arxiv.org/abs/2601.00625",
      "author": "Junxiao Xue, Pavel Smirnov, Ziao Li, Yunyun Shi, Shi Chen, Xinyi Yin, Xiaohan Yue, Lei Wang, Yiduo Wang, Feng Lin, Yijia Chen, Xiao Ma, Xiaoran Yan, Qing Zhang, Fengjian Xue, Xuecheng Wu",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes RePose for real-time 3D human pose estimation and biomechanical analysis for rehabilitation using multi-camera RGB video with fast tracking method for multi-person scenarios.",
      "importance_score": 44,
      "reasoning": "Practical system for rehabilitation applications. Fast tracking contribution is useful. Domain-specific with limited broader impact.",
      "themes": [
        "Pose Estimation",
        "Rehabilitation",
        "Computer Vision"
      ],
      "continuation": null
    },
    {
      "id": "ca3e227c6d90",
      "title": "Optimized Hybrid Feature Engineering for Resource-Efficient Arrhythmia Detection in ECG Signals: An Optimization Framework",
      "content": "Cardiovascular diseases, particularly arrhythmias, remain a leading global cause of mortality, necessitating continuous monitoring via the Internet of Medical Things (IoMT). However, state-of-the-art deep learning approaches often impose prohibitive computational overheads, rendering them unsuitable for resource-constrained edge devices. This study proposes a resource-efficient, data-centric framework that prioritizes feature engineering over complexity. Our optimized pipeline makes the complex, high-dimensional arrhythmia data linearly separable. This is achieved by integrating time-frequency wavelet decompositions with graph-theoretic structural descriptors, such as PageRank centrality. This hybrid feature space, combining wavelet decompositions and graph-theoretic descriptors, is then refined using mutual information and recursive elimination, enabling interpretable, ultra-lightweight linear classifiers. Validation on the MIT-BIH and INCART datasets yields 98.44% diagnostic accuracy with an 8.54 KB model footprint. The system achieves 0.46 $\\mu$s classification inference latency within a 52 ms per-beat pipeline, ensuring real-time operation. These outcomes provide an order-of-magnitude efficiency gain over compressed models, such as KD-Light (25 KB, 96.32% accuracy), advancing battery-less cardiac sensors.",
      "url": "http://arxiv.org/abs/2601.00192",
      "author": "Moirangthem Tiken Singh, Manibhushan Yaikhom",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes resource-efficient arrhythmia detection using optimized feature engineering combining wavelet decompositions with graph-theoretic descriptors like PageRank centrality. Designed for IoMT edge devices.",
      "importance_score": 43,
      "reasoning": "Practical approach for edge-device deployment. Feature engineering focus provides interpretability advantage over deep learning.",
      "themes": [
        "Healthcare AI",
        "Edge Computing",
        "Feature Engineering",
        "ECG Analysis"
      ],
      "continuation": null
    },
    {
      "id": "18ae62fd8b7c",
      "title": "Intelligent Traffic Surveillance for Real-Time Vehicle Detection, License Plate Recognition, and Speed Estimation",
      "content": "Speeding is a major contributor to road fatalities, particularly in developing countries such as Uganda, where road safety infrastructure is limited. This study proposes a real-time intelligent traffic surveillance system tailored to such regions, using computer vision techniques to address vehicle detection, license plate recognition, and speed estimation. The study collected a rich dataset using a speed gun, a Canon Camera, and a mobile phone to train the models. License plate detection using YOLOv8 achieved a mean average precision (mAP) of 97.9%. For character recognition of the detected license plate, the CNN model got a character error rate (CER) of 3.85%, while the transformer model significantly reduced the CER to 1.79%. Speed estimation used source and target regions of interest, yielding a good performance of 10 km/h margin of error. Additionally, a database was established to correlate user information with vehicle detection data, enabling automated ticket issuance via SMS via Africa's Talking API. This system addresses critical traffic management needs in resource-constrained environments and shows potential to reduce road accidents through automated traffic enforcement in developing countries where such interventions are urgently needed.",
      "url": "http://arxiv.org/abs/2601.00344",
      "author": "Bruce Mugizi, Sudi Murindanyi, Olivia Nakacwa, Andrew Katumba",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Develops real-time traffic surveillance system for Uganda combining YOLOv8 for vehicle detection, CNN/Transformer for license plate recognition, and geometric speed estimation.",
      "importance_score": 43,
      "reasoning": "Applied work for developing country context. Good practical value but standard techniques.",
      "themes": [
        "Traffic Surveillance",
        "Object Detection",
        "OCR"
      ],
      "continuation": null
    },
    {
      "id": "e0aaed888dc5",
      "title": "Stronger Approximation Guarantees for Non-Monotone {\\gamma}-Weakly DR-Submodular Maximization",
      "content": "Maximizing submodular objectives under constraints is a fundamental problem in machine learning and optimization. We study the maximization of a nonnegative, non-monotone $\\gamma$-weakly DR-submodular function over a down-closed convex body. Our main result is an approximation algorithm whose guarantee depends smoothly on $\\gamma$; in particular, when $\\gamma=1$ (the DR-submodular case) our bound recovers the $0.401$ approximation factor, while for $\\gamma<1$ the guarantee degrades gracefully and, it improves upon previously reported bounds for $\\gamma$-weakly DR-submodular maximization under the same constraints. Our approach combines a Frank-Wolfe-guided continuous-greedy framework with a $\\gamma$-aware double-greedy step, yielding a simple yet effective procedure for handling non-monotonicity. This results in state-of-the-art guarantees for non-monotone $\\gamma$-weakly DR-submodular maximization over down-closed convex bodies.",
      "url": "http://arxiv.org/abs/2601.00611",
      "author": "Hareshkumar Jadav and Ranveer Singh and Vaneet Aggarwal",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proves improved approximation guarantees for maximizing non-monotone γ-weakly DR-submodular functions over down-closed convex bodies, recovering 0.401 factor for DR-submodular case.",
      "importance_score": 43,
      "reasoning": "Solid theoretical optimization contribution. Improved bounds over previous work. Niche but rigorous.",
      "themes": [
        "Optimization",
        "Submodular Functions",
        "Theory"
      ],
      "continuation": null
    },
    {
      "id": "41ecc0aa659d",
      "title": "Agentic TinyML for Intent-aware Handover in 6G Wireless Networks",
      "content": "As 6G networks evolve into increasingly AI-driven, user-centric ecosystems, traditional reactive handover mechanisms demonstrate limitations, especially in mobile edge computing and autonomous agent-based service scenarios. This manuscript introduces WAAN, a cross-layer framework that enables intent-aware and proactive handovers by embedding lightweight TinyML agents as autonomous, negotiation-capable entities across heterogeneous edge nodes that contribute to intent propagation and network adaptation. To ensure continuity across mobility-induced disruptions, WAAN incorporates semi-stable rendezvous points that serve as coordination anchors for context transfer and state preservation. The framework's operational capabilities are demonstrated through a multimodal environmental control case study, highlighting its effectiveness in maintaining user experience under mobility. Finally, the article discusses key challenges and future opportunities associated with the deployment and evolution of WAAN.",
      "url": "http://arxiv.org/abs/2508.09147",
      "author": "Alaa Saleh, Roberto Morabito, Sasu Tarkoma, Anders Lindgren, Susanna Pirttikangas, and Lauri Lov\\'en",
      "published": "2026-01-05",
      "source": "arXiv (cs.NI)",
      "source_type": "arxiv",
      "tags": [
        "cs.NI"
      ],
      "summary": "Presents WAAN, a cross-layer framework enabling intent-aware proactive handovers in 6G networks by embedding TinyML agents as autonomous entities across edge nodes. Demonstrates through multimodal environmental control case study.",
      "importance_score": 42,
      "reasoning": "Interesting combination of TinyML and 6G networking concepts. Timely topic but early-stage work with limited experimental validation.",
      "themes": [
        "TinyML",
        "Edge Computing",
        "Wireless Networks"
      ],
      "continuation": null
    },
    {
      "id": "ee0d51cb884f",
      "title": "Combining datasets with different ground truths using Low-Rank Adaptation to generalize image-based CNN models for photometric redshift prediction",
      "content": "In this work, we demonstrate how Low-Rank Adaptation (LoRA) can be used to combine different galaxy imaging datasets to improve redshift estimation with CNN models for cosmology. LoRA is an established technique for large language models that adds adapter networks to adjust model weights and biases to efficiently fine-tune large base models without retraining. We train a base model using a photometric redshift ground truth dataset, which contains broad galaxy types but is less accurate. We then fine-tune using LoRA on a spectroscopic redshift ground truth dataset. These redshifts are more accurate but limited to bright galaxies and take orders of magnitude more time to obtain, so are less available for large surveys. Ideally, the combination of the two datasets would yield more accurate models that generalize well. The LoRA model performs better than a traditional transfer learning method, with $\\sim2.5\\times$ less bias and $\\sim$2.2$\\times$ less scatter. Retraining the model on a combined dataset yields a model that generalizes better than LoRA but at a cost of greater computation time. Our work shows that LoRA is useful for fine-tuning regression models in astrophysics by providing a middle ground between full retraining and no retraining. LoRA shows potential in allowing us to leverage existing pretrained astrophysical models, especially for data sparse tasks.",
      "url": "http://arxiv.org/abs/2601.00146",
      "author": "Vikram Seenivasan (1), Srinath Saikrishnan (1), Andrew Lizarraga (1), Jonathan Soriano (1), Bernie Boscoe (2), Tuan Do (1) ((1) University of California, Los Angeles, (2) Southern Oregon University)",
      "published": "2026-01-05",
      "source": "arXiv (astro-ph.IM)",
      "source_type": "arxiv",
      "tags": [
        "astro-ph.IM"
      ],
      "summary": "Demonstrates Low-Rank Adaptation (LoRA) can combine galaxy imaging datasets with different ground truths (photometric vs spectroscopic) to improve CNN redshift estimation without full model retraining.",
      "importance_score": 42,
      "reasoning": "Creative application of LoRA to astronomy. Shows transfer learning benefits for scientific data combination.",
      "themes": [
        "Astronomy",
        "Transfer Learning",
        "LoRA",
        "Scientific Machine Learning"
      ],
      "continuation": null
    },
    {
      "id": "3d9be9f4552d",
      "title": "Hear the Heartbeat in Phases: Physiologically Grounded Phase-Aware ECG Biometrics",
      "content": "Electrocardiography (ECG) is adopted for identity authentication in wearable devices due to its individual-specific characteristics and inherent liveness. However, existing methods often treat heartbeats as homogeneous signals, overlooking the phase-specific characteristics within the cardiac cycle. To address this, we propose a Hierarchical Phase-Aware Fusion~(HPAF) framework that explicitly avoids cross-feature entanglement through a three-stage design. In the first stage, Intra-Phase Representation (IPR) independently extracts representations for each cardiac phase, ensuring that phase-specific morphological and variation cues are preserved without interference from other phases. In the second stage, Phase-Grouped Hierarchical Fusion (PGHF) aggregates physiologically related phases in a structured manner, enabling reliable integration of complementary phase information. In the final stage, Global Representation Fusion (GRF) further combines the grouped representations and adaptively balances their contributions to produce a unified and discriminative identity representation. Moreover, considering ECG signals are continuously acquired, multiple heartbeats can be collected for each individual. We propose a Heartbeat-Aware Multi-prototype (HAM) enrollment strategy, which constructs a multi-prototype gallery template set to reduce the impact of heartbeat-specific noise and variability. Extensive experiments on three public datasets demonstrate that HPAF achieves state-of-the-art results in the comparison with other methods under both closed and open-set settings.",
      "url": "http://arxiv.org/abs/2601.00170",
      "author": "Jintao Huang and Lu Leng and Yi Zhang and Ziyuan Yang",
      "published": "2026-01-05",
      "source": "arXiv (eess.IV)",
      "source_type": "arxiv",
      "tags": [
        "eess.IV"
      ],
      "summary": "Proposes Hierarchical Phase-Aware Fusion (HPAF) framework for ECG biometrics that explicitly models cardiac cycle phases. Uses three-stage design to avoid cross-feature entanglement while preserving phase-specific characteristics.",
      "importance_score": 42,
      "reasoning": "Novel approach leveraging cardiac physiology for biometrics. Well-motivated design but limited comparison to other modalities.",
      "themes": [
        "Biometrics",
        "ECG Analysis",
        "Healthcare AI"
      ],
      "continuation": null
    },
    {
      "id": "d2627a125b71",
      "title": "Application Research of a Deep Learning Model Integrating CycleGAN and YOLO in PCB Infrared Defect Detection",
      "content": "This paper addresses the critical bottleneck of infrared (IR) data scarcity in Printed Circuit Board (PCB) defect detection by proposing a cross-modal data augmentation framework integrating CycleGAN and YOLOv8. Unlike conventional methods relying on paired supervision, we leverage CycleGAN to perform unpaired image-to-image translation, mapping abundant visible-light PCB images into the infrared domain. This generative process synthesizes high-fidelity pseudo-IR samples that preserve the structural semantics of defects while accurately simulating thermal distribution patterns. Subsequently, we construct a heterogeneous training strategy that fuses generated pseudo-IR data with limited real IR samples to train a lightweight YOLOv8 detector. Experimental results demonstrate that this method effectively enhances feature learning under low-data conditions. The augmented detector significantly outperforms models trained on limited real data alone and approaches the performance benchmarks of fully supervised training, proving the efficacy of pseudo-IR synthesis as a robust augmentation strategy for industrial inspection.",
      "url": "http://arxiv.org/abs/2601.00237",
      "author": "Chao Yang, Haoyuan Zheng, Yue Ma",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Combines CycleGAN for unpaired visible-to-infrared image translation with YOLOv8 for PCB defect detection, addressing infrared data scarcity in industrial inspection.",
      "importance_score": 42,
      "reasoning": "Applied work combining existing methods without novel contributions. Useful industrial application but limited research novelty.",
      "themes": [
        "Industrial Inspection",
        "Data Augmentation",
        "Object Detection"
      ],
      "continuation": null
    },
    {
      "id": "e6e039709961",
      "title": "Replaceable Bit-based Gripper for Picking Cluttered Food Items",
      "content": "The food packaging industry goes through changes in food items and their weights quite rapidly. These items range from easy-to-pick, single-piece food items to flexible, long and cluttered ones. We propose a replaceable bit-based gripper system to tackle the challenge of weight-based handling of cluttered food items. The gripper features specialized food attachments(bits) that enhance its grasping capabilities, and a belt replacement system allows switching between different food items during packaging operations. It offers a wide range of control options, enabling it to grasp and drop specific weights of granular, cluttered, and entangled foods. We specifically designed bits for two flexible food items that differ in shape: ikura(salmon roe) and spaghetti. They represent the challenging categories of sticky, granular food and long, sticky, cluttered food, respectively. The gripper successfully picked up both spaghetti and ikura and demonstrated weight-specific dropping of these items with an accuracy over 80% and 95% respectively. The gripper system also exhibited quick switching between different bits, leading to the handling of a large range of food items.",
      "url": "http://arxiv.org/abs/2601.00305",
      "author": "Prashant Kumar, Yukiyasu Domae, Weiwei Wan, and Kensuke Harada",
      "published": "2026-01-05",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Presents replaceable bit-based gripper system for handling cluttered food items with weight-based control, featuring specialized attachments for different food types like salmon roe and spaghetti.",
      "importance_score": 42,
      "reasoning": "Practical robotics engineering for food industry but narrow application scope.",
      "themes": [
        "Robotics",
        "Manipulation",
        "Food Industry"
      ],
      "continuation": null
    },
    {
      "id": "77b5d0ac1fed",
      "title": "Quadratic Unconstrained Binary Optimisation for Training and Regularisation of Binary Neural Networks",
      "content": "Advances in artificial intelligence (AI) and deep learning have raised concerns about its increasing energy consumption, while demand for deploying AI in mobile devices and machines at the edge is growing. Binary neural networks (BNNs) have recently gained attention as energy and memory efficient models suitable for resource constrained environments; however, training BNNs exactly is computationally challenging because of its discrete characteristics. Recent work proposing a framework for training BNNs based on quadratic unconstrained binary optimisation (QUBO) and progress in the design of Ising machines for solving QUBO problems suggest a potential path to efficiently optimising discrete neural networks. In this work, we extend existing QUBO models for training BNNs to accommodate arbitrary network topologies and propose two novel methods for regularisation. The first method maximises neuron margins biasing the training process toward parameter configurations that yield larger pre-activation magnitudes. The second method employs a dropout-inspired iterative scheme in which reduced subnetworks are trained and used to adjust linear penalties on network parameters. We apply the proposed QUBO formulation to a small binary image classification problem and conduct computational experiments on a GPU-based Ising machine. The numerical results indicate that the proposed regularisation terms modify training behaviour and yield improvements in classification accuracy on data not present in the training set.",
      "url": "http://arxiv.org/abs/2601.00449",
      "author": "Jonas Christoffer Villumsen and Yusuke Sugita",
      "published": "2026-01-05",
      "source": "arXiv (math.OC)",
      "source_type": "arxiv",
      "tags": [
        "math.OC"
      ],
      "summary": "Extends QUBO-based training framework for binary neural networks to handle arbitrary architectures, connecting to Ising machines for potential quantum/specialized hardware acceleration.",
      "importance_score": 42,
      "reasoning": "Novel approach connecting BNN training to quantum-compatible optimization. Interesting future direction but current practical impact limited. Niche application area.",
      "themes": [
        "Neural Network Training",
        "Efficient AI",
        "Quantum Computing"
      ],
      "continuation": null
    },
    {
      "id": "6abc1a29c5d3",
      "title": "Cloud-Native Generative AI for Automated Planogram Synthesis: A Diffusion Model Approach for Multi-Store Retail Optimization",
      "content": "Planogram creation is a significant challenge for retail, requiring an average of 30 hours per complex layout. This paper introduces a cloud-native architecture using diffusion models to automatically generate store-specific planograms. Unlike conventional optimization methods that reorganize existing layouts, our system learns from successful shelf arrangements across multiple retail locations to create new planogram configurations. The architecture combines cloud-based model training via AWS with edge deployment for real-time inference. The diffusion model integrates retail-specific constraints through a modified loss function. Simulation-based analysis demonstrates the system reduces planogram design time by 98.3% (from 30 to 0.5 hours) while achieving 94.4% constraint satisfaction. Economic analysis reveals a 97.5% reduction in creation expenses with a 4.4-month break-even period. The cloud-native architecture scales linearly, supporting up to 10,000 concurrent store requests. This work demonstrates the viability of generative AI for automated retail space optimization.",
      "url": "http://arxiv.org/abs/2601.00527",
      "author": "Ravi Teja Pagidoju and Shriya Agarwal",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes cloud-native architecture using diffusion models to generate retail planograms, reducing design time by 98.3% while achieving 94.4% constraint satisfaction through modified loss function.",
      "importance_score": 42,
      "reasoning": "Creative application of diffusion models to retail optimization. Strong practical results but simulation-based validation. Limited broader research contribution.",
      "themes": [
        "Diffusion Models",
        "Retail",
        "Applied AI"
      ],
      "continuation": null
    },
    {
      "id": "68a5122f22c4",
      "title": "Traffic-Aware Optimal Taxi Placement Using Graph Neural Network-Based Reinforcement Learning",
      "content": "In the context of smart city transportation, efficient matching of taxi supply with passenger demand requires real-time integration of urban traffic network data and mobility patterns. Conventional taxi hotspot prediction models often rely solely on historical demand, overlooking dynamic influences such as traffic congestion, road incidents, and public events. This paper presents a traffic-aware, graph-based reinforcement learning (RL) framework for optimal taxi placement in metropolitan environments. The urban road network is modeled as a graph where intersections represent nodes, road segments serve as edges, and node attributes capture historical demand, event proximity, and real-time congestion scores obtained from live traffic APIs. Graph Neural Network (GNN) embeddings are employed to encode spatial-temporal dependencies within the traffic network, which are then used by a Q-learning agent to recommend optimal taxi hotspots. The reward mechanism jointly optimizes passenger waiting time, driver travel distance, and congestion avoidance. Experiments on a simulated Delhi taxi dataset, generated using real geospatial boundaries and historic ride-hailing request patterns, demonstrate that the proposed model reduced passenger waiting time by about 56% and reduced travel distance by 38% compared to baseline stochastic selection. The proposed approach is adaptable to multi-modal transport systems and can be integrated into smart city platforms for real-time urban mobility optimization.",
      "url": "http://arxiv.org/abs/2601.00607",
      "author": "Sonia Khetarpaul, P Y Sharan",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes GNN-based RL framework for taxi placement using urban road graph with traffic, demand, and event features, employing GNN embeddings for state representation in metropolitan environments.",
      "importance_score": 42,
      "reasoning": "Reasonable application of GNN-RL to transportation. Uses real traffic APIs for practical relevance. Incremental technical contribution.",
      "themes": [
        "Reinforcement Learning",
        "Graph Neural Networks",
        "Transportation"
      ],
      "continuation": null
    },
    {
      "id": "520ecbf78d3b",
      "title": "QSLM: A Performance- and Memory-aware Quantization Framework with Tiered Search Strategy for Spike-driven Language Models",
      "content": "Large Language Models (LLMs) have been emerging as prominent AI models for solving many natural language tasks due to their high performance (e.g., accuracy) and capabilities in generating high-quality responses to the given inputs. However, their large computational cost, huge memory footprints, and high processing power/energy make it challenging for their embedded deployments. Amid several tinyLLMs, recent works have proposed spike-driven language models (SLMs) for significantly reducing the processing power/energy of LLMs. However, their memory footprints still remain too large for low-cost and resource-constrained embedded devices. Manual quantization approach may effectively compress SLM memory footprints, but it requires a huge design time and compute power to find the quantization setting for each network, hence making this approach not-scalable for handling different networks, performance requirements, and memory budgets. To bridge this gap, we propose QSLM, a novel framework that performs automated quantization for compressing pre-trained SLMs, while meeting the performance and memory constraints. To achieve this, QSLM first identifies the hierarchy of the given network architecture and the sensitivity of network layers under quantization, then employs a tiered quantization strategy (e.g., global-, block-, and module-level quantization) while leveraging a multi-objective performance-and-memory trade-off function to select the final quantization setting. Experimental results indicate that our QSLM reduces memory footprint by up to 86.5%, reduces power consumption by up to 20%, maintains high performance across different tasks (i.e., by up to 84.4% accuracy of sentiment classification on the SST-2 dataset and perplexity score of 23.2 for text generation on the WikiText-2 dataset) close to the original non-quantized model while meeting the performance and memory constraints.",
      "url": "http://arxiv.org/abs/2601.00679",
      "author": "Rachmad Vidya Wicaksana Putra, Pasindu Wickramasinghe, Muhammad Shafique",
      "published": "2026-01-05",
      "source": "arXiv (Neural and Evolutionary Computing)",
      "source_type": "arxiv",
      "tags": [
        "cs.NE"
      ],
      "summary": "Proposes QSLM, a quantization framework with tiered search strategy for spike-driven language models, aiming to reduce memory footprints for embedded deployment while maintaining performance.",
      "importance_score": 42,
      "reasoning": "Niche intersection of quantization and spiking neural networks for LLMs. Important for edge deployment but limited immediate applicability given current SLM maturity. Addresses real problem of LLM memory footprints.",
      "themes": [
        "Model Compression",
        "Spiking Neural Networks",
        "Language Models",
        "Edge AI"
      ],
      "continuation": null
    },
    {
      "id": "e34c32319d32",
      "title": "Multi-Level Feature Fusion for Continual Learning in Visual Quality Inspection",
      "content": "Deep neural networks show great potential for automating various visual quality inspection tasks in manufacturing. However, their applicability is limited in more volatile scenarios, such as remanufacturing, where the inspected products and defect patterns often change. In such settings, deployed models require frequent adaptation to novel conditions, effectively posing a continual learning problem. To enable quick adaptation, the necessary training processes must be computationally efficient while still avoiding effects like catastrophic forgetting. This work presents a multi-level feature fusion (MLFF) approach that aims to improve both aspects simultaneously by utilizing representations from different depths of a pretrained network. We show that our approach is able to match the performance of end-to-end training for different quality inspection problems while using significantly less trainable parameters. Furthermore, it reduces catastrophic forgetting and improves generalization robustness to new product types or defects.",
      "url": "http://arxiv.org/abs/2601.00725",
      "author": "Johannes C. Bauer and Paul Geng and Stephan Trattnig and Petr Dokl\\'adal and R\\\"udiger Daub",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes multi-level feature fusion approach for continual learning in visual quality inspection, utilizing representations from different network depths to enable efficient adaptation while avoiding catastrophic forgetting.",
      "importance_score": 42,
      "reasoning": "Practical contribution for manufacturing AI. Addresses real challenge of model adaptation in volatile settings. Limited novelty - feature fusion for continual learning is well-explored.",
      "themes": [
        "Continual Learning",
        "Computer Vision",
        "Manufacturing AI"
      ],
      "continuation": null
    },
    {
      "id": "3cf4512adee9",
      "title": "LLM Agents for Combinatorial Efficient Frontiers: Investment Portfolio Optimization",
      "content": "Investment portfolio optimization is a task conducted in all major financial institutions. The Cardinality Constrained Mean-Variance Portfolio Optimization (CCPO) problem formulation is ubiquitous for portfolio optimization. The challenge of this type of portfolio optimization, a mixed-integer quadratic programming (MIQP) problem, arises from the intractability of solutions from exact solvers, where heuristic algorithms are used to find approximate portfolio solutions. CCPO entails many laborious and complex workflows and also requires extensive effort pertaining to heuristic algorithm development, where the combination of pooled heuristic solutions results in improved efficient frontiers. Hence, common approaches are to develop many heuristic algorithms. Agentic frameworks emerge as a promising candidate for many problems within combinatorial optimization, as they have been shown to be equally efficient with regard to automating large workflows and have been shown to be excellent in terms of algorithm development, sometimes surpassing human-level performance. This study implements a novel agentic framework for the CCPO and explores several concrete architectures. In benchmark problems, the implemented agentic framework matches state-of-the-art algorithms. Furthermore, complex workflows and algorithm development efforts are alleviated, while in the worst case, lower but acceptable error is reported.",
      "url": "http://arxiv.org/abs/2601.00770",
      "author": "Simon Paquette-Greenbaum, Jiangbo Yu",
      "published": "2026-01-05",
      "source": "arXiv (cs.CE)",
      "source_type": "arxiv",
      "tags": [
        "cs.CE"
      ],
      "summary": "Applies LLM agents to Cardinality Constrained Mean-Variance Portfolio Optimization, using agentic frameworks to automate heuristic algorithm development for improved efficient frontiers.",
      "importance_score": 42,
      "reasoning": "Interesting application of LLM agents to financial optimization. Novel use case but limited methodological contribution. The agentic approach to heuristic development is creative.",
      "themes": [
        "LLM Agents",
        "Financial AI",
        "Optimization"
      ],
      "continuation": null
    },
    {
      "id": "d0494efde947",
      "title": "Integrating Multi-Armed Bandit, Active Learning, and Distributed Computing for Scalable Optimization",
      "content": "Modern optimization problems in scientific and engineering domains often rely on expensive black-box evaluations, such as those arising in physical simulations or deep learning pipelines, where gradient information is unavailable or unreliable. In these settings, conventional optimization methods quickly become impractical due to prohibitive computational costs and poor scalability. We propose ALMAB-DC, a unified and modular framework for scalable black-box optimization that integrates active learning, multi-armed bandits, and distributed computing, with optional GPU acceleration. The framework leverages surrogate modeling and information-theoretic acquisition functions to guide informative sample selection, while bandit-based controllers dynamically allocate computational resources across candidate evaluations in a statistically principled manner. These decisions are executed asynchronously within a distributed multi-agent system, enabling high-throughput parallel evaluation. We establish theoretical regret bounds for both UCB-based and Thompson-sampling-based variants and develop a scalability analysis grounded in Amdahl's and Gustafson's laws. Empirical results across synthetic benchmarks, reinforcement learning tasks, and scientific simulation problems demonstrate that ALMAB-DC consistently outperforms state-of-the-art black-box optimizers. By design, ALMAB-DC is modular, uncertainty-aware, and extensible, making it particularly well suited for high-dimensional, resource-intensive optimization challenges.",
      "url": "http://arxiv.org/abs/2601.00615",
      "author": "Foo Hui-Mean and Yuan-chin Ivan Chang",
      "published": "2026-01-05",
      "source": "arXiv (stat.CO)",
      "source_type": "arxiv",
      "tags": [
        "stat.CO"
      ],
      "summary": "Proposes ALMAB-DC, a framework integrating active learning, multi-armed bandits, and distributed computing for scalable black-box optimization with optional GPU acceleration.",
      "importance_score": 42,
      "reasoning": "Practical optimization framework combining several techniques. Modular design is useful. However, primarily engineering integration rather than novel methodology.",
      "themes": [
        "Black-Box Optimization",
        "Active Learning",
        "Multi-Armed Bandits",
        "Distributed Computing"
      ],
      "continuation": null
    },
    {
      "id": "d7824e4e7b18",
      "title": "Comparative Evaluation of Embedding Representations for Financial News Sentiment Analysis",
      "content": "Financial sentiment analysis enhances market understanding; however, standard natural language processing approaches encounter significant challenges when applied to small datasets. This study provides a comparative evaluation of embedding-based methods for financial news sentiment classification in resource-constrained environments. Word2Vec, GloVe, and sentence transformer representations are evaluated in combination with gradient boosting on manually labeled headlines. Experimental results identify a substantial gap between validation and test performance, with models performing worse than trivial baselines despite strong validation metrics. The analysis demonstrates that pretrained embeddings yield diminishing returns below a critical data sufficiency threshold, and that small validation sets contribute to overfitting during model selection. Practical application is illustrated through weekly sentiment aggregation and narrative summarization for market monitoring workflows. The findings offer empirical evidence that embedding quality alone cannot address fundamental data scarcity in sentiment classification. For practitioners operating with limited resources, the results indicate the need to consider alternative approaches such as few-shot learning, data augmentation, or lexicon-enhanced hybrid methods when labeled samples are scarce.",
      "url": "http://arxiv.org/abs/2512.13749",
      "author": "Joyjit Roy, Samaresh Kumar Singh",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Compares Word2Vec, GloVe, and sentence transformers for financial sentiment analysis on small datasets. Reveals significant gap between validation and test performance, with models underperforming trivial baselines despite good validation metrics.",
      "importance_score": 40,
      "reasoning": "Useful negative result highlighting limitations of pretrained embeddings on small datasets. Important practical findings but limited novel methodology.",
      "themes": [
        "Natural Language Processing",
        "Financial Analysis",
        "Sentiment Analysis"
      ],
      "continuation": null
    },
    {
      "id": "1e751e2ceb4a",
      "title": "Automated electrostatic characterization of quantum dot devices in single- and bilayer heterostructures",
      "content": "As quantum dot (QD)-based spin qubits advance toward larger, more complex device architectures, rapid, automated device characterization and data analysis tools become critical. The orientation and spacing of transition lines in a charge stability diagram (CSD) contain a fingerprint of a QD device's capacitive environment, making these measurements useful tools for device characterization. However, manually interpreting these features is time-consuming, error-prone, and impractical at scale. Here, we present an automated protocol for extracting underlying capacitive properties from CSDs. Our method integrates machine learning, image processing, and object detection to identify and track charge transitions across large datasets without manual labeling. We demonstrate this method using experimentally measured data from a strained-germanium single-quantum-well (planar) and a strained-germanium double-quantum-well (bilayer) QD device. Unlike for planar QD devices, CSDs in bilayer germanium heterostructure exhibit a larger set of transitions, including interlayer tunneling and distinct loading lines for the vertically stacked QDs, making them a powerful testbed for automation methods. By analyzing the properties of many CSDs, we can statistically estimate physically relevant quantities, like relative lever arms and capacitive couplings. Thus, our protocol enables rapid extraction of useful, nontrivial information about QD devices.",
      "url": "http://arxiv.org/abs/2601.00067",
      "author": "Merritt P. R. Losert, Dario Denora, Barnaby van Straaten, Michael Chan, Stefan D. Oosterhout, Lucas Stehouwer, Giordano Scappucci, Menno Veldhorst, Justyna P. Zwolak",
      "published": "2026-01-05",
      "source": "arXiv (cond-mat.mes-hall)",
      "source_type": "arxiv",
      "tags": [
        "cond-mat.mes-hall"
      ],
      "summary": "Presents automated protocol for extracting capacitive properties from quantum dot charge stability diagrams using ML, image processing, and object detection. Demonstrates on single and bilayer heterostructures without manual labeling.",
      "importance_score": 40,
      "reasoning": "Specialized physics/ML application for quantum computing device characterization. Useful tool but narrow domain.",
      "themes": [
        "Quantum Computing",
        "Automated Characterization",
        "Computer Vision"
      ],
      "continuation": null
    },
    {
      "id": "0a0c79a15d58",
      "title": "SSI-GAN: Semi-Supervised Swin-Inspired Generative Adversarial Networks for Neuronal Spike Classification",
      "content": "Mosquitos are the main transmissive agents of arboviral diseases. Manual classification of their neuronal spike patterns is very labor-intensive and expensive. Most available deep learning solutions require fully labeled spike datasets and highly preprocessed neuronal signals. This reduces the feasibility of mass adoption in actual field scenarios. To address the scarcity of labeled data problems, we propose a new Generative Adversarial Network (GAN) architecture that we call the Semi-supervised Swin-Inspired GAN (SSI-GAN). The Swin-inspired, shifted-window discriminator, together with a transformer-based generator, is used to classify neuronal spike trains and, consequently, detect viral neurotropism. We use a multi-head self-attention model in a flat, window-based transformer discriminator that learns to capture sparser high-frequency spike features. Using just 1 to 3% labeled data, SSI-GAN was trained with more than 15 million spike samples collected at five-time post-infection and recording classification into Zika-infected, dengue-infected, or uninfected categories. Hyperparameters were optimized using the Bayesian Optuna framework, and performance for robustness was validated under fivefold Monte Carlo cross-validation. SSI-GAN reached 99.93% classification accuracy on the third day post-infection with only 3% labeled data. It maintained high accuracy across all stages of infection with just 1% supervision. This shows a 97-99% reduction in manual labeling effort relative to standard supervised approaches at the same performance level. The shifted-window transformer design proposed here beat all baselines by a wide margin and set new best marks in spike-based neuronal infection classification.",
      "url": "http://arxiv.org/abs/2601.00189",
      "author": "Danial Sharifrazi, Nouman Javed, Mojtaba Mohammadi, Seyede Sana Salehi, Roohallah Alizadehsani, Prasad N. Paradkar, U. Rajendra Acharya, Asim Bhatti",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes SSI-GAN, a semi-supervised GAN with Swin-inspired shifted-window discriminator for classifying mosquito neuronal spikes to detect viral neurotropism. Uses transformer-based generator for arboviral disease detection.",
      "importance_score": 40,
      "reasoning": "Novel architecture for specialized neuroscience application. Creative combination of techniques but narrow domain.",
      "themes": [
        "GANs",
        "Neuronal Signal Classification",
        "Semi-Supervised Learning"
      ],
      "continuation": null
    },
    {
      "id": "2f0621ed114a",
      "title": "Context-Aware Pesticide Recommendation via Few-Shot Pest Recognition for Precision Agriculture",
      "content": "Effective pest management is crucial for enhancing agricultural productivity, especially for crops such as sugarcane and wheat that are highly vulnerable to pest infestations. Traditional pest management methods depend heavily on manual field inspections and the use of chemical pesticides. These approaches are often costly, time-consuming, labor-intensive, and can have a negative impact on the environment. To overcome these challenges, this study presents a lightweight framework for pest detection and pesticide recommendation, designed for low-resource devices such as smartphones and drones, making it suitable for use by small and marginal farmers.   The proposed framework includes two main components. The first is a Pest Detection Module that uses a compact, lightweight convolutional neural network (CNN) combined with prototypical meta-learning to accurately identify pests even when only a few training samples are available. The second is a Pesticide Recommendation Module that incorporates environmental factors like crop type and growth stage to suggest safe and eco-friendly pesticide recommendations. To train and evaluate our framework, a comprehensive pest image dataset was developed by combining multiple publicly available datasets. The final dataset contains samples with different viewing angles, pest sizes, and background conditions to ensure strong generalization.   Experimental results show that the proposed lightweight CNN achieves high accuracy, comparable to state-of-the-art models, while significantly reducing computational complexity. The Decision Support System additionally improves pest management by reducing dependence on traditional chemical pesticides and encouraging sustainable practices, demonstrating its potential for real-time applications in precision agriculture.",
      "url": "http://arxiv.org/abs/2601.00243",
      "author": "Anirudha Ghosh, Ritam Sarkar, Debaditya Barman",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Presents a lightweight framework for pest detection and pesticide recommendation using few-shot learning, designed for low-resource devices like smartphones and drones for agricultural applications.",
      "importance_score": 40,
      "reasoning": "Applied AI for agriculture with practical deployment considerations, but limited technical novelty.",
      "themes": [
        "Agricultural AI",
        "Few-Shot Learning",
        "Edge Deployment"
      ],
      "continuation": null
    },
    {
      "id": "341b9c5d0699",
      "title": "Vehicle Painting Robot Path Planning Using Hierarchical Optimization",
      "content": "In vehicle production factories, the vehicle painting process employs multiple robotic arms to simultaneously apply paint to car bodies advancing along a conveyor line. Designing paint paths for these robotic arms, which involves assigning car body areas to arms and determining paint sequences for each arm, remains a time-consuming manual task for engineers, indicating the demand for automation and design time reduction. The unique constraints of the painting process hinder the direct application of conventional robotic path planning techniques, such as those used in welding. Therefore, this paper formulates the design of paint paths as a hierarchical optimization problem, where the upper-layer subproblem resembles a vehicle routing problem (VRP), and the lower-layer subproblem involves detailed path planning. This approach allows the use of different optimization algorithms at each layer, and permits flexible handling of constraints specific to the vehicle painting process through the design of variable representation, constraints, repair operators, and an initialization process at the upper and lower layers. Experiments with three commercially available vehicle models demonstrated that the proposed method can automatically design paths that satisfy all constraints for vehicle painting with quality comparable to those created manually by engineers.",
      "url": "http://arxiv.org/abs/2601.00271",
      "author": "Yuya Nagai, Hiromitsu Nakamura, Narito Shinmachi, Yuta Higashizono, Satoshi Ono",
      "published": "2026-01-05",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Formulates vehicle painting robot path planning as hierarchical optimization combining vehicle routing problem with motion planning for multi-arm coordination.",
      "importance_score": 40,
      "reasoning": "Industrial robotics application with practical value but limited research novelty.",
      "themes": [
        "Robotics",
        "Motion Planning",
        "Manufacturing"
      ],
      "continuation": null
    },
    {
      "id": "050c075be296",
      "title": "Space Debris Removal using Nano-Satellites controlled by Low-Power Autonomous Agents",
      "content": "Space debris is an ever-increasing problem in space travel. There are already many old, no longer functional spacecraft and debris orbiting the earth, which endanger both the safe operation of satellites and space travel. Small nano-satellite swarms can address this problem by autonomously de-orbiting debris safely into the Earth's atmosphere. This work builds on the recent advances of autonomous agents deployed in resource-constrained platforms and shows a first simplified approach how such intelligent and autonomous nano-satellite swarms can be realized. We implement our autonomous agent software on wireless microcontrollers and perform experiments on a specialized test-bed to show the feasibility and overall energy efficiency of our approach.",
      "url": "http://arxiv.org/abs/2601.00465",
      "author": "Dennis Christmann, Juan F. Gutierrez, Sthiti Padhi, Patrick Pl\\\"orer, Aditya Takur, Simona Silvestri, and Andres Gomez",
      "published": "2026-01-05",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Demonstrates feasibility of autonomous nano-satellite swarms for space debris removal using resource-constrained autonomous agents, implementing software on wireless microcontrollers.",
      "importance_score": 40,
      "reasoning": "Interesting application domain but preliminary work. Limited technical depth on the AI/ML aspects. More engineering than research contribution.",
      "themes": [
        "Robotics",
        "Autonomous Agents",
        "Space Applications"
      ],
      "continuation": null
    },
    {
      "id": "67bf0cd9ed9a",
      "title": "Generative Conditional Missing Imputation Networks",
      "content": "In this study, we introduce a sophisticated generative conditional strategy designed to impute missing values within datasets, an area of considerable importance in statistical analysis. Specifically, we initially elucidate the theoretical underpinnings of the Generative Conditional Missing Imputation Networks (GCMI), demonstrating its robust properties in the context of the Missing Completely at Random (MCAR) and the Missing at Random (MAR) mechanisms. Subsequently, we enhance the robustness and accuracy of GCMI by integrating a multiple imputation framework using a chained equations approach. This innovation serves to bolster model stability and improve imputation performance significantly. Finally, through a series of meticulous simulations and empirical assessments utilizing benchmark datasets, we establish the superior efficacy of our proposed methods when juxtaposed with other leading imputation techniques currently available. This comprehensive evaluation not only underscores the practicality of GCMI but also affirms its potential as a leading-edge tool in the field of statistical data analysis.",
      "url": "http://arxiv.org/abs/2601.00517",
      "author": "George Sun, Yi-Hui Zhou",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning (Statistics))",
      "source_type": "arxiv",
      "tags": [
        "stat.ML"
      ],
      "summary": "Introduces theoretical framework for missing data imputation using generative conditional networks with formal properties under MCAR and MAR mechanisms, enhanced with multiple imputation.",
      "importance_score": 40,
      "reasoning": "Solid theoretical contribution to imputation methods. Well-grounded in missing data theory. Limited practical novelty over existing approaches.",
      "themes": [
        "Missing Data",
        "Generative Models",
        "Statistical Learning"
      ],
      "continuation": null
    },
    {
      "id": "1152076c853f",
      "title": "A Vision-and-Knowledge Enhanced Large Language Model for Generalizable Pedestrian Crossing Behavior Inference",
      "content": "Existing paradigms for inferring pedestrian crossing behavior, ranging from statistical models to supervised learning methods, demonstrate limited generalizability and perform inadequately on new sites. Recent advances in Large Language Models (LLMs) offer a shift from numerical pattern fitting to semantic, context-aware behavioral reasoning, yet existing LLM applications lack domain-specific adaptation and visual context. This study introduces Pedestrian Crossing LLM (PedX-LLM), a vision-and-knowledge enhanced framework designed to transform pedestrian crossing inference from site-specific pattern recognition to generalizable behavioral reasoning. By integrating LLaVA-extracted visual features with textual data and transportation domain knowledge, PedX-LLM fine-tunes a LLaMA-2-7B foundation model via Low-Rank Adaptation (LoRA) to infer crossing decisions. PedX-LLM achieves 82.0% balanced accuracy, outperforming the best statistical and supervised learning methods. Results demonstrate that the vision-augmented module contributes a 2.9% performance gain by capturing the built environment and integrating domain knowledge yields an additional 4.1% improvement. To evaluate generalizability across unseen environments, cross-site validation was conducted using site-based partitioning. The zero-shot PedX-LLM configuration achieves 66.9% balanced accuracy on five unseen test sites, outperforming the baseline data-driven methods by at least 18 percentage points. Incorporating just five validation examples via few-shot learning to PedX-LLM further elevates the balanced accuracy to 72.2%. PedX-LLM demonstrates strong generalizability to unseen scenarios, confirming that vision-and-knowledge-enhanced reasoning enables the model to mimic human-like decision logic and overcome the limitations of purely data-driven methods.",
      "url": "http://arxiv.org/abs/2601.00694",
      "author": "Qingwen Pu, Kun Xie, Hong Yang, Guocong Zhai",
      "published": "2026-01-05",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Introduces PedX-LLM, a vision-and-knowledge enhanced framework for pedestrian crossing behavior prediction using LLaVA visual features with LLaMA-2-7B, aiming to improve generalizability across different sites compared to traditional methods.",
      "importance_score": 40,
      "reasoning": "Domain-specific application of VLMs to transportation safety. Shows value of domain knowledge integration but limited novelty in methodology. Practical implications for autonomous driving.",
      "themes": [
        "Vision-Language Models",
        "Autonomous Driving",
        "Domain Adaptation"
      ],
      "continuation": null
    },
    {
      "id": "83d7159520b6",
      "title": "Grading Handwritten Engineering Exams with Multimodal Large Language Models",
      "content": "Handwritten STEM exams capture open-ended reasoning and diagrams, but manual grading is slow and difficult to scale. We present an end-to-end workflow for grading scanned handwritten engineering quizzes with multimodal large language models (LLMs) that preserves the standard exam process (A4 paper, unconstrained student handwriting). The lecturer provides only a handwritten reference solution (100%) and a short set of grading rules; the reference is converted into a text-only summary that conditions grading without exposing the reference scan. Reliability is achieved through a multi-stage design with a format/presence check to prevent grading blank answers, an ensemble of independent graders, supervisor aggregation, and rigid templates with deterministic validation to produce auditable, machine-parseable reports. We evaluate the frozen pipeline in a clean-room protocol on a held-out real course quiz in Slovenian, including hand-drawn circuit schematics. With state-of-the-art backends (GPT-5.2 and Gemini-3 Pro), the full pipeline achieves $\\approx$8-point mean absolute difference to lecturer grades with low bias and an estimated manual-review trigger rate of $\\approx$17% at $D_{\\max}=40$. Ablations show that trivial prompting and removing the reference solution substantially degrade accuracy and introduce systematic over-grading, confirming that structured prompting and reference grounding are essential.",
      "url": "http://arxiv.org/abs/2601.00730",
      "author": "Janez Per\\v{s}, Jon Muhovi\\v{c}, Andrej Ko\\v{s}ir, Bo\\v{s}tjan Murovec",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Presents end-to-end workflow for grading handwritten engineering exams using multimodal LLMs, with multi-stage design including format checking, ensemble grading, and supervisor aggregation for reliability.",
      "importance_score": 40,
      "reasoning": "Practical application of MLLMs with solid engineering. Useful for educational settings but limited research novelty. The multi-stage reliability approach is sensible but not novel.",
      "themes": [
        "Multimodal LLMs",
        "Education Technology",
        "Document Understanding"
      ],
      "continuation": null
    },
    {
      "id": "fd7d1dcde033",
      "title": "Deep learning estimation of the spectral density of functional time series on large domains",
      "content": "We derive an estimator of the spectral density of a functional time series that is the output of a multilayer perceptron neural network. The estimator is motivated by difficulties with the computation of existing spectral density estimators for time series of functions defined on very large grids that arise, for example, in climate compute models and medical scans. Existing estimators use autocovariance kernels represented as large $G \\times G$ matrices, where $G$ is the number of grid points on which the functions are evaluated. In many recent applications, functions are defined on 2D and 3D domains, and $G$ can be of the order $G \\sim 10^5$, making the evaluation of the autocovariance kernels computationally intensive or even impossible. We use the theory of spectral functional principal components to derive our deep learning estimator and prove that it is a universal approximator to the spectral density under general assumptions. Our estimator can be trained without computing the autocovariance kernels and it can be parallelized to provide the estimates much faster than existing approaches. We validate its performance by simulations and an application to fMRI images.",
      "url": "http://arxiv.org/abs/2601.00284",
      "author": "Neda Mohammadi and Soham Sarkar and Piotr Kokoszka",
      "published": "2026-01-05",
      "source": "arXiv (stat.ME)",
      "source_type": "arxiv",
      "tags": [
        "stat.ME"
      ],
      "summary": "Derives neural network-based estimator for spectral density of functional time series, motivated by computational challenges when functions are defined on large grids (10^5 points) from climate models or medical scans.",
      "importance_score": 40,
      "reasoning": "Addresses computational scaling challenge for functional data analysis. Specialized statistical methodology. Limited AI research impact but solid contribution to functional data analysis.",
      "themes": [
        "Statistical Learning",
        "Time Series Analysis",
        "Neural Networks"
      ],
      "continuation": null
    },
    {
      "id": "b1e7ce170f95",
      "title": "Probabilistic Reduced-Dimensional Vector Autoregressive Modeling with Oblique Projections",
      "content": "In this paper, we propose a probabilistic reduced-dimensional vector autoregressive (PredVAR) model to extract low-dimensional dynamics from high-dimensional noisy data. The model utilizes an oblique projection to partition the measurement space into a subspace that accommodates the reduced-dimensional dynamics and a complementary static subspace. An optimal oblique decomposition is derived for the best predictability regarding prediction error covariance. Building on this, we develop an iterative PredVAR algorithm using maximum likelihood and the expectation-maximization (EM) framework. This algorithm alternately updates the estimates of the latent dynamics and optimal oblique projection, yielding dynamic latent variables with rank-ordered predictability and an explicit latent VAR model that is consistent with the outer projection model. The superior performance and efficiency of the proposed approach are demonstrated using data sets from a synthesized Lorenz system and an industrial process from Eastman Chemical.",
      "url": "http://arxiv.org/abs/2401.07206",
      "author": "Yanfang Mo and S. Joe Qin",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning (Statistics))",
      "source_type": "arxiv",
      "tags": [
        "stat.ML"
      ],
      "summary": "Proposes PredVAR, a probabilistic model that extracts low-dimensional dynamics from high-dimensional noisy time series using oblique projections. Uses EM algorithm to alternately update latent dynamics and optimal projections for rank-ordered predictability.",
      "importance_score": 38,
      "reasoning": "Solid statistical methodology paper for time series dimensionality reduction. Technical contribution but limited broader impact beyond specialized applications.",
      "themes": [
        "Time Series Analysis",
        "Dimensionality Reduction",
        "Statistical Machine Learning"
      ],
      "continuation": null
    },
    {
      "id": "e456b02933a7",
      "title": "Yahtzee: Reinforcement Learning Techniques for Stochastic Combinatorial Games",
      "content": "Yahtzee is a classic dice game with a stochastic, combinatorial structure and delayed rewards, making it an interesting mid-scale RL benchmark. While an optimal policy for solitaire Yahtzee can be computed using dynamic programming methods, multiplayer is intractable, motivating approximation methods. We formulate Yahtzee as a Markov Decision Process (MDP), and train self-play agents using various policy gradient methods: REINFORCE, Advantage Actor-Critic (A2C), and Proximal Policy Optimization (PPO), all using a multi-headed network with a shared trunk. We ablate feature and action encodings, architecture, return estimators, and entropy regularization to understand their impact on learning. Under a fixed training budget, REINFORCE and PPO prove sensitive to hyperparameters and fail to reach near-optimal performance, whereas A2C trains robustly across a range of settings. Our agent attains a median score of 241.78 points over 100,000 evaluation games, within 5.0\\% of the optimal DP score of 254.59, achieving the upper section bonus and Yahtzee at rates of 24.9\\% and 34.1\\%, respectively. All models struggle to learn the upper bonus strategy, overindexing on four-of-a-kind's, highlighting persistent long-horizon credit-assignment and exploration challenges.",
      "url": "http://arxiv.org/abs/2601.00007",
      "author": "Nicholas A. Pape",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Studies reinforcement learning for Yahtzee as a mid-scale benchmark with stochastic, combinatorial structure. Compares REINFORCE, A2C, and PPO with ablations on architectures, return estimators, and entropy regularization.",
      "importance_score": 38,
      "reasoning": "Useful benchmark study for policy gradient methods in stochastic games. Limited novelty but provides practical insights for RL practitioners.",
      "themes": [
        "Reinforcement Learning",
        "Game Playing",
        "Policy Gradient Methods"
      ],
      "continuation": null
    },
    {
      "id": "4b0f04fc8a9c",
      "title": "The Weather Paradox: Why Precipitation Fails to Predict Traffic Accident Severity in Large-Scale US Data",
      "content": "This study investigates the predictive capacity of environmental, temporal, and spatial factors on traffic accident severity in the United States. Using a dataset of 500,000 U.S. traffic accidents spanning 2016-2023, we trained an XGBoost classifier optimized through randomized search cross-validation and adjusted for class imbalance via class weighting. The final model achieves an overall accuracy of 78%, with strong performance on the majority class (Severity 2), attaining 87% precision and recall. Feature importance analysis reveals that time of day, geographic location, and weather-related variables, including visibility, temperature, and wind speed, rank among the strongest predictors of accident severity. However, contrary to initial hypotheses, precipitation and visibility demonstrate limited predictive power, potentially reflecting behavioral adaptation by drivers under overtly hazardous conditions. The dataset's predominance of mid-level severity accidents constrains the model's capacity to learn meaningful patterns for extreme cases, highlighting the need for alternative sampling strategies, enhanced feature engineering, and integration of external datasets. These findings contribute to evidence-based traffic management and suggest future directions for severity prediction research.",
      "url": "http://arxiv.org/abs/2601.00152",
      "author": "Yann Bellec, Rohan Kaman, Siwen Cui, Aarav Agrawal, Calvin Chen",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Analyzes 500K US traffic accidents finding that time of day and location predict severity better than weather variables. Precipitation and visibility show counterintuitive weak predictive power despite initial hypotheses.",
      "importance_score": 38,
      "reasoning": "Interesting negative result challenging assumptions about weather-accident relationships. Limited ML novelty but useful empirical finding.",
      "themes": [
        "Traffic Analysis",
        "Machine Learning Applications",
        "Feature Importance"
      ],
      "continuation": null
    },
    {
      "id": "9e55c1bce8c0",
      "title": "DichroGAN: Towards Restoration of in-air Colours of Seafloor from Satellite Imagery",
      "content": "Recovering the in-air colours of seafloor from satellite imagery is a challenging task due to the exponential attenuation of light with depth in the water column. In this study, we present DichroGAN, a conditional generative adversarial network (cGAN) designed for this purpose. DichroGAN employs a two-steps simultaneous training: first, two generators utilise a hyperspectral image cube to estimate diffuse and specular reflections, thereby obtaining atmospheric scene radiance. Next, a third generator receives as input the generated scene radiance containing the features of each spectral band, while a fourth generator estimates the underwater light transmission. These generators work together to remove the effects of light absorption and scattering, restoring the in-air colours of seafloor based on the underwater image formation equation. DichroGAN is trained on a compact dataset derived from PRISMA satellite imagery, comprising RGB images paired with their corresponding spectral bands and masks. Extensive experiments on both satellite and underwater datasets demonstrate that DichroGAN achieves competitive performance compared to state-of-the-art underwater restoration techniques.",
      "url": "http://arxiv.org/abs/2601.00194",
      "author": "Salma Gonzalez-Sabbagh and Antonio Robles-Kelly and Shang Gao",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Presents DichroGAN, a conditional GAN for recovering in-air colors of seafloor from satellite imagery. Uses four generators to estimate reflections, scene radiance, and underwater light transmission.",
      "importance_score": 38,
      "reasoning": "Specialized application of GANs to underwater imaging. Domain-specific contribution with limited broader impact.",
      "themes": [
        "Computer Vision",
        "GANs",
        "Remote Sensing",
        "Underwater Imaging"
      ],
      "continuation": null
    },
    {
      "id": "c2e6d7a007c5",
      "title": "Next Generation Intelligent Low-Altitude Economy Deployments: The O-RAN Perspective",
      "content": "Despite the growing interest in low-altitude economy (LAE) applications, including UAV-based logistics and emergency response, fundamental challenges remain in orchestrating such missions over complex, signal-constrained environments. These include the absence of real-time, resilient, and context-aware orchestration of aerial nodes with limited integration of artificial intelligence (AI) specialized for LAE missions. This paper introduces an open radio access network (O-RAN)-enabled LAE framework that leverages seamless coordination between the disaggregated RAN architecture, open interfaces, and RAN intelligent controllers (RICs) to facilitate closed-loop, AI-optimized, and mission-critical LAE operations. We evaluate the feasibility and performance of the proposed architecture via a semantic-aware rApp that acts as a terrain interpreter, offering semantic guidance to a reinforcement learning-enabled xApp, which performs real-time trajectory planning for LAE swarm nodes. We survey the capabilities of UAV testbeds that can be leveraged for LAE research, and present critical research challenges and standardization needs.",
      "url": "http://arxiv.org/abs/2601.00257",
      "author": "Aly Sabri Abdalla and Vuk Marojevic",
      "published": "2026-01-05",
      "source": "arXiv (eess.SY)",
      "source_type": "arxiv",
      "tags": [
        "eess.SY"
      ],
      "summary": "Proposes O-RAN-enabled framework for low-altitude economy (drone) operations, leveraging RAN intelligent controllers for AI-optimized mission-critical orchestration.",
      "importance_score": 38,
      "reasoning": "Niche application of existing O-RAN concepts to drone networks. Limited broader impact.",
      "themes": [
        "Drone Networks",
        "Telecommunications",
        "Systems"
      ],
      "continuation": null
    },
    {
      "id": "f100760a6a05",
      "title": "Smart Fault Detection in Nanosatellite Electrical Power System",
      "content": "This paper presents a new detection method of faults at Nanosatellites' electrical power without an Attitude Determination Control Subsystem (ADCS) at the LEO orbit. Each part of this system is at risk of fault due to pressure tolerance, launcher pressure, and environmental circumstances. Common faults are line to line fault and open circuit for the photovoltaic subsystem, short circuit and open circuit IGBT at DC to DC converter, and regulator fault of the ground battery. The system is simulated without fault based on a neural network using solar radiation and solar panel's surface temperature as input data and current and load as outputs. Finally, using the neural network classifier, different faults are diagnosed by pattern and type of fault. For fault classification, other machine learning methods are also used, such as PCA classification, decision tree, and KNN.",
      "url": "http://arxiv.org/abs/2601.00335",
      "author": "Alireza Rezaee, Niloofar Nobahari, Amin Asgarifar, Farshid Hajati",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Presents neural network approach for fault detection in nanosatellite electrical power systems using pattern recognition for different fault types without ADCS.",
      "importance_score": 38,
      "reasoning": "Narrow application domain with standard ML techniques.",
      "themes": [
        "Fault Detection",
        "Space Systems",
        "Anomaly Detection"
      ],
      "continuation": null
    },
    {
      "id": "3f11955b9a82",
      "title": "Comparative Efficiency Analysis of Lightweight Transformer Models: A Multi-Domain Empirical Benchmark for Enterprise NLP Deployment",
      "content": "In the rapidly evolving landscape of enterprise natural language processing (NLP), the demand for efficient, lightweight models capable of handling multi-domain text automation tasks has intensified. This study conducts a comparative analysis of three prominent lightweight Transformer models - DistilBERT, MiniLM, and ALBERT - across three distinct domains: customer sentiment classification, news topic classification, and toxicity and hate speech detection. Utilizing datasets from IMDB, AG News, and the Measuring Hate Speech corpus, we evaluated performance using accuracy-based metrics including accuracy, precision, recall, and F1-score, as well as efficiency metrics such as model size, inference time, throughput, and memory usage. Key findings reveal that no single model dominates all performance dimensions. ALBERT achieves the highest task-specific accuracy in multiple domains, MiniLM excels in inference speed and throughput, and DistilBERT demonstrates the most consistent accuracy across tasks while maintaining competitive efficiency. All results reflect controlled fine-tuning under fixed enterprise-oriented constraints rather than exhaustive hyperparameter optimization. These results highlight trade-offs between accuracy and efficiency, recommending MiniLM for latency-sensitive enterprise applications, DistilBERT for balanced performance, and ALBERT for resource-constrained environments.",
      "url": "http://arxiv.org/abs/2601.00444",
      "author": "Muhammad Shahmeer Khan",
      "published": "2026-01-05",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Comparative analysis of DistilBERT, MiniLM, and ALBERT across sentiment, news, and toxicity classification tasks, evaluating both accuracy and efficiency metrics. Provides practical guidance for enterprise NLP deployment but findings are largely confirmatory of existing knowledge.",
      "importance_score": 38,
      "reasoning": "Incremental empirical work without novel methodology. Useful for practitioners but limited research contribution. Unknown author affiliation.",
      "themes": [
        "Language Models",
        "Efficient AI",
        "Applied NLP"
      ],
      "continuation": null
    },
    {
      "id": "7b22eede78db",
      "title": "Noise-Aware Named Entity Recognition for Historical VET Documents",
      "content": "This paper addresses Named Entity Recognition (NER) in the domain of Vocational Education and Training (VET), focusing on historical, digitized documents that suffer from OCR-induced noise. We propose a robust NER approach leveraging Noise-Aware Training (NAT) with synthetically injected OCR errors, transfer learning, and multi-stage fine-tuning. Three complementary strategies, training on noisy, clean, and artificial data, are systematically compared. Our method is one of the first to recognize multiple entity types in VET documents. It is applied to German documents but transferable to arbitrary languages. Experimental results demonstrate that domain-specific and noise-aware fine-tuning substantially increases robustness and accuracy under noisy conditions. We provide publicly available code for reproducible noise-aware NER in domain-specific contexts.",
      "url": "http://arxiv.org/abs/2601.00488",
      "author": "Alexander M. Esser and Jens D\\\"orpinghaus",
      "published": "2026-01-05",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes noise-aware NER approach using synthetic OCR error injection, transfer learning, and multi-stage fine-tuning for historical vocational education documents with OCR-induced noise.",
      "importance_score": 38,
      "reasoning": "Useful technique for noisy document processing. Domain-specific application with limited broader impact. Methodological contribution is incremental.",
      "themes": [
        "NLP",
        "Named Entity Recognition",
        "Document Processing"
      ],
      "continuation": null
    },
    {
      "id": "f1566d367bb5",
      "title": "Efficient Deep Demosaicing with Spatially Downsampled Isotropic Networks",
      "content": "In digital imaging, image demosaicing is a crucial first step which recovers the RGB information from a color filter array (CFA). Oftentimes, deep learning is utilized to perform image demosaicing. Given that most modern digital imaging applications occur on mobile platforms, applying deep learning to demosaicing requires lightweight and efficient networks. Isotropic networks, also known as residual-in-residual networks, have been often employed for image demosaicing and joint-demosaicing-and-denoising (JDD). Most demosaicing isotropic networks avoid spatial downsampling entirely, and thus are often prohibitively expensive computationally for mobile applications. Contrary to previous isotropic network designs, this paper claims that spatial downsampling to a signficant degree can improve the efficiency and performance of isotropic networks. To validate this claim, we design simple fully convolutional networks with and without downsampling using a mathematical architecture design technique adapted from DeepMAD, and find that downsampling improves empirical performance. Additionally, empirical testing of the downsampled variant, JD3Net, of our fully convolutional networks reveals strong empirical performance on a variety of image demosaicing and JDD tasks.",
      "url": "http://arxiv.org/abs/2601.00703",
      "author": "Cory Fan, Wenchao Zhang",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Challenges conventional wisdom that isotropic networks for demosaicing should avoid spatial downsampling, showing that significant downsampling can improve both efficiency and quality for mobile deployment.",
      "importance_score": 38,
      "reasoning": "Practical contribution for mobile imaging but incremental. The insight about downsampling is useful but limited novelty. Very application-specific.",
      "themes": [
        "Computer Vision",
        "Image Processing",
        "Efficient Networks",
        "Mobile AI"
      ],
      "continuation": null
    },
    {
      "id": "140070e3698a",
      "title": "Adapting Natural Language Processing Models Across Jurisdictions: A pilot Study in Canadian Cancer Registries",
      "content": "Population-based cancer registries depend on pathology reports as their primary diagnostic source, yet manual abstraction is resource-intensive and contributes to delays in cancer data. While transformer-based NLP systems have improved registry workflows, their ability to generalize across jurisdictions with differing reporting conventions remains poorly understood. We present the first cross-provincial evaluation of adapting BCCRTron, a domain-adapted transformer model developed at the British Columbia Cancer Registry, alongside GatorTron, a biomedical transformer model, for cancer surveillance in Canada. Our training dataset consisted of approximately 104,000 and 22,000 de-identified pathology reports from the Newfoundland & Labrador Cancer Registry (NLCR) for Tier 1 (cancer vs. non-cancer) and Tier 2 (reportable vs. non-reportable) tasks, respectively. Both models were fine-tuned using complementary synoptic and diagnosis focused report section input pipelines. Across NLCR test sets, the adapted models maintained high performance, demonstrating transformers pretrained in one jurisdiction can be localized to another with modest fine-tuning. To improve sensitivity, we combined the two models using a conservative OR-ensemble achieving a Tier 1 recall of 0.99 and reduced missed cancers to 24, compared with 48 and 54 for the standalone models. For Tier 2, the ensemble achieved 0.99 recall and reduced missed reportable cancers to 33, compared with 54 and 46 for the individual models. These findings demonstrate that an ensemble combining complementary text representations substantially reduce missed cancers and improve error coverage in cancer-registry NLP. We implement a privacy-preserving workflow in which only model weights are shared between provinces, supporting interoperable NLP infrastructure and a future pan-Canadian foundation model for cancer pathology and registry workflows.",
      "url": "http://arxiv.org/abs/2601.00787",
      "author": "Jonathan Simkin, Lovedeep Gondara, Zeeshan Rizvi, Gregory Doyle, Jeff Dowden, Dan Bond, Desmond Martin, and Raymond Ng",
      "published": "2026-01-05",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Presents first cross-provincial evaluation of adapting transformer models (BCCRTron, GatorTron) for cancer surveillance across Canadian cancer registries, addressing generalization across jurisdictions with different reporting conventions.",
      "importance_score": 38,
      "reasoning": "Important practical study for medical NLP deployment but limited methodological novelty. Valuable for understanding cross-jurisdiction transfer but narrow domain.",
      "themes": [
        "Medical NLP",
        "Domain Adaptation",
        "Cancer Registry"
      ],
      "continuation": null
    },
    {
      "id": "dc6b319c3e0a",
      "title": "Sparse Tucker Decomposition and Graph Regularization for High-Dimensional Time Series Forecasting",
      "content": "Existing methods of vector autoregressive model for multivariate time series analysis make use of low-rank matrix approximation or Tucker decomposition to reduce the dimension of the over-parameterization issue. In this paper, we propose a sparse Tucker decomposition method with graph regularization for high-dimensional vector autoregressive time series. By stacking the time-series transition matrices into a third-order tensor, the sparse Tucker decomposition is employed to characterize important interactions within the transition third-order tensor and reduce the number of parameters. Moreover, the graph regularization is employed to measure the local consistency of the response, predictor and temporal factor matrices in the vector autoregressive model.The two proposed regularization techniques can be shown to more accurate parameters estimation. A non-asymptotic error bound of the estimator of the proposed method is established, which is lower than those of the existing matrix or tensor based methods. A proximal alternating linearized minimization algorithm is designed to solve the resulting model and its global convergence is established under very mild conditions. Extensive numerical experiments on synthetic data and real-world datasets are carried out to verify the superior performance of the proposed method over existing state-of-the-art methods.",
      "url": "http://arxiv.org/abs/2601.00377",
      "author": "Sijia Xia, Michael K. Ng, Xiongjun Zhang",
      "published": "2026-01-05",
      "source": "arXiv (math.ST)",
      "source_type": "arxiv",
      "tags": [
        "math.ST"
      ],
      "summary": "Proposes sparse Tucker decomposition with graph regularization for high-dimensional vector autoregressive time series, using factor matrices to reduce overparameterization while preserving local consistency.",
      "importance_score": 38,
      "reasoning": "Mathematical statistics contribution for time series. Solid technical work but very specialized. Limited broader ML impact.",
      "themes": [
        "Time Series Analysis",
        "Tensor Decomposition",
        "Statistical Learning"
      ],
      "continuation": null
    },
    {
      "id": "cb417a6a9e94",
      "title": "A Chain-of-Thought Approach to Semantic Query Categorization in e-Commerce Taxonomies",
      "content": "Search in e-Commerce is powered at the core by a structured representation of the inventory, often formulated as a category taxonomy. An important capability in e-Commerce with hierarchical taxonomies is to select a set of relevant leaf categories that are semantically aligned with a given user query. In this scope, we address a fundamental problem of search query categorization in real-world e-Commerce taxonomies. A correct categorization of a query not only provides a way to zoom into the correct inventory space, but opens the door to multiple intent understanding capabilities for a query. A practical and accurate solution to this problem has many applications in e-commerce, including constraining retrieved items and improving the relevance of the search results. For this task, we explore a novel Chain-of-Thought (CoT) paradigm that combines simple tree-search with LLM semantic scoring. Assessing its classification performance on human-judged query-category pairs, relevance tests, and LLM-based reference methods, we find that the CoT approach performs better than a benchmark that uses embedding-based query category predictions. We show how the CoT approach can detect problems within a hierarchical taxonomy. Finally, we also propose LLM-based approaches for query-categorization of the same spirit, but which scale better at the range of millions of queries.",
      "url": "http://arxiv.org/abs/2601.00510",
      "author": "Jetlir Duraj, Ishita Khan, Kilian Merkelbach, Mehran Elyasi",
      "published": "2026-01-05",
      "source": "arXiv (cs.IR)",
      "source_type": "arxiv",
      "tags": [
        "cs.IR"
      ],
      "summary": "Applies chain-of-thought prompting for e-commerce search query categorization in hierarchical taxonomies, improving alignment between queries and leaf categories.",
      "importance_score": 37,
      "reasoning": "Applied work with limited novelty. Chain-of-thought application is straightforward. Primarily of interest to e-commerce practitioners.",
      "themes": [
        "E-Commerce",
        "Information Retrieval",
        "Language Models"
      ],
      "continuation": null
    },
    {
      "id": "eea8e653b889",
      "title": "From Clay to Code: Typological and Material Reasoning in AI Interpretations of Iranian Pigeon Towers",
      "content": "This study investigates how generative AI systems interpret the architectural intelligence embedded in vernacular form. Using the Iranian pigeon tower as a case study, the research tests three diffusion models, Midjourney v6, DALL-E 3, and DreamStudio based on Stable Diffusion XL (SDXL), across three prompt stages: referential, adaptive, and speculative. A five-criteria evaluation framework assesses how each system reconstructs typology, materiality, environment, realism, and cultural specificity. Results show that AI reliably reproduces geometric patterns but misreads material and climatic reasoning. Reference imagery improves realism yet limits creativity, while freedom from reference generates inventive but culturally ambiguous outcomes. The findings define a boundary between visual resemblance and architectural reasoning, positioning computational vernacular reasoning as a framework for analyzing how AI perceives, distorts, and reimagines traditional design intelligence.",
      "url": "http://arxiv.org/abs/2601.00029",
      "author": "Abolhassan Pishahang, Maryam Badiei",
      "published": "2026-01-05",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Evaluates how generative AI (Midjourney, DALL-E 3, Stable Diffusion) interprets vernacular architecture using Iranian pigeon towers as case study. Tests across referential, adaptive, and speculative prompts using five-criteria evaluation.",
      "importance_score": 36,
      "reasoning": "Interesting cultural AI evaluation but narrow scope. Provides insights on AI understanding of material and environmental reasoning.",
      "themes": [
        "Generative AI",
        "Architecture",
        "Cultural AI",
        "Text-to-Image"
      ],
      "continuation": null
    },
    {
      "id": "34d90e05b20e",
      "title": "MorphoCopter: Design, Modeling, and Control of a New Transformable Quad-Bi Copter",
      "content": "This paper presents a novel morphing quadrotor, named MorphoCopter, covering its design, modeling, control, and experimental tests. It features a unique single rotary joint that enables rapid transformation into an ultra-narrow profile. Although quadrotors have seen widespread adoption in applications such as cinematography, agriculture, and disaster management with increasingly sophisticated control systems, their hardware configurations have remained largely unchanged, limiting their capabilities in certain environments. Our design addresses this by enabling the hardware configuration to change on the fly when required. In standard flight mode, the MorphoCopter adopts an X configuration, functioning as a traditional quadcopter, but can quickly fold into a stacked bicopters arrangement or any configuration in between. Existing morphing designs often sacrifice controllability in compact configurations or rely on complex multi-joint systems. Moreover, our design achieves a greater width reduction than any existing solution. We develop a new inertia and control-action aware adaptive control system that maintains robust performance across all rotary-joint configurations. The prototype can reduce its width from 447 mm to 138 mm (nearly 70\\% reduction) in just a few seconds. We validated the MorphoCopter through rigorous simulations and a comprehensive series of flight experiments, including robustness tests, trajectory tracking, and narrow-gap passing tests.",
      "url": "http://arxiv.org/abs/2506.07204",
      "author": "Harsh Modi, Hao Su, Xiao Liang, Minghui Zheng",
      "published": "2026-01-05",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Introduces MorphoCopter, a transformable quadrotor that can rapidly switch between X-configuration and ultra-narrow bicopter arrangement via a single rotary joint. Covers design, modeling, control, and experimental validation.",
      "importance_score": 35,
      "reasoning": "Innovative hardware design for adaptive drone configurations. Primarily mechanical engineering contribution with limited ML/AI focus.",
      "themes": [
        "Robotics",
        "Drone Design",
        "Control Systems"
      ],
      "continuation": null
    },
    {
      "id": "d6f5489b5b37",
      "title": "Toward a Physical Theory of Intelligence",
      "content": "We present a physical theory of intelligence grounded in irreversible information processing in systems constrained by conservation laws. An intelligent system is modelled as a coupled agent-environment process whose evolution transforms information into goal-directed work. To connect information to physical state, we introduce the Conservation-Congruent Encoding (CCE) framework, in which encodings correspond to metastable basins of attraction whose separability is enforced by conservation laws. Within this framework, intelligence is defined as the amount of goal-directed work produced per nat of irreversibly processed information. From this definition we derive a hierarchy of physical constraints governing information intake, irreversible computation, and work extraction in open systems. The framework reveals how long-horizon efficiency requires the preservation of internal informational structure, giving rise to self-modelling, and it establishes that physically embodied intelligent systems possess intrinsic epistemic limits analogous to incompleteness phenomena. Applying the theory to biological systems, we analyse how oscillatory and near-critical dynamics optimise the trade-off between information preservation, dissipation, and useful work, placing the brain near an efficient operating regime predicted by the framework. At the architectural level, we develop a theory of continuous dynamical circuits in which classical Boolean logic emerges as a special case of attractor selection, while more general invariant geometries support computational modes beyond fixed-point logic. Finally, we propose a physically grounded perspective on artificial intelligence safety based on irreversible information flow and structural homeostasis. Together, these results provide a unified, substrate-neutral account of intelligence as a physical phenomenon.",
      "url": "http://arxiv.org/abs/2601.00021",
      "author": "Peter David Fagan",
      "published": "2026-01-05",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Proposes a physical theory of intelligence based on irreversible information processing in systems constrained by conservation laws. Defines intelligence as goal-directed work produced per nat of irreversibly processed information.",
      "importance_score": 35,
      "reasoning": "Ambitious theoretical framework attempting to ground intelligence in physics. Speculative with limited empirical validation; primarily philosophical contribution.",
      "themes": [
        "Artificial Intelligence Theory",
        "Information Theory",
        "Physics of Intelligence"
      ],
      "continuation": null
    },
    {
      "id": "62961f89f4f6",
      "title": "Language as Mathematical Structure: Examining Semantic Field Theory Against Language Games",
      "content": "Large language models (LLMs) offer a new empirical setting in which long-standing theories of linguistic meaning can be examined. This paper contrasts two broad approaches: social constructivist accounts associated with language games, and a mathematically oriented framework we call Semantic Field Theory. Building on earlier work by the author, we formalize the notions of lexical fields (Lexfelder) and linguistic fields (Lingofelder) as interacting structures in a continuous semantic space. We then analyze how core properties of transformer architectures-such as distributed representations, attention mechanisms, and geometric regularities in embedding spaces-relate to these concepts. We argue that the success of LLMs in capturing semantic regularities supports the view that language exhibits an underlying mathematical structure, while their persistent limitations in pragmatic reasoning and context sensitivity are consistent with the importance of social grounding emphasized in philosophical accounts of language use. On this basis, we suggest that mathematical structure and language games can be understood as complementary rather than competing perspectives. The resulting framework clarifies the scope and limits of purely statistical models of language and motivates new directions for theoretically informed AI architectures.",
      "url": "http://arxiv.org/abs/2601.00448",
      "author": "Dimitris Vartziotis",
      "published": "2026-01-05",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Theoretical examination of linguistic meaning theories using LLMs as an empirical testbed, contrasting social constructivist approaches with a mathematical Semantic Field Theory framework. Analyzes how transformer architectures relate to semantic concepts.",
      "importance_score": 35,
      "reasoning": "Interesting philosophical/theoretical perspective but lacks empirical validation. Single author work with limited methodological rigor for the claims made.",
      "themes": [
        "Language Models",
        "Linguistics",
        "Theory"
      ],
      "continuation": null
    },
    {
      "id": "f3380b660d7d",
      "title": "Detecting Spike Wave Discharges (SWD) using 1-dimensional Residual UNet",
      "content": "The manual labeling of events in electroencephalography (EEG) records is time-consuming. This is especially true when EEG recordings are taken continuously over weeks to months. Therefore, a method to automatically label pertinent EEG events reduces the manual workload. Spike wave discharges (SWD), which are the electrographic hallmark of absence seizures, are EEG events that are often labeled manually. While some previous studies have utilized machine learning to automatically segment and classify EEG signals like SWDs, they can be improved. Here we compare the performance of 14 machine learning classifiers on our own manually annotated dataset of 961 hours of EEG recordings from C3H/HeJ mice, including 22,637 labeled SWDs. We find that a 1D UNet performs best for labeling SWDs in this dataset. We also improve the 1D UNet by augmenting our training data and determine that scaling showed the greatest benefit of all augmentation procedures applied. We then compare the 1D UNet with data augmentation, AugUNet1D, against a recently published time- and frequency-based algorithmic approach called \"Twin Peaks\". AugUNet1D showed superior performance and detected events with more similar features to the SWDs labeled manually. AugUNet1D, pretrained on our manually annotated data or untrained, is made public for others users.",
      "url": "http://arxiv.org/abs/2601.00459",
      "author": "Saurav Sengupta, Scott Kilianski, Suchetha Sharma, Sakina Lashkeri, Ashley McHugh, Mark Beenhakker, and Donald E. Brown",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Compares 14 ML classifiers for detecting spike wave discharges in EEG, finding 1D UNet performs best on a large dataset of 961 hours of recordings with 22,637 labeled events.",
      "importance_score": 35,
      "reasoning": "Domain-specific applied work with solid dataset contribution. Limited novelty in methods. Primarily useful for neuroscience/medical applications.",
      "themes": [
        "Medical AI",
        "Time Series",
        "EEG Analysis"
      ],
      "continuation": null
    },
    {
      "id": "56ca8da76394",
      "title": "Parametrized Sharing for Multi-Agent Hybrid DRL for Multiple Multi-Functional RISs-Aided Downlink NOMA Networks",
      "content": "Multi-functional reconfigurable intelligent surface (MF-RIS) is conceived to address the communication efficiency thanks to its extended signal coverage from its active RIS capability and self-sustainability from energy harvesting (EH). We investigate the architecture of multi-MF-RISs to assist non-orthogonal multiple access (NOMA) downlink networks. We formulate an energy efficiency (EE) maximization problem by optimizing power allocation, transmit beamforming and MF-RIS configurations of amplitudes, phase-shifts and EH ratios, as well as the position of MF-RISs, while satisfying constraints of available power, user rate requirements, and self-sustainability property. We design a parametrized sharing scheme for multi-agent hybrid deep reinforcement learning (PMHRL), where the multi-agent proximal policy optimization (PPO) and deep-Q network (DQN) handle continuous and discrete variables, respectively. The simulation results have demonstrated that proposed PMHRL has the highest EE compared to other benchmarks, including cases without parametrized sharing, pure PPO and DQN. Moreover, the proposed multi-MF-RISs-aided downlink NOMA achieves the highest EE compared to scenarios of no-EH/amplification, traditional RISs, and deployment without RISs/MF-RISs under different multiple access.",
      "url": "http://arxiv.org/abs/2601.00538",
      "author": "Chi-Te Kuo, Li-Hsiang Shen, Jyun-Jhe Huang",
      "published": "2026-01-05",
      "source": "arXiv (eess.SP)",
      "source_type": "arxiv",
      "tags": [
        "eess.SP"
      ],
      "summary": "Proposes parametrized sharing scheme for multi-agent hybrid deep reinforcement learning to optimize multi-functional RIS-assisted NOMA networks for energy efficiency.",
      "importance_score": 35,
      "reasoning": "Domain-specific wireless communications application. Limited broader ML/AI impact. Technical but niche contribution.",
      "themes": [
        "Reinforcement Learning",
        "Wireless Communications",
        "Multi-Agent Systems"
      ],
      "continuation": null
    },
    {
      "id": "005cafa497a1",
      "title": "A Cascaded Information Interaction Network for Precise Image Segmentation",
      "content": "Visual perception plays a pivotal role in enabling autonomous behavior, offering a cost-effective and efficient alternative to complex multi-sensor systems. However, robust segmentation remains a challenge in complex scenarios. To address this, this paper proposes a cascaded convolutional neural network integrated with a novel Global Information Guidance Module. This module is designed to effectively fuse low-level texture details with high-level semantic features across multiple layers, thereby overcoming the inherent limitations of single-scale feature extraction. This architectural innovation significantly enhances segmentation accuracy, particularly in visually cluttered or blurred environments where traditional methods often fail. Experimental evaluations on benchmark image segmentation datasets demonstrate that the proposed framework achieves superior precision, outperforming existing state-of-the-art methods. The results highlight the effectiveness of the approach and its promising potential for deployment in practical robotic applications.",
      "url": "http://arxiv.org/abs/2601.00562",
      "author": "Hewen Xiao, Jie Mei, Guangfu Ma, Weiren Wu",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes cascaded CNN with Global Information Guidance Module for image segmentation, fusing low-level texture with high-level semantics across multiple layers.",
      "importance_score": 35,
      "reasoning": "Incremental architecture improvement for segmentation. Standard multi-scale fusion approach. Limited novelty over existing methods.",
      "themes": [
        "Image Segmentation",
        "Computer Vision",
        "CNN Architecture"
      ],
      "continuation": null
    },
    {
      "id": "11988fc42d04",
      "title": "Sparse FEONet: A Low-Cost, Memory-Efficient Operator Network via Finite-Element Local Sparsity for Parametric PDEs",
      "content": "In this paper, we study the finite element operator network (FEONet), an operator-learning method for parametric problems, originally introduced in J. Y. Lee, S. Ko, and Y. Hong, Finite Element Operator Network for Solving Elliptic-Type Parametric PDEs, SIAM J. Sci. Comput., 47(2), C501-C528, 2025. FEONet realizes the parameter-to-solution map on a finite element space and admits a training procedure that does not require training data, while exhibiting high accuracy and robustness across a broad class of problems. However, its computational cost increases and accuracy may deteriorate as the number of elements grows, posing notable challenges for large-scale problems. In this paper, we propose a new sparse network architecture motivated by the structure of the finite elements to address this issue. Throughout extensive numerical experiments, we show that the proposed sparse network achieves substantial improvements in computational cost and efficiency while maintaining comparable accuracy. We also establish theoretical results demonstrating that the sparse architecture can approximate the target operator effectively and provide a stability analysis ensuring reliable training and prediction.",
      "url": "http://arxiv.org/abs/2601.00672",
      "author": "Seungchan Ko, Jiyeon Kim, Dongwook Shin",
      "published": "2026-01-05",
      "source": "arXiv (math.NA)",
      "source_type": "arxiv",
      "tags": [
        "math.NA"
      ],
      "summary": "Proposes a sparse network architecture for finite element operator networks to solve parametric PDEs more efficiently, motivated by the structure of finite elements. Addresses computational cost scaling issues in large-scale problems.",
      "importance_score": 35,
      "reasoning": "Highly specialized contribution to scientific computing. Limited broader AI impact despite solid methodology. Very niche audience in computational mathematics.",
      "themes": [
        "Scientific Computing",
        "Neural Networks for PDEs",
        "Efficient Architectures"
      ],
      "continuation": null
    },
    {
      "id": "f2a238271963",
      "title": "Calling for Backup: How Children Navigate Successive Robot Communication Failures",
      "content": "How do children respond to repeated robot errors? While prior research has examined adult reactions to successive robot errors, children's responses remain largely unexplored. In this study, we explore children's reactions to robot social errors and performance errors. For the latter, this study reproduces the successive robot failure paradigm of Liu et al. with child participants (N=59, ages 8-10) to examine how young users respond to repeated robot conversational errors. Participants interacted with a robot that failed to understand their prompts three times in succession, with their behavioral responses video-recorded and analyzed. We found both similarities and differences compared to adult responses from the original study. Like adults, children adjusted their prompts, modified their verbal tone, and exhibited increasingly emotional non-verbal responses throughout successive errors. However, children demonstrated more disengagement behaviors, including temporarily ignoring the robot or actively seeking an adult. Errors did not affect participants' perception of the robot, suggesting more flexible conversational expectations in children. These findings inform the design of more effective and developmentally appropriate human-robot interaction systems for young users.",
      "url": "http://arxiv.org/abs/2601.00754",
      "author": "Maria Teresa Parreira, Isabel Neto, Filipa Rocha, Wendy Ju",
      "published": "2026-01-05",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Studies how children (ages 8-10) respond to successive robot communication failures, comparing to prior adult studies. Finds both similarities and differences in how children adjust prompts and modify interaction strategies.",
      "importance_score": 35,
      "reasoning": "Valuable HRI research but narrow scope. Replication study with child participants provides useful developmental perspective but limited AI methodology contribution.",
      "themes": [
        "Human-Robot Interaction",
        "Child-Robot Interaction",
        "Communication Failures"
      ],
      "continuation": null
    },
    {
      "id": "f389258f81fc",
      "title": "Strategic Geosteeering Workflow with Uncertainty Quantification and Deep Learning: A Case Study on the Goliat Field",
      "content": "The real-time interpretation of the logging-while-drilling data allows us to estimate the positions and properties of the geological layers in an anisotropic subsurface environment. Robust real-time estimations capturing uncertainty can be very useful for efficient geosteering operations. However, the model errors in the prior conceptual geological models and forward simulation of the measurements can be significant factors in the unreliable estimations of the profiles of the geological layers. The model errors are specifically pronounced when using a deep-neural-network (DNN) approximation which we use to accelerate and parallelize the simulation of the measurements. This paper presents a practical workflow consisting of offline and online phases. The offline phase includes DNN training and building of an uncertain prior near-well geo-model. The online phase uses the flexible iterative ensemble smoother (FlexIES) to perform real-time assimilation of extra-deep electromagnetic data accounting for the model errors in the approximate DNN model. We demonstrate the proposed workflow on a case study for a historic well in the Goliat Field (Barents Sea). The median of our probabilistic estimation is on-par with proprietary inversion despite the approximate DNN model and regardless of the number of layers in the chosen prior. By estimating the model errors, FlexIES automatically quantifies the uncertainty in the layers' boundaries and resistivities, which is not standard for proprietary inversion.",
      "url": "http://arxiv.org/abs/2210.15548",
      "author": "Muzammil Hussain Rammay, Sergey Alyaev, David Selv{\\aa}g Larsen, Reidar Brumer Bratvold, Craig Saint",
      "published": "2026-01-05",
      "source": "arXiv (physics.geo-ph)",
      "source_type": "arxiv",
      "tags": [
        "physics.geo-ph"
      ],
      "summary": "Presents practical workflow for real-time geosteering using DNN-accelerated uncertainty quantification, addressing model errors in prior geological models and forward simulation through offline-online phase design.",
      "importance_score": 35,
      "reasoning": "Domain-specific deep learning application for drilling operations. Practical but very narrow audience. Limited broader ML contribution.",
      "themes": [
        "Geoscience AI",
        "Uncertainty Quantification",
        "Deep Learning Applications"
      ],
      "continuation": null
    },
    {
      "id": "5cd584346e1b",
      "title": "Deep Learning Approach for the Diagnosis of Pediatric Pneumonia Using Chest X-ray Imaging",
      "content": "Pediatric pneumonia remains a leading cause of morbidity and mortality in children worldwide. Timely and accurate diagnosis is critical but often challenged by limited radiological expertise and the physiological and procedural complexity of pediatric imaging. This study investigates the performance of state-of-the-art convolutional neural network (CNN) architectures ResNetRS, RegNet, and EfficientNetV2 using transfer learning for the automated classification of pediatric chest Xray images as either pneumonia or normal.A curated subset of 1,000 chest X-ray images was extracted from a publicly available dataset originally comprising 5,856 pediatric images. All images were preprocessed and labeled for binary classification. Each model was fine-tuned using pretrained ImageNet weights and evaluated based on accuracy and sensitivity. RegNet achieved the highest classification performance with an accuracy of 92.4 and a sensitivity of 90.1, followed by ResNetRS (accuracy: 91.9, sensitivity: 89.3) and EfficientNetV2 (accuracy: 88.5, sensitivity: 88.1).",
      "url": "http://arxiv.org/abs/2601.00041",
      "author": "Fatemeh Hosseinabadi, Mohammad Mojtaba Rohani",
      "published": "2026-01-05",
      "source": "arXiv (eess.IV)",
      "source_type": "arxiv",
      "tags": [
        "eess.IV"
      ],
      "summary": "Evaluates ResNetRS, RegNet, and EfficientNetV2 with transfer learning for pediatric pneumonia classification from chest X-rays. Uses curated 1,000-image subset from larger dataset.",
      "importance_score": 34,
      "reasoning": "Standard medical imaging application with limited novelty. Small dataset size and well-established methodology.",
      "themes": [
        "Medical Imaging",
        "Transfer Learning",
        "Computer Vision"
      ],
      "continuation": null
    },
    {
      "id": "da945a08e4e4",
      "title": "From 2D to 3D terrain-following area coverage path planning",
      "content": "An algorithm for 3D terrain-following area coverage path planning is presented. Multiple adjacent paths are generated that are (i) locally apart from each other by a distance equal to the working width of a machinery, while (ii) simultaneously floating at a projection distance equal to a specific working height above the terrain. The complexities of the algorithm in comparison to its 2D equivalent are highlighted. These include uniformly spaced elevation data generation using an Inverse Distance Weighting-approach and a local search. Area coverage path planning results for real-world 3D data within an agricultural context are presented to validate the algorithm.",
      "url": "http://arxiv.org/abs/2601.00614",
      "author": "Mogens Plessen",
      "published": "2026-01-05",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Presents algorithm for 3D terrain-following coverage path planning generating adjacent paths at specified working width and height above terrain using IDW interpolation.",
      "importance_score": 34,
      "reasoning": "Applied algorithm for agricultural/surveying applications. Limited ML/AI novelty. Domain-specific engineering contribution.",
      "themes": [
        "Path Planning",
        "Robotics",
        "Agriculture"
      ],
      "continuation": null
    },
    {
      "id": "b5ae468bad98",
      "title": "Rule-Based Approaches to Atomic Sentence Extraction",
      "content": "Natural language often combines multiple ideas into complex sentences. Atomic sentence extraction, the task of decomposing complex sentences into simpler sentences that each express a single idea, improves performance in information retrieval, question answering, and automated reasoning systems. Previous work has formalized the \"split-and-rephrase\" task and established evaluation metrics, and machine learning approaches using large language models have improved extraction accuracy. However, these methods lack interpretability and provide limited insight into which linguistic structures cause extraction failures. Although some studies have explored dependency-based extraction of subject-verb-object triples and clauses, no principled analysis has examined which specific clause structures and dependencies lead to extraction difficulties. This study addresses this gap by analyzing how complex sentence structures, including relative clauses, adverbial clauses, coordination patterns, and passive constructions, affect the performance of rule-based atomic sentence extraction. Using the WikiSplit dataset, we implemented dependency-based extraction rules in spaCy, generated 100 gold=standard atomic sentence sets, and evaluated performance using ROUGE and BERTScore. The system achieved ROUGE-1 F1 = 0.6714, ROUGE-2 F1 = 0.478, ROUGE-L F1 = 0.650, and BERTScore F1 = 0.5898, indicating moderate-to-high lexical, structural, and semantic alignment. Challenging structures included relative clauses, appositions, coordinated predicates, adverbial clauses, and passive constructions. Overall, rule-based extraction is reasonably accurate but sensitive to syntactic complexity.",
      "url": "http://arxiv.org/abs/2601.00506",
      "author": "Lineesha Kamana, Akshita Ananda Subramanian, Mehuli Ghosh, and Suman Saha",
      "published": "2026-01-05",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Analyzes rule-based approaches to extracting atomic sentences from complex sentences, examining which linguistic structures cause extraction failures compared to ML approaches.",
      "importance_score": 33,
      "reasoning": "Useful analysis for NLP practitioners but limited novel contribution. Primarily analytical rather than proposing new methods.",
      "themes": [
        "NLP",
        "Sentence Processing",
        "Linguistics"
      ],
      "continuation": null
    },
    {
      "id": "97f77300521c",
      "title": "Memory-Aware Partitioning of Machine Learning Applications for Optimal Energy Use in Batteryless Systems",
      "content": "Sensing systems powered by energy harvesting have traditionally been designed to tolerate long periods without energy. As the Internet of Things (IoT) evolves towards a more transient and opportunistic execution paradigm, reducing energy storage costs will be key for its economic and ecologic viability. However, decreasing energy storage in harvesting systems introduces reliability issues. Transducers only produce intermittent energy at low voltage and current levels, making guaranteed task completion a challenge. Existing ad hoc methods overcome this by buffering enough energy either for single tasks, incurring large data-retention overheads, or for one full application cycle, requiring a large energy buffer. We present Julienning: an automated method for optimizing the total energy cost of batteryless applications. Using a custom specification model, developers can describe transient applications as a set of atomically executed kernels with explicit data dependencies. Our optimization flow can partition data- and energy-intensive applications into multiple execution cycles with bounded energy consumption. By leveraging interkernel data dependencies, these energy-bounded execution cycles minimize the number of system activations and nonvolatile data transfers, and thus the total energy overhead. We validate our methodology with two batteryless cameras running energy-intensive machine learning applications. Results demonstrate that compared to ad hoc solutions, our method can reduce the required energy storage by over 94% while only incurring a 0.12% energy overhead.",
      "url": "http://arxiv.org/abs/2108.04059",
      "author": "Andres Gomez, Andreas Tretter, Pascal Alexander Hager, Praveenth Sanmugarajah, Luca Benini, Lothar Thiele",
      "published": "2026-01-05",
      "source": "arXiv (cs.DC)",
      "source_type": "arxiv",
      "tags": [
        "cs.DC"
      ],
      "summary": "Presents Julienning, an automated method for optimizing energy costs in batteryless IoT systems by partitioning ML applications to handle intermittent energy from energy harvesting. Addresses reliability issues in systems with reduced energy storage through memory-aware task scheduling.",
      "importance_score": 32,
      "reasoning": "Niche systems/embedded paper focused on IoT energy optimization. Limited ML novelty; primarily addresses hardware energy management challenges.",
      "themes": [
        "Internet of Things",
        "Energy-Efficient Computing",
        "Embedded Systems"
      ],
      "continuation": null
    },
    {
      "id": "bc69e6369235",
      "title": "A multi-algorithm approach for operational human resources workload balancing in a last mile urban delivery system",
      "content": "Efficient workload assignment to the workforce is critical in last-mile package delivery systems. In this context, traditional methods of assigning package deliveries to workers based on geographical proximity can be inefficient and surely guide to an unbalanced workload distribution among delivery workers. In this paper, we look at the problem of operational human resources workload balancing in last-mile urban package delivery systems. The idea is to consider the effort workload to optimize the system, i.e., the optimization process is now focused on improving the delivery time, so that the workload balancing is complete among all the staff. This process should correct significant decompensations in workload among delivery workers in a given zone. Specifically, we propose a multi-algorithm approach to tackle this problem. The proposed approach takes as input a set of delivery points and a defined number of workers, and then assigns packages to workers, in such a way that it ensures that each worker completes a similar amount of work per day. The proposed algorithms use a combination of distance and workload considerations to optimize the allocation of packages to workers. In this sense, the distance between the delivery points and the location of each worker is also taken into account. The proposed multi-algorithm methodology includes different versions of k-means, evolutionary approaches, recursive assignments based on k-means initialization with different problem encodings, and a hybrid evolutionary ensemble algorithm. We have illustrated the performance of the proposed approach in a real-world problem in an urban last-mile package delivery workforce operating at Azuqueca de Henares, Spain.",
      "url": "http://arxiv.org/abs/2601.00023",
      "author": "Luis M. Moreno-Saavedra, Silvia Jimenez-Fernandez, Antonio Portilla-Figueras, David Casillas-Perez, Sancho Salcedo-Sanz",
      "published": "2026-01-05",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Proposes multi-algorithm approach for balancing workload among delivery workers in last-mile urban delivery by optimizing delivery time rather than geographic proximity.",
      "importance_score": 32,
      "reasoning": "Operations research paper with limited ML novelty. Practical application but standard optimization techniques.",
      "themes": [
        "Operations Research",
        "Logistics Optimization",
        "Resource Allocation"
      ],
      "continuation": null
    },
    {
      "id": "ac7b725d280f",
      "title": "Word Frequency Counting Based on Serverless MapReduce",
      "content": "With the increasing demand for high-performance and high-efficiency computing, cloud computing, especially serverless computing, has gradually become a research hotspot in recent years, attracting numerous research attention. Meanwhile, MapReduce, which is a popular big data processing model in the industry, has been widely applied in various fields. Inspired by the serverless framework of Function as a Service and the high concurrency and robustness of MapReduce programming model, this paper focus on combining them to reduce the time span and increase the efficiency when executing the word frequency counting task. In this case, the paper use a MapReduce programming model based on a serverless computing platform to figure out the most optimized number of Map functions and Reduce functions for a particular task. For the same amount of workload, extensive experiments show both execution time reduces and the overall efficiency of the program improves at different rates as the number of map functions and reduce functions increases. This paper suppose the discovery of the most optimized number of map and reduce functions can help cooperations and programmers figure out the most optimized solutions.",
      "url": "http://arxiv.org/abs/2601.00380",
      "author": "Hanzhe Li and Bingchen Lin and Mengyuan Xu",
      "published": "2026-01-05",
      "source": "arXiv (cs.DC)",
      "source_type": "arxiv",
      "tags": [
        "cs.DC"
      ],
      "summary": "Optimizes MapReduce word counting on serverless platforms to find optimal number of Map and Reduce functions for efficiency.",
      "importance_score": 32,
      "reasoning": "Basic applied work with limited novelty.",
      "themes": [
        "Cloud Computing",
        "MapReduce",
        "Serverless"
      ],
      "continuation": null
    },
    {
      "id": "ba5b36f8848e",
      "title": "Interpretable Machine Learning for Quantum-Informed Property Predictions in Artificial Sensing Materials",
      "content": "Digital sensing faces challenges in developing sustainable methods to extend the applicability of customized e-noses to complex body odor volatilome (BOV). To address this challenge, we developed MORE-ML, a computational framework that integrates quantum-mechanical (QM) property data of e-nose molecular building blocks with machine learning (ML) methods to predict sensing-relevant properties. Within this framework, we expanded our previous dataset, MORE-Q, to MORE-QX by sampling a larger conformational space of interactions between BOV molecules and mucin-derived receptors. This dataset provides extensive electronic binding features (BFs) computed upon BOV adsorption. Analysis of MORE-QX property space revealed weak correlations between QM properties of building blocks and resulting BFs. Leveraging this observation, we defined electronic descriptors of building blocks as inputs for tree-based ML models to predict BFs. Benchmarking showed CatBoost models outperform alternatives, especially in transferability to unseen compounds. Explainable AI methods further highlighted which QM properties most influence BF predictions. Collectively, MORE-ML combines QM insights with ML to provide mechanistic understanding and rational design principles for molecular receptors in BOV sensing. This approach establishes a foundation for advancing artificial sensing materials capable of analyzing complex odor mixtures, bridging the gap between molecular-level computations and practical e-nose applications.",
      "url": "http://arxiv.org/abs/2601.00503",
      "author": "Li Chen, Leonardo Medrano Sandonas, Shirong Huang, Alexander Croy, Gianaurelio Cuniberti",
      "published": "2026-01-05",
      "source": "arXiv (physics.chem-ph)",
      "source_type": "arxiv",
      "tags": [
        "physics.chem-ph"
      ],
      "summary": "Develops MORE-ML framework integrating quantum-mechanical property data with ML for predicting sensing properties of artificial e-nose materials for body odor detection.",
      "importance_score": 32,
      "reasoning": "Highly domain-specific application in chemical sensing. Limited relevance to broader ML/AI research community.",
      "themes": [
        "Scientific ML",
        "Chemistry",
        "Materials Science"
      ],
      "continuation": null
    },
    {
      "id": "db89f5c8d32f",
      "title": "Quality Detection of Stored Potatoes via Transfer Learning: A CNN and Vision Transformer Approach",
      "content": "Image-based deep learning provides a non-invasive, scalable solution for monitoring potato quality during storage, addressing key challenges such as sprout detection, weight loss estimation, and shelf-life prediction. In this study, images and corresponding weight data were collected over a 200-day period under controlled temperature and humidity conditions. Leveraging powerful pre-trained architectures of ResNet, VGG, DenseNet, and Vision Transformer (ViT), we designed two specialized models: (1) a high-precision binary classifier for sprout detection, and (2) an advanced multi-class predictor to estimate weight loss and forecast remaining shelf-life with remarkable accuracy. DenseNet achieved exceptional performance, with 98.03% accuracy in sprout detection. Shelf-life prediction models performed best with coarse class divisions (2-5 classes), achieving over 89.83% accuracy, while accuracy declined for finer divisions (6-8 classes) due to subtle visual differences and limited data per class. These findings demonstrate the feasibility of integrating image-based models into automated sorting and inventory systems, enabling early identification of sprouted potatoes and dynamic categorization based on storage stage. Practical implications include improved inventory management, differential pricing strategies, and reduced food waste across supply chains. While predicting exact shelf-life intervals remains challenging, focusing on broader class divisions ensures robust performance. Future research should aim to develop generalized models trained on diverse potato varieties and storage conditions to enhance adaptability and scalability. Overall, this approach offers a cost-effective, non-destructive method for quality assessment, supporting efficiency and sustainability in potato storage and distribution.",
      "url": "http://arxiv.org/abs/2601.00645",
      "author": "Shrikant Kapse, Priyankkumar Dhrangdhariya, Priya Kedia, Manasi Patwardhan, Shankar Kausley, Soumyadipta Maiti, Beena Rai, Shirish Karande",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Applies transfer learning with ResNet, VGG, DenseNet, and ViT for potato quality detection including sprout detection (98% accuracy), weight loss estimation, and shelf-life prediction.",
      "importance_score": 32,
      "reasoning": "Straightforward transfer learning application. Limited novelty in methods. Domain-specific agricultural contribution.",
      "themes": [
        "Computer Vision",
        "Agriculture",
        "Transfer Learning"
      ],
      "continuation": null
    },
    {
      "id": "c6e6ad6ed95c",
      "title": "TeleDoCTR: Domain-Specific and Contextual Troubleshooting for Telecommunications",
      "content": "Ticket troubleshooting refers to the process of analyzing and resolving problems that are reported through a ticketing system. In large organizations offering a wide range of services, this task is highly complex due to the diversity of submitted tickets and the need for specialized domain knowledge. In particular, troubleshooting in telecommunications (telecom) is a very time-consuming task as it requires experts to interpret ticket content, consult documentation, and search historical records to identify appropriate resolutions. This human-intensive approach not only delays issue resolution but also hinders overall operational efficiency. To enhance the effectiveness and efficiency of ticket troubleshooting in telecom, we propose TeleDoCTR, a novel telecom-related, domain-specific, and contextual troubleshooting system tailored for end-to-end ticket resolution in telecom. TeleDoCTR integrates both domain-specific ranking and generative models to automate key steps of the troubleshooting workflow which are: routing tickets to the appropriate expert team responsible for resolving the ticket (classification task), retrieving contextually and semantically similar historical tickets (retrieval task), and generating a detailed fault analysis report outlining the issue, root cause, and potential solutions (generation task). We evaluate TeleDoCTR on a real-world dataset from a telecom infrastructure and demonstrate that it achieves superior performance over existing state-of-the-art methods, significantly enhancing the accuracy and efficiency of the troubleshooting process.",
      "url": "http://arxiv.org/abs/2601.00691",
      "author": "Mohamed Trabelsi, Huseyin Uzunalioglu",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces TeleDoCTR, a domain-specific troubleshooting system for telecommunications that analyzes tickets using specialized knowledge. Aims to improve efficiency over human-intensive ticket resolution.",
      "importance_score": 32,
      "reasoning": "Applied ML for specific industrial domain. Limited novelty in methodology. Practical value for telecom industry but minimal research contribution to broader ML field.",
      "themes": [
        "Applied Machine Learning",
        "Natural Language Processing",
        "Domain Adaptation"
      ],
      "continuation": null
    },
    {
      "id": "50d3e07d74ea",
      "title": "A Machine Learning Framework for Off Ball Defensive Role and Performance Evaluation in Football",
      "content": "Evaluating off-ball defensive performance in football is challenging, as traditional metrics do not capture the nuanced coordinated movements that limit opponent action selection and success probabilities. Although widely used possession value models excel at appraising on-ball actions, their application to defense remains limited. Existing counterfactual methods, such as ghosting models, help extend these analyses but often rely on simulating \"average\" behavior that lacks tactical context. To address this, we introduce a covariate-dependent Hidden Markov Model (CDHMM) tailored to corner kicks, a highly structured aspect of football games. Our label-free model infers time-resolved man-marking and zonal assignments directly from player tracking data. We leverage these assignments to propose a novel framework for defensive credit attribution and a role-conditioned ghosting method for counterfactual analysis of off-ball defensive performance. We show how these contributions provide a interpretable evaluation of defensive contributions against context-aware baselines.",
      "url": "http://arxiv.org/abs/2601.00748",
      "author": "Sean Groom, Shuo Wang, Francisco Belo, Axl Rice, Liam Anderson",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces covariate-dependent Hidden Markov Model for analyzing defensive behavior in football corner kicks, inferring man-marking and zonal assignments directly from tracking data without labels.",
      "importance_score": 32,
      "reasoning": "Novel methodology for sports analytics but very narrow application domain. Limited broader ML research impact despite solid statistical modeling.",
      "themes": [
        "Sports Analytics",
        "Hidden Markov Models",
        "Computer Vision"
      ],
      "continuation": null
    },
    {
      "id": "a48b13e195a2",
      "title": "Two Deep Learning Approaches for Automated Segmentation of Left Ventricle in Cine Cardiac MRI",
      "content": "Left ventricle (LV) segmentation is critical for clinical quantification and diagnosis of cardiac images. In this work, we propose two novel deep learning architectures called LNU-Net and IBU-Net for left ventricle segmentation from short-axis cine MRI images. LNU-Net is derived from layer normalization (LN) U-Net architecture, while IBU-Net is derived from the instance-batch normalized (IB) U-Net for medical image segmentation. The architectures of LNU-Net and IBU-Net have a down-sampling path for feature extraction and an up-sampling path for precise localization. We use the original U-Net as the basic segmentation approach and compared it with our proposed architectures. Both LNU-Net and IBU-Net have left ventricle segmentation methods: LNU-Net applies layer normalization in each convolutional block, while IBU-Net incorporates instance and batch normalization together in the first convolutional block and passes its result to the next layer. Our method incorporates affine transformations and elastic deformations for image data processing. Our dataset that contains 805 MRI images regarding the left ventricle from 45 patients is used for evaluation. We experimentally evaluate the results of the proposed approaches outperforming the dice coefficient and the average perpendicular distance than other state-of-the-art approaches.",
      "url": "http://arxiv.org/abs/2601.00794",
      "author": "Wenhui Chu, Nikolaos V. Tsekos",
      "published": "2026-01-05",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes LNU-Net and IBU-Net architectures for left ventricle segmentation in cardiac MRI, using layer normalization and instance-batch normalization respectively in U-Net variants.",
      "importance_score": 32,
      "reasoning": "Incremental contribution to medical image segmentation. Straightforward normalization modifications to U-Net. Limited novelty despite practical medical application.",
      "themes": [
        "Medical Image Segmentation",
        "Deep Learning",
        "Cardiac Imaging"
      ],
      "continuation": null
    },
    {
      "id": "eb8649025d06",
      "title": "Enhancing Decision Space Diversity in Multi-Objective Evolutionary Optimization for the Diet Problem",
      "content": "Multi-objective evolutionary algorithms (MOEAs) are essential for solving complex optimization problems, such as the diet problem, where balancing conflicting objectives, like cost and nutritional content, is crucial. However, most MOEAs focus on optimizing solutions in the objective space, often neglecting the diversity of solutions in the decision space, which is critical for providing decision-makers with a wide range of choices. This paper introduces an approach that directly integrates a Hamming distance-based measure of uniformity into the selection mechanism of a MOEA to enhance decision space diversity. Experiments on a multi-objective formulation of the diet problem demonstrate that our approach significantly improves decision space diversity compared to NSGA-II, while maintaining comparable objective space performance. The proposed method offers a generalizable strategy for integrating decision space awareness into MOEAs.",
      "url": "http://arxiv.org/abs/2508.07077",
      "author": "Gustavo V. Nascimento, Ivan R. Meneghini, Val\\'eria Santos, Eduardo Luz and Gladston Moreira",
      "published": "2026-01-05",
      "source": "arXiv (Neural and Evolutionary Computing)",
      "source_type": "arxiv",
      "tags": [
        "cs.NE"
      ],
      "summary": "Introduces a Hamming distance-based diversity measure integrated into MOEA selection mechanisms to enhance decision space diversity for the diet problem. Shows improved diversity compared to NSGA-II while maintaining objective space performance.",
      "importance_score": 30,
      "reasoning": "Incremental contribution to evolutionary optimization with narrow application focus. Limited novelty and broader impact.",
      "themes": [
        "Evolutionary Computing",
        "Multi-Objective Optimization"
      ],
      "continuation": null
    },
    {
      "id": "d07bbcd25ae5",
      "title": "Quantitative Rule-Based Strategy modeling in Classic Indian Rummy: A Metric Optimization Approach",
      "content": "The 13-card variant of Classic Indian Rummy is a sequential game of incomplete information that requires probabilistic reasoning and combinatorial decision-making. This paper proposes a rule-based framework for strategic play, driven by a new hand-evaluation metric termed MinDist. The metric modifies the MinScore metric by quantifying the edit distance between a hand and the nearest valid configuration, thereby capturing structural proximity to completion. We design a computationally efficient algorithm derived from the MinScore algorithm, leveraging dynamic pruning and pattern caching to exactly calculate this metric during play. Opponent hand-modeling is also incorporated within a two-player zero-sum simulation framework, and the resulting strategies are evaluated using statistical hypothesis testing. Empirical results show significant improvement in win rates for MinDist-based agents over traditional heuristics, providing a formal and interpretable step toward algorithmic Rummy strategy design.",
      "url": "http://arxiv.org/abs/2601.00024",
      "author": "Purushottam Saha, Avirup Chakraborty, Sourish Sarkar, Subhamoy Maitra, Diganta Mukherjee and Tridib Mukherjee",
      "published": "2026-01-05",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Develops MinDist metric for strategic play in 13-card Indian Rummy, quantifying edit distance to valid hand configurations. Includes opponent hand-modeling within two-player zero-sum simulation framework.",
      "importance_score": 30,
      "reasoning": "Niche game AI paper with limited broader applicability. Rule-based approach with modest ML content.",
      "themes": [
        "Game AI",
        "Combinatorial Decision-Making"
      ],
      "continuation": null
    },
    {
      "id": "d2771ca76f06",
      "title": "Probability-Aware Parking Selection",
      "content": "Current parking navigation systems often underestimate total travel time by failing to account for the time spent searching for a parking space, which significantly affects user experience, mode choice, congestion, and emissions. To address this issue, this paper introduces the probability-aware parking selection problem, which aims to direct drivers to the best parking location rather than straight to their destination. An adaptable dynamic programming framework is proposed for decision-making based on probabilistic information about parking availability at the parking lot level. Closed-form analysis determines when it is optimal to target a specific parking lot or explore alternatives, as well as the expected time cost. Sensitivity analysis and three illustrative cases are examined, demonstrating the model's ability to account for the dynamic nature of parking availability. Acknowledging the financial costs of permanent sensing infrastructure, the paper provides analytical and empirical assessments of errors incurred when leveraging stochastic observations to estimate parking availability. Experiments with real-world data from the US city of Seattle indicate this approach's viability, with mean absolute error decreasing from 7% to below 2% as observation frequency grows. In data-based simulations, probability-aware strategies demonstrate time savings up to 66% relative to probability-unaware baselines, yet still take up to 123% longer than direct-to-destination estimates.",
      "url": "http://arxiv.org/abs/2601.00521",
      "author": "Cameron Hickert, Sirui Li, Zhengbing He, Cathy Wu",
      "published": "2026-01-05",
      "source": "arXiv (eess.SY)",
      "source_type": "arxiv",
      "tags": [
        "eess.SY"
      ],
      "summary": "Introduces probability-aware parking selection problem with dynamic programming framework for decision-making based on probabilistic parking availability, providing closed-form analysis for optimal lot selection.",
      "importance_score": 30,
      "reasoning": "Applied optimization work with limited ML/AI novelty. Primarily transportation engineering contribution.",
      "themes": [
        "Optimization",
        "Transportation",
        "Decision Making"
      ],
      "continuation": null
    },
    {
      "id": "b1309d3b5952",
      "title": "The inaugural Redwood Research podcast",
      "content": "After five months of me (Buck) being slow at finishing up the editing on this, we’re finally putting out our inaugural Redwood Research podcast. I think it came out pretty well—we discussed a bunch of interesting and underdiscussed topics and I’m glad to have a public record of a bunch of stuff about our history. Tell your friends! Whether we do another one depends on how useful people find this one. You can watch on Youtube&nbsp;here, or as a Substack podcast, or on Spotify.Notes on editing the podcast with Claude Code(Buck wrote this section)After the recording, we faced a problem. We had four hours of footage from our three cameras. We wanted it to snazzily cut between shots depending on who was talking. But I don’t truly in my heart believe that it’s that important for the video editing to be that good, and I don’t really like the idea of paying a video editor. But I also don’t want to edit the four hours of video myself. And it seemed to me that video editing software was generally not optimized for the kind of editing I wanted to do here (especially automatically cutting between different shots according to which speakers are talking).Surely, I decided, it wouldn’t be that hard to just write some command-line video-editing software from scratch, with the aid of my friend Claude. So that’s what we did. We (which henceforth means “me and Claude”) first used deepgram to make a transcript of the podcast that includes timestamps and a note of who’s speaking. Then we generated IDs for all the different lines in the transcript, leading to a huge file that looks like this:$segment2/34 // Buck: So how good you know, you're you're saying, like, 50% of, like, catastrophically bad outcomes. $segment2/35 // Ryan: Yep. $segment2/36 // Buck: And then what's the distribution of how good the other 50% of worlds are? $segment2/37 // Ryan: Yeah. $segment2/38 // Ryan: So I think there's a bunch of variation on like, from a long term perspective in terms of, like, how good is, lik...",
      "url": "https://www.lesswrong.com/posts/p4iJpumHt6Ay9KnXT/the-inaugural-redwood-research-podcast",
      "author": "Buck",
      "published": "2026-01-04T17:11:54.477000",
      "source": "LessWrong",
      "source_type": "research_blog",
      "tags": [],
      "summary": "Redwood Research releases their inaugural podcast discussing the organization's history, underdiscussed topics, and includes technical notes on editing the video using Claude Code for automatic camera switching.",
      "importance_score": 30,
      "reasoning": "Primarily organizational content with some interesting technical notes on LLM-assisted video editing. Not research per se but provides context on a significant alignment research organization.",
      "themes": [
        "AI Safety Organizations",
        "AI Tools"
      ],
      "continuation": null
    },
    {
      "id": "55ef483283e4",
      "title": "RadAround: A Field-Expedient Direction Finder for Contested IoT Sensing & EM Situational Awareness",
      "content": "This paper presents RadAround, a passive 2-D direction-finding system designed for adversarial IoT sensing in contested environments. Using mechanically steered narrow-beam antennas and field-deployable SCADA software, it generates high-resolution electromagnetic (EM) heatmaps using low-cost COTS or 3D-printed components. The microcontroller-deployable SCADA coordinates antenna positioning and SDR sampling in real time for resilient, on-site operation. Its modular design enables rapid adaptation for applications such as EMC testing in disaster-response deployments, battlefield spectrum monitoring, electronic intrusion detection, and tactical EM situational awareness (EMSA). Experiments show RadAround detecting computing machinery through walls, assessing utilization, and pinpointing EM interference (EMI) leakage sources from Faraday enclosures.",
      "url": "http://arxiv.org/abs/2511.11392",
      "author": "Owen A. Maute, Blake A. Roberts, Berker Pek\\\"oz",
      "published": "2026-01-05",
      "source": "arXiv (eess.SP)",
      "source_type": "arxiv",
      "tags": [
        "eess.SP"
      ],
      "summary": "Presents RadAround, a passive 2D direction-finding system using mechanically steered antennas and field-deployable SCADA software for adversarial IoT sensing. Generates EM heatmaps for applications including EMC testing and tactical situational awareness.",
      "importance_score": 28,
      "reasoning": "Hardware/signal processing paper with specialized applications. Minimal ML content and limited broader AI relevance.",
      "themes": [
        "Signal Processing",
        "IoT Security",
        "Hardware Systems"
      ],
      "continuation": null
    },
    {
      "id": "8da0beed569d",
      "title": "Optimizing LSTM Neural Networks for Resource-Constrained Retail Sales Forecasting: A Model Compression Study",
      "content": "Standard LSTM(Long Short-Term Memory) neural networks provide accurate predictions for sales data in the retail industry, but require a lot of computing power. It can be challenging especially for mid to small retail industries. This paper examines LSTM model compression by gradually reducing the number of hidden units from 128 to 16. We used the Kaggle Store Item Demand Forecasting dataset, which has 913,000 daily sales records from 10 stores and 50 items, to look at the trade-off between model size and how accurate the predictions are. Experiments show that lowering the number of hidden LSTM units to 64 maintains the same level of accuracy while also improving it. The mean absolute percentage error (MAPE) ranges from 23.6% for the full 128-unit model to 12.4% for the 64-unit model. The optimized model is 73% smaller (from 280KB to 76KB) and 47% more accurate. These results show that larger models do not always achieve better results.",
      "url": "http://arxiv.org/abs/2601.00525",
      "author": "Ravi Teja Pagidoju",
      "published": "2026-01-05",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Studies LSTM compression for retail sales forecasting by reducing hidden units from 128 to 16, finding 64-unit model achieves better MAPE (12.4%) than full model (23.6%).",
      "importance_score": 28,
      "reasoning": "Limited novelty in methodology. Surprising result (smaller is better) but may indicate overfitting in larger model. Narrow domain application.",
      "themes": [
        "Time Series",
        "Model Compression",
        "Retail"
      ],
      "continuation": null
    },
    {
      "id": "54af3b29641e",
      "title": "Humanity's Gambit",
      "content": "This piece is a study in contrast and coherence between different narratives for understanding AI, namely the perspectives of AI Doomers, AI Accelerationists, and AI Ethicists.I have substantial background with the AI Doomer narrative, and I’m quite sympathetic to it. I name it here as a narrative rather than the plain truth, as some might. This is not as an attempt to undermine it (or support it), but rather as a means to place it in context with competing narratives.The inspiration for this piece is a book called The AI Con, which I saw shelved in a library and was intrigued by. The central premise of the book is that both the doomer and accelerationist narratives are two sides of the same coin. Both treat advanced AI as fundamentally godlike: the all-encompassing technology on the horizon, the centrally important thing happening in the world... the only difference being what the consequences of that will be.The authors of The AI Con, unsurprisingly, do not believe that AI will become godlike. They dismiss the possibility as ridiculous, sci-fi, nerd fantasy, etc.&nbsp;I think this is a mistake, of course. AI might very well become godlike, or at least, I can’t dismiss it as easily as these authors can. But I also see the importance in paying attention to the rest of the world. So, I’m sympathetic to the perspective they present, which I refer to as the AI Ethics narrative.The AI Ethics narrative focuses on the impact of the AI industry on the broader world. For example: the energy required to run data centers, how it will be generated, and the effects on our climate. The raw materials to build chips, including rare earth metals, and the impacts of extracting them from the ground. These are costs that we don’t immediately see.Similarly, socioeconomic costs abound. The technological development of AI is yet another means for the rich to get richer. For power to consolidate more fully into the hands of technocrats and rich investors.&nbsp;Another cost is in attention...",
      "url": "https://www.lesswrong.com/posts/9jNQeqtm8F225rkZH/humanity-s-gambit",
      "author": "Ben Ihrig",
      "published": "2026-01-03T22:08:28.136000",
      "source": "LessWrong",
      "source_type": "research_blog",
      "tags": [],
      "summary": "Frames AI Doomer, Accelerationist, and Ethicist perspectives as competing narratives, inspired by 'The AI Con' book, while arguing for taking the possibility of godlike AI seriously despite dismissals.",
      "importance_score": 28,
      "reasoning": "Meta-level framing of AI perspectives without novel analysis. Summarizes existing viewpoints rather than advancing understanding.",
      "themes": [
        "AI Narratives",
        "AI Philosophy",
        "Existential Risk"
      ],
      "continuation": null
    },
    {
      "id": "ce1749c4ad61",
      "title": "Group Cross-Correlations with Faintly Constrained Filters",
      "content": "We provide a notion of group cross-correlations, where the associated filter is not as tightly constrained as in the previous literature. This resolves an incompatibility previous constraints have for group actions with non-compact stabilizers. Moreover, we generalize previous results to group actions that are not necessarily transitive, and we weaken the common assumption of unimodularity.",
      "url": "http://arxiv.org/abs/2601.00045",
      "author": "Benedikt Fluhr",
      "published": "2026-01-05",
      "source": "arXiv (math.DS)",
      "source_type": "arxiv",
      "tags": [
        "math.DS"
      ],
      "summary": "Generalizes group cross-correlations with less constrained filters, resolving incompatibilities for group actions with non-compact stabilizers. Extends to non-transitive group actions and weakens unimodularity assumption.",
      "importance_score": 25,
      "reasoning": "Highly theoretical mathematical paper with limited immediate ML applications. Specialized contribution to mathematical foundations.",
      "themes": [
        "Mathematical Foundations",
        "Group Theory"
      ],
      "continuation": null
    },
    {
      "id": "113ec47f7dcc",
      "title": "Rock bottom terminal value",
      "content": "Terminal values are discussed here:https://www.lesswrong.com/s/3HyeNiEpvbQQaqeoH/p/n5ucT5ZbPdhfGNLtPand https://www.lesswrong.com/posts/zqwWicCLNBSA5Ssmn/by-which-it-may-be-judgedAnd Yudkowsky references Frankena's terminal values ...but are these actually terminal?Do terminal values \"reduce\" or \"bottom-out?\"Frankena's first two are Life and Consciousness. Even as terminal as these may seem, I contend that they're actually instrumental. &nbsp;I want life and consciousness so I can experience happiness/flourishing. &nbsp;I certainly don't want life and consciousness if existence is just pain and misery.I posit (I think in agreement with Aristotle) all values bottom out in the terminal value of happiness/flourishing...actually maybe it's perhaps better formalized as the most flourishing, happy world outcome (as the agent judges it), as even the mom who sacrifices herself for her son does so not because the action feels right, nor because her son's survival is a terminal value weighed against other terminal values like her own survival, but because she judges the outcome (world state) where her son lives and she dies to save him as better (read: \"more flourishing\") than the alternative, even though she knows she will no longer there to experience it. &nbsp;It's not the act she values, nor her experience of the outcome (there will be none), it's the outcome itself.On the negative side, one could judge death a \"more flourishing\" outcome than living a predominantly painful life (though, hopefully these are not the only choices one faces).On the even more negative side, I think even a sociopath's values bottom out like this. &nbsp;They just prefer outcomes most people don't (potentially including some that most people find abominable).TL;DR we all just wanna be happy, and we have our ideas about what world outcomes are \"better\" and \"worse.\" EVERY value derived from this terminal value is...instrumental.Ok, so maybe terminal values bottom out. &nbsp;So what?Well, if termina...",
      "url": "https://www.lesswrong.com/posts/DJeBQrBSqFYqBaeQW/rock-bottom-terminal-value",
      "author": "ihatenumbersinusernames7",
      "published": "2026-01-04T15:43:02.398000",
      "source": "LessWrong",
      "source_type": "research_blog",
      "tags": [],
      "summary": "Philosophical discussion questioning whether Frankena's terminal values (like life, consciousness) are truly terminal or instrumental to happiness/flourishing as the ultimate terminal value.",
      "importance_score": 22,
      "reasoning": "Philosophical speculation on terminal values with limited rigor. Reiterates existing philosophical positions without novel contribution.",
      "themes": [
        "Philosophy",
        "Values",
        "AI Alignment"
      ],
      "continuation": null
    },
    {
      "id": "555b6af3140a",
      "title": "Cost Optimization in Production Line Using Genetic Algorithm",
      "content": "This paper presents a genetic algorithm (GA) approach to cost-optimal task scheduling in a production line. The system consists of a set of serial processing tasks, each with a given duration, unit execution cost, and precedence constraints, which must be assigned to an unlimited number of stations subject to a per-station duration bound. The objective is to minimize the total production cost, modeled as a station-wise function of task costs and the duration bound, while strictly satisfying all prerequisite and capacity constraints. Two chromosome encoding strategies are investigated: a station-based representation implemented using the JGAP library with SuperGene validity checks, and a task-based representation in which genes encode station assignments directly. For each encoding, standard GA operators (crossover, mutation, selection, and replacement) are adapted to preserve feasibility and drive the population toward lower-cost schedules. Experimental results on three classes of precedence structures-tightly coupled, loosely coupled, and uncoupled-demonstrate that the task-based encoding yields smoother convergence and more reliable cost minimization than the station-based encoding, particularly when the number of valid schedules is large. The study highlights the advantages of GA over gradient-based and analytical methods for combinatorial scheduling problems, especially in the presence of complex constraints and non-differentiable cost landscapes.",
      "url": "http://arxiv.org/abs/2601.00689",
      "author": "Alireza Rezaee",
      "published": "2026-01-05",
      "source": "arXiv (Neural and Evolutionary Computing)",
      "source_type": "arxiv",
      "tags": [
        "cs.NE"
      ],
      "summary": "Applies genetic algorithms to production line cost optimization with task scheduling under precedence constraints. Compares station-based and task-based chromosome encodings using standard crossover and mutation operators.",
      "importance_score": 18,
      "reasoning": "Very standard application of genetic algorithms to classical scheduling problem. No novel contributions to AI/ML methodology. Limited research value.",
      "themes": [
        "Evolutionary Computing",
        "Optimization",
        "Manufacturing"
      ],
      "continuation": null
    },
    {
      "id": "ba57baee6cbb",
      "title": "The Maduro Polymarket bet is not \"obviously insider trading\"",
      "content": "Crosspost from substackSo, if you haven’t heard the news, America deposed Maduro, and a fresh polymarket account bet on it happening and made ~$320k in profit.Seems suspicious right! And yeah! The media, expectedly, went hogwild.And look, I agree, I smell the same stench all of you do, but that doesn’t mean that this is not an “obvious case of insider trading”, as some twitterers, redditors, youtubers and even news outlets have claimed. Today I want to make the case that this is not an obvious conclusion!1Full story of the polymarket accountThe account bought shares in 3 prediction markets:2Maduro out by January 31 (bought at 7-11 cents)US forces in Venezuela by January 31Trump invokes war powers against Venezuela by January 31The first market was resolved to yes, since well, he’s out. This is where the majority of the profits were made.The others have not been resolved yet. Yet this person sold! If this person had perfect information, as has been suggested, it would be very irrational to sell these shares before the market resolves.Also, notice the rates at which he bought. It’s not like polymarket broadly believed this to be impossible at all. 10 cents means that the market thinks the odds of this happening are around 10%. You could explain this with even more insider trading. But maybe not! Maybe, in some ways, a lot of the signs were quite obvious.“Trump has repeatedly told the media that Maduro’s days in power are numbered.”The above quote is from december 31st.And if you think that this is so obviously insider trading and this person is obviously so sure, then why only bet 80k? I can’t really imagine a guy close enough to trump that he would have this amount of intel yet not have more than 80k in the bank to gamble with. And I don’t think the argument of “any more would be suspicious” really holds either here, betting $800k or $80k is about as suspicious, at the very least, the wins would outpace the odds of trouble.I think if what we were seeing was genuine i...",
      "url": "https://www.lesswrong.com/posts/7MLPvfzBCwuzWY8Xf/the-maduro-polymarket-bet-is-not-obviously-insider-trading",
      "author": "ceselder",
      "published": "2026-01-04T05:53:59.946000",
      "source": "LessWrong",
      "source_type": "research_blog",
      "tags": [],
      "summary": "Analysis arguing that the Polymarket Maduro bet is not obviously insider trading, noting the bettor sold other related contracts before resolution and bought at non-trivial prices.",
      "importance_score": 18,
      "reasoning": "Prediction market analysis unrelated to AI research. Some analytical value but off-topic for AI research relevance.",
      "themes": [
        "Prediction Markets",
        "Analysis"
      ],
      "continuation": null
    },
    {
      "id": "399f73b92393",
      "title": "Calling all college students (and new readers)",
      "content": "After seeing this post and it's comments, I realized there may be an influx of new, roughly college-aged people joining LessWrong and the broader AI x-risk reduction community.As a college student myself, this is a relief!I have been regularly reading and digesting posts on here for nearly a year now, and the journey has been a bit lonely – navigating these ideas can feel detached from reality when the people around you aren’t really discussing them yet. I think it would be very helpful to have like-minded peers to talk to.Note that this applies to anyone who is relatively new to the community, not just college students. The reason I specified that in my title is because I'm also interested in college community-building, which I think could be high leverage for a few reasons:Very few have been exposed to the quality of thinking found on LessWrong. I discovered this forum a few years back through Bentham's Bulldog and started taking x-risk seriously only when I realized that AI was indeed becoming as transformative as many over here predicted. I know many intelligent students who could certainly contribute somewhere but have not yet engaged with perspective-shifting content, such as posts from years before the \"ChatGPT moment\" that now seem remarkably prescient, which they are unlikely to get from a clip on YouTube.AI risk is likely to become a bigger, multifaceted public issue. Given the impending job displacement that seems likelier by the day, I expect that many students will soon find themselves confused and searching for a coherent source of information. Whether this translates into effective action or disorder may be a result of the community building efforts we start now. Also, as AI risk increasingly becomes a governance issue, it seems important to engage students beyond those already in CS/ML.Will this meaningfully influence the world? I don't know, but it seems worth trying. And it may be a place to pick up the ball, because it looks like an awful number o...",
      "url": "https://www.lesswrong.com/posts/DEqWFasdqcSv2K3tz/calling-all-college-students-and-new-readers-1",
      "author": "neo",
      "published": "2026-01-04T16:20:23.972000",
      "source": "LessWrong",
      "source_type": "research_blog",
      "tags": [],
      "summary": "Community building post for college students interested in AI x-risk, expressing interest in forming peer groups for discussing alignment and related topics.",
      "importance_score": 15,
      "reasoning": "Community organizing post with no research content.",
      "themes": [
        "Community",
        "AI Safety"
      ],
      "continuation": null
    },
    {
      "id": "df739e415629",
      "title": "LessOnline 2026 Improvement Ideas",
      "content": "I had a wonderful time at LessOnline 2025 and am excitedly looking forward to the 2026 installment. If you're reading this, you should definitely consider going!Here are a few ideas I had that may improve the LessOnline experience a bit. Feel free to add your own ideas to the comments.(Again, the event was run incredibly well and a vast majority of attendees had similar opinions as me based on the feedback at the ending session—these ideas are just some \"extras\".)QR code on the name tag for easy access to contact info. Quite a few times when I asked for somebody's social I had to pull out my phone, open up my browser, listen to them spell out their info while I typed it, backspace a few times because I misheard, then finally ask \"is this you?\". A QR code linking directly to their LessOnline profile would be less disruptive to the conversation, easier to manage, etc. The code could be automatically generated when they make their profile and then \"locked in\" whenever name tags are printed.Hotel group rates for cheaper stays nearby. Working with a nearby hotel to get discounted rates and serve as the second official LessOnline lodge (after Lighthaven, of course) may allow more people to come in case it's too expensive with flights, plane tickets, lodging, and miscellaneous expenses. This is probably prohibitive because it requires a lot more work on the organizers' parts (finding a good hotel, contracts, etc) and may draw people away from staying at Lighthaven, which is a nice source of revenue for Lightcone Infrastructure.",
      "url": "https://www.lesswrong.com/posts/5KTKLYcuuQkZ4TynM/lessonline-2026-improvement-ideas",
      "author": "nomagicpill",
      "published": "2026-01-04T16:56:53.476000",
      "source": "LessWrong",
      "source_type": "research_blog",
      "tags": [],
      "summary": "Community suggestions for improving the LessOnline 2026 conference, including QR codes on name tags, hotel group rates, and various logistical improvements.",
      "importance_score": 12,
      "reasoning": "Event planning discussion with no research content. Community organizing value only.",
      "themes": [
        "Community"
      ],
      "continuation": null
    },
    {
      "id": "4a1230166a23",
      "title": "In My Misanthropy Era",
      "content": "For the past year I've been sinking into the Great Books via the Penguin Great Ideas series, because I wanted to be conversant in the Great Conversation. I am occasionally frustrated by this endeavour, but overall, it's been fun! I'm learning a lot about my civilization and the various curmudgeons who shaped it.But one dismaying side effect is that it's also been quite empowering for my inner 13 year old edgelord. Did you know that before we invented woke, you were just allowed to be openly contemptuous of people?Here's Schopenhauer on the common man:They take an objective interest in nothing whatever. Their attention, not to speak of their mind, is engaged by nothing that does not bear some relation, or at least some possible relation, to their own person: otherwise their interest is not aroused. They are not noticeably stimulated even by wit or humour; they hate rather everything that demands the slightest thought. Coarse buffooneries at most excite them to laughter: apart from that they are earnest brutes – and all because they are capable of only subjective interest. It is precisely this which makes card-playing the most appropriate amusement for them – card-playing for money: because this does not remain in the sphere of mere knowledge, as stage plays, music, conversation, etc., do, but sets in motion the will itself, the primary element which exists everywhere. For the rest they are, from their first breath to their last, tradesmen, life’s born drudges. All their pleasures are sensuous: they have no feeling for any other kind of pleasure. To be sociable with them is to be degraded.And Freud on why he's skeptical about this \"universal love\" thing:Even at this early stage we will not withhold our two main reservations: first, an undiscriminating love seems to us to forfeit some of its intrinsic value by doing its object an injustice, and, secondly, not all human beings are worthy of love.After being raised by SJW tumblr, reading this was unbelievably exhilaratin...",
      "url": "https://www.lesswrong.com/posts/otgrxjbWLsrDjbC2w/in-my-misanthropy-era",
      "author": "jenn",
      "published": "2026-01-04T13:34:43.514000",
      "source": "LessWrong",
      "source_type": "research_blog",
      "tags": [],
      "summary": "Personal essay reflecting on reading Great Books and historical philosophers' contempt for common people, exploring themes of misanthropy and intellectual elitism.",
      "importance_score": 10,
      "reasoning": "Personal reflection with no AI or research content.",
      "themes": [
        "Philosophy",
        "Personal Reflection"
      ],
      "continuation": null
    },
    {
      "id": "67e129b0afb5",
      "title": "The Problem with Democracy",
      "content": "The problem with democracies is that they're based on the naive and erroneous assumption that people voting for representatives will elect people who'll represent them. In other words, democracies were intended to be democratic, but never designed to be. They were intended to derive power from citizens, but never designed to allow people to work together to influence government.A democracy is a form of government that gets its power from its citizens. America's founders called its form of representative democracy a \"Republic.\" In the beginning, when representatives tried to be representative, it sort of worked, but it never worked well.Because it worked poorly, a huge political system evolved in which other players compete to control the government. Meanwhile, a culture evolved with myths that say a citizen's main responsibility is to vote. While voting is a democratic action, it has become part of our very non-democratic system. Other myths ensure people support the dysfunctional status quo in other ways.Meanwhile, political science studies our current systems and ignores the fundamental questions:What foundation does a representative democracy need in order to work well?How could this foundation arise?Political science has answers to the first question, but they're very poor answers. Instead of grappling with the question, they look at what seems to make the system work less poorly, such as free and fair elections, strong institutions, a free press, an independent judiciary, a constitution, competent candidates, and a choice of parties. People who want to improve politics then work on these instead of helping create the needed foundation.While I've written more about this on PeopleCount.org, it's almost pointless to read about the details. Almost everyone thinks they know that really:Politics is hopelessPolitics is corruptPolitics needs some law(s) to be passed in order to work\"Our\" party needs a big winWe need a whole new set of representativesRepresentative demo...",
      "url": "https://www.lesswrong.com/posts/p97ckXzfkjMFhJkJs/the-problem-with-democracy",
      "author": "RandStrauss",
      "published": "2026-01-04T02:11:22.310000",
      "source": "LessWrong",
      "source_type": "research_blog",
      "tags": [],
      "summary": "Political philosophy essay arguing that democracies were intended but not designed to be representative, and that voting has become part of a dysfunctional system.",
      "importance_score": 10,
      "reasoning": "Political philosophy with no AI research content.",
      "themes": [
        "Political Philosophy"
      ],
      "continuation": null
    }
  ],
  "notice": {
    "type": "info",
    "title": "Monday Edition",
    "message": "Today's arXiv papers cover submissions from the entire weekend (Friday through Sunday) due to arXiv's publishing schedule."
  }
}