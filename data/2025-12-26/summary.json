{
  "date": "2025-12-26",
  "coverage_date": "2025-12-25",
  "coverage_start": "2025-12-25T00:00:00",
  "coverage_end": "2025-12-25T23:59:59.999999",
  "executive_summary": "#### Top Story\n**Nvidia** [is acquiring **Groq's** assets](/?date=2025-12-26&category=news#item-0cbe689d0986) for approximately **$20 billion**—its largest deal ever—to integrate Groq's low-latency LPU inference technology into its AI factory architecture.\n\n#### Key Developments\n- **OpenAI**: [Released **GPT-5.2 Codex**](/?date=2025-12-26&category=news#item-bdd4fd1873c1) for advanced coding capabilities, with cross-source verification from multiple outlets\n- **Google**: [Launched **Gemini Free Flash**](/?date=2025-12-26&category=news#item-bdd4fd1873c1) for competitive AI performance\n- **Nvidia**: [Open-sourced **Trion-3** models](/?date=2025-12-26&category=news#item-bdd4fd1873c1) with strong benchmark results\n- **Yann LeCun/Meta**: [Announced **VL-JEPA**](/?date=2025-12-26&category=reddit#item-a6ae7a47ef04), a non-generative vision-language model outperforming multimodal LLMs\n- **Anthropic**: Engineer responded to **Karpathy's** token limit concerns with [immediate **Claude Code** configuration fix](/?date=2025-12-26&category=social#item-acb2f75d907c) via new environment variable\n\n#### Safety & Regulation\n- **ICLR 2025 Outstanding Paper** [revealed LLM safety training is fragile](/?date=2025-12-26&category=social#item-095e879bcaeb) against adversarial attacks at response boundaries\n- LessWrong published [call for research on evaluation awareness](/?date=2025-12-26&category=research#item-ebb98c108ced)—whether frontier models can detect testing conditions and modify behavior\n- AI chatbots now [**twice as likely** to spread misinformation](/?date=2025-12-26&category=social#item-8d239e685bb3) compared to last year\n- New York's [**RAISE Act** advancing](/?date=2025-12-26&category=research#item-1da8e2454594) through legislature on AI policy\n\n#### Research Highlights\n- **François Chollet** [clarified ARC-AGI benchmark saturation](/?date=2025-12-26&category=social#item-0824686a63b4) implications and announced **ARC-AGI-3** roadmap for March 2026\n- **META SuperIntelligence Labs** [announced **SWE-RL**](/?date=2025-12-26&category=reddit#item-80ef3655cb3c): agents that autonomously generate training data, claiming superhuman software engineering capabilities\n- **Claude Opus 4.5** [showed strong performance on **METR**](/?date=2025-12-26&category=research#item-1da8e2454594) agentic benchmarks\n- **PhysMaster** autonomous AI physicist [research highlighted](/?date=2025-12-26&category=reddit#item-0193589124e0) in r/Futurology\n\n#### Looking Ahead\nWatch for consolidation effects as Nvidia integrates Groq's inference technology, and whether **ARC-AGI-3** benchmarks can address growing concerns about evaluation methodology and model awareness of testing conditions.",
  "executive_summary_html": "<h4>Top Story</h4>\n<p><strong>Nvidia</strong> <a href=\"/?date=2025-12-26&category=news#item-0cbe689d0986\" class=\"internal-link\">is acquiring <strong>Groq's</strong> assets</a> for approximately <strong>$20 billion</strong>—its largest deal ever—to integrate Groq's low-latency LPU inference technology into its AI factory architecture.</p>\n<h4>Key Developments</h4>\n<ul>\n<li><strong>OpenAI</strong>: <a href=\"/?date=2025-12-26&category=news#item-bdd4fd1873c1\" class=\"internal-link\">Released <strong>GPT-5.2 Codex</strong></a> for advanced coding capabilities, with cross-source verification from multiple outlets</li>\n<li><strong>Google</strong>: <a href=\"/?date=2025-12-26&category=news#item-bdd4fd1873c1\" class=\"internal-link\">Launched <strong>Gemini Free Flash</strong></a> for competitive AI performance</li>\n<li><strong>Nvidia</strong>: <a href=\"/?date=2025-12-26&category=news#item-bdd4fd1873c1\" class=\"internal-link\">Open-sourced <strong>Trion-3</strong> models</a> with strong benchmark results</li>\n<li><strong>Yann LeCun/Meta</strong>: <a href=\"/?date=2025-12-26&category=reddit#item-a6ae7a47ef04\" class=\"internal-link\">Announced <strong>VL-JEPA</strong></a>, a non-generative vision-language model outperforming multimodal LLMs</li>\n<li><strong>Anthropic</strong>: Engineer responded to <strong>Karpathy's</strong> token limit concerns with <a href=\"/?date=2025-12-26&category=social#item-acb2f75d907c\" class=\"internal-link\">immediate <strong>Claude Code</strong> configuration fix</a> via new environment variable</li>\n</ul>\n<h4>Safety & Regulation</h4>\n<ul>\n<li><strong>ICLR 2025 Outstanding Paper</strong> <a href=\"/?date=2025-12-26&category=social#item-095e879bcaeb\" class=\"internal-link\">revealed LLM safety training is fragile</a> against adversarial attacks at response boundaries</li>\n<li>LessWrong published <a href=\"/?date=2025-12-26&category=research#item-ebb98c108ced\" class=\"internal-link\">call for research on evaluation awareness</a>—whether frontier models can detect testing conditions and modify behavior</li>\n<li>AI chatbots now <a href=\"/?date=2025-12-26&category=social#item-8d239e685bb3\" class=\"internal-link\"><strong>twice as likely</strong> to spread misinformation</a> compared to last year</li>\n<li>New York's <a href=\"/?date=2025-12-26&category=research#item-1da8e2454594\" class=\"internal-link\"><strong>RAISE Act</strong> advancing</a> through legislature on AI policy</li>\n</ul>\n<h4>Research Highlights</h4>\n<ul>\n<li><strong>François Chollet</strong> <a href=\"/?date=2025-12-26&category=social#item-0824686a63b4\" class=\"internal-link\">clarified ARC-AGI benchmark saturation</a> implications and announced <strong>ARC-AGI-3</strong> roadmap for March 2026</li>\n<li><strong>META SuperIntelligence Labs</strong> <a href=\"/?date=2025-12-26&category=reddit#item-80ef3655cb3c\" class=\"internal-link\">announced <strong>SWE-RL</strong></a>: agents that autonomously generate training data, claiming superhuman software engineering capabilities</li>\n<li><strong>Claude Opus 4.5</strong> <a href=\"/?date=2025-12-26&category=research#item-1da8e2454594\" class=\"internal-link\">showed strong performance on <strong>METR</strong></a> agentic benchmarks</li>\n<li><strong>PhysMaster</strong> autonomous AI physicist <a href=\"/?date=2025-12-26&category=reddit#item-0193589124e0\" class=\"internal-link\">research highlighted</a> in r/Futurology</li>\n</ul>\n<h4>Looking Ahead</h4>\n<p>Watch for consolidation effects as Nvidia integrates Groq's inference technology, and whether <strong>ARC-AGI-3</strong> benchmarks can address growing concerns about evaluation methodology and model awareness of testing conditions.</p>",
  "top_topics": [
    {
      "name": "Nvidia-Groq $20B Acquisition",
      "description": "Nvidia is acquiring AI chip startup Groq's assets for approximately $20 billion, marking its largest deal ever. Last Week in AI [covered the acquisition](/?date=2025-12-26&category=news#item-0cbe689d0986) as the lead story, while Twitter speculation from gp_pulipaka [provided detailed analysis](/?date=2025-12-26&category=social#item-b1239046c2f6) of how Groq's LPU technology would integrate with Nvidia's GPU architecture to enhance inference capabilities.",
      "description_html": "Nvidia is acquiring AI chip startup Groq's assets for approximately $20 billion, marking its largest deal ever. Last Week in AI <a href=\"/?date=2025-12-26&category=news#item-0cbe689d0986\" class=\"internal-link\">covered the acquisition</a> as the lead story, while Twitter speculation from gp_pulipaka <a href=\"/?date=2025-12-26&category=social#item-b1239046c2f6\" class=\"internal-link\">provided detailed analysis</a> of how Groq's LPU technology would integrate with Nvidia's GPU architecture to enhance inference capabilities.",
      "category_breakdown": {
        "news": 2,
        "social": 1
      },
      "representative_items": [],
      "importance": 95
    },
    {
      "name": "AI Evaluation & Benchmark Methodology",
      "description": "A convergent focus on how we measure AI capabilities and safety emerged across platforms. LessWrong featured a [call for research](/?date=2025-12-26&category=research#item-ebb98c108ced) on evaluation awareness, examining whether models can detect testing conditions. François Chollet's [comprehensive thread](/?date=2025-12-26&category=social#item-0824686a63b4) explained ARC-AGI benchmark saturation implications, while an ICLR 2025 [Outstanding Paper](/?date=2025-12-26&category=social#item-095e879bcaeb) highlighted by Andriy Burkov revealed that LLM safety training is surprisingly fragile against adversarial attacks.",
      "description_html": "A convergent focus on how we measure AI capabilities and safety emerged across platforms. LessWrong featured a <a href=\"/?date=2025-12-26&category=research#item-ebb98c108ced\" class=\"internal-link\">call for research</a> on evaluation awareness, examining whether models can detect testing conditions. François Chollet's <a href=\"/?date=2025-12-26&category=social#item-0824686a63b4\" class=\"internal-link\">comprehensive thread</a> explained ARC-AGI benchmark saturation implications, while an ICLR 2025 <a href=\"/?date=2025-12-26&category=social#item-095e879bcaeb\" class=\"internal-link\">Outstanding Paper</a> highlighted by Andriy Burkov revealed that LLM safety training is surprisingly fragile against adversarial attacks.",
      "category_breakdown": {
        "research": 2,
        "social": 4
      },
      "representative_items": [],
      "importance": 88
    },
    {
      "name": "AI Coding Tools & Agents",
      "description": "Software engineering AI dominated multiple categories with significant developments. OpenAI's [GPT-5.2 Codex release](/?date=2025-12-26&category=news#item-bdd4fd1873c1) for advanced coding was covered in news roundups. Karpathy and Anthropic engineer bcherny [exchanged on Twitter](/?date=2025-12-26&category=social#item-acb2f75d907c) about Claude Code token limits, resulting in an immediate configuration fix. META SuperIntelligence Labs [announced SWE-RL](/?date=2025-12-26&category=reddit#item-80ef3655cb3c) on Reddit, claiming agents that autonomously generate training data and exceed human capabilities in software engineering.",
      "description_html": "Software engineering AI dominated multiple categories with significant developments. OpenAI's <a href=\"/?date=2025-12-26&category=news#item-bdd4fd1873c1\" class=\"internal-link\">GPT-5.2 Codex release</a> for advanced coding was covered in news roundups. Karpathy and Anthropic engineer bcherny <a href=\"/?date=2025-12-26&category=social#item-acb2f75d907c\" class=\"internal-link\">exchanged on Twitter</a> about Claude Code token limits, resulting in an immediate configuration fix. META SuperIntelligence Labs <a href=\"/?date=2025-12-26&category=reddit#item-80ef3655cb3c\" class=\"internal-link\">announced SWE-RL</a> on Reddit, claiming agents that autonomously generate training data and exceed human capabilities in software engineering.",
      "category_breakdown": {
        "news": 2,
        "social": 2,
        "reddit": 1
      },
      "representative_items": [],
      "importance": 85
    },
    {
      "name": "GPT-5.2 & Model Releases",
      "description": "Multiple major model releases this week created significant coverage overlap. Last Week in AI Podcast [covered OpenAI's GPT-5.2 Codex](/?date=2025-12-26&category=news#item-bdd4fd1873c1) alongside Google's Gemini Free Flash and Nvidia's open-source Trion-3 models. Zvi's weekly AI roundup on LessWrong [independently confirmed GPT-5.2-Codex's existence](/?date=2025-12-26&category=research#item-1da8e2454594), establishing cross-source verification of this significant capability release.",
      "description_html": "Multiple major model releases this week created significant coverage overlap. Last Week in AI Podcast <a href=\"/?date=2025-12-26&category=news#item-bdd4fd1873c1\" class=\"internal-link\">covered OpenAI's GPT-5.2 Codex</a> alongside Google's Gemini Free Flash and Nvidia's open-source Trion-3 models. Zvi's weekly AI roundup on LessWrong <a href=\"/?date=2025-12-26&category=research#item-1da8e2454594\" class=\"internal-link\">independently confirmed GPT-5.2-Codex's existence</a>, establishing cross-source verification of this significant capability release.",
      "category_breakdown": {
        "news": 2,
        "research": 1
      },
      "representative_items": [],
      "importance": 82
    },
    {
      "name": "Claude Ecosystem Developments",
      "description": "Anthropic's Claude models generated discussion across research and social channels. Zvi's LessWrong roundup [highlighted Claude Opus 4.5's strong performance](/?date=2025-12-26&category=research#item-1da8e2454594) on METR agentic benchmarks. On Twitter, Karpathy [raised token context limit issues](/?date=2025-12-26&category=social#item-ac63f2ec2415) with AI coding tools, prompting Anthropic engineer bcherny to [immediately announce](/?date=2025-12-26&category=social#item-acb2f75d907c) a new CLAUDE_CODE_FILE_READ_MAX_OUTPUT_TOKENS environment variable fix for Claude Code.",
      "description_html": "Anthropic's Claude models generated discussion across research and social channels. Zvi's LessWrong roundup <a href=\"/?date=2025-12-26&category=research#item-1da8e2454594\" class=\"internal-link\">highlighted Claude Opus 4.5's strong performance</a> on METR agentic benchmarks. On Twitter, Karpathy <a href=\"/?date=2025-12-26&category=social#item-ac63f2ec2415\" class=\"internal-link\">raised token context limit issues</a> with AI coding tools, prompting Anthropic engineer bcherny to <a href=\"/?date=2025-12-26&category=social#item-acb2f75d907c\" class=\"internal-link\">immediately announce</a> a new CLAUDE_CODE_FILE_READ_MAX_OUTPUT_TOKENS environment variable fix for Claude Code.",
      "category_breakdown": {
        "research": 1,
        "social": 2
      },
      "representative_items": [],
      "importance": 78
    },
    {
      "name": "Intelligence Conceptualization",
      "description": "Theoretical frameworks for understanding intelligence surfaced in parallel discussions. LessWrong [published a typology](/?date=2025-12-26&category=research#item-66525618a9d3) proposing intelligence as a multi-layered axis of functional competencies rather than a single scalar. On Twitter, Yann LeCun [endorsed the same conceptual view](/?date=2025-12-26&category=social#item-b403d7bf6252), arguing that intelligence is a multidimensional vector and that all species are specialized with varying adaptability rather than ranked on a single scale.",
      "description_html": "Theoretical frameworks for understanding intelligence surfaced in parallel discussions. LessWrong <a href=\"/?date=2025-12-26&category=research#item-66525618a9d3\" class=\"internal-link\">published a typology</a> proposing intelligence as a multi-layered axis of functional competencies rather than a single scalar. On Twitter, Yann LeCun <a href=\"/?date=2025-12-26&category=social#item-b403d7bf6252\" class=\"internal-link\">endorsed the same conceptual view</a>, arguing that intelligence is a multidimensional vector and that all species are specialized with varying adaptability rather than ranked on a single scale.",
      "category_breakdown": {
        "research": 1,
        "social": 1
      },
      "representative_items": [],
      "importance": 68
    }
  ],
  "total_items_collected": 415,
  "total_items_analyzed": 415,
  "collection_status": {
    "overall": "success",
    "sources": [
      {
        "name": "news",
        "display_name": "News",
        "status": "success",
        "count": 2,
        "error": null
      },
      {
        "name": "research",
        "display_name": "Research",
        "status": "success",
        "count": 6,
        "error": null
      },
      {
        "name": "social",
        "display_name": "Social",
        "status": "success",
        "count": 339,
        "error": null
      },
      {
        "name": "reddit",
        "display_name": "Reddit",
        "status": "success",
        "count": 68,
        "error": null
      }
    ],
    "social_platforms": [
      {
        "name": "twitter",
        "display_name": "Twitter",
        "status": "success",
        "count": 337,
        "error": null
      },
      {
        "name": "bluesky",
        "display_name": "Bluesky",
        "status": "success",
        "count": 1,
        "error": null
      },
      {
        "name": "mastodon",
        "display_name": "Mastodon",
        "status": "success",
        "count": 1,
        "error": null
      }
    ],
    "warnings": []
  },
  "hero_image_url": "/data/2025-12-26/hero.webp?v=1768107177",
  "hero_image_prompt": "You are generating a daily hero image for an AI news aggregator website.\n\n## Your Goal\nCreate a playful, colorful editorial illustration that visually represents today's top AI news stories. The scene should immediately convey the themes of the day's news to readers.\n\n## The Mascot (CRITICAL)\nThe attached image shows our skunk mascot. You MUST:\n- Keep the EXACT circuit board pattern on the skunk's body and tail - this is a core part of the brand identity\n- Maintain the skunk's white and black coloring with the tech circuit pattern visible\n- The skunk must be ACTIVELY DOING SOMETHING related to the topics - typing on a keyboard, reading papers, adjusting equipment, pointing at a screen, holding tools, etc. NOT just standing and smiling at the camera!\n- Position the skunk in the lower-left or lower-right portion, engaged with the scene\n\n## Today's Stories\n\n**Topic 1: Nvidia-Groq $20B Acquisition**\nNvidia is acquiring AI chip startup Groq's assets for approximately $20 billion, marking its largest deal ever. Last Week in AI covered the acquisition as the lead story, while Twitter speculation from gp_pulipaka provided detailed analysis of how Groq's LPU technology would integrate with Nvidia's GPU architecture to enhance inference capabilities.\n**Topic 2: AI Evaluation & Benchmark Methodology**\nA convergent focus on how we measure AI capabilities and safety emerged across platforms. LessWrong featured a call for research on evaluation awareness, examining whether models can detect testing conditions. François Chollet's comprehensive thread explained ARC-AGI benchmark saturation implications, while an ICLR 2025 Outstanding Paper highlighted by Andriy Burkov revealed that LLM safety training is surprisingly fragile against adversarial attacks.\n**Topic 3: AI Coding Tools & Agents**\nSoftware engineering AI dominated multiple categories with significant developments. OpenAI's GPT-5.2 Codex release for advanced coding was covered in news roundups. Karpathy and Anthropic engineer bcherny exchanged on Twitter about Claude Code token limits, resulting in an immediate configuration fix. META SuperIntelligence Labs announced SWE-RL on Reddit, claiming agents that autonomously generate training data and exceed human capabilities in software engineering.\n**Topic 4: GPT-5.2 & Model Releases**\nMultiple major model releases this week created significant coverage overlap. Last Week in AI Podcast covered OpenAI's GPT-5.2 Codex alongside Google's Gemini Free Flash and Nvidia's open-source Trion-3 models. Zvi's weekly AI roundup on LessWrong independently confirmed GPT-5.2-Codex's existence, establishing cross-source verification of this significant capability release.\n**Topic 5: Claude Ecosystem Developments**\nAnthropic's Claude models generated discussion across research and social channels. Zvi's LessWrong roundup highlighted Claude Opus 4.5's strong performance on METR agentic benchmarks. On Twitter, Karpathy raised token context limit issues with AI coding tools, prompting Anthropic engineer bcherny to immediately announce a new CLAUDE_CODE_FILE_READ_MAX_OUTPUT_TOKENS environment variable fix for Claude Code.\n**Topic 6: Intelligence Conceptualization**\nTheoretical frameworks for understanding intelligence surfaced in parallel discussions. LessWrong published a typology proposing intelligence as a multi-layered axis of functional competencies rather than a single scalar. On Twitter, Yann LeCun endorsed the same conceptual view, arguing that intelligence is a multidimensional vector and that all species are specialized with varying adaptability rather than ranked on a single scale.\n\n## Visual Direction\nCreate a scene that represents these stories. You must include Topic 1 (the top story), then pick 2-3 others that would make the best scene together. Consider:\n- What visual metaphors could represent these themes?\n- How can the skunk mascot interact with or observe these elements?\n- Suggested scene elements: performance charts, comparison graphs, trophy, autonomous systems, workflow diagrams, connected tools, neural network visualization, glowing nodes, architecture\n\n## Style Requirements\n- Playful cartoon illustration, tech editorial art style\n- Vibrant colors with Trend Red (#E63946) accents\n- Energetic, forward-looking, tech-optimistic mood\n- No Trend Micro logos or watermarks - but other company logos (OpenAI, Anthropic, Google, etc.) are encouraged when relevant to the stories",
  "generated_at": "2026-01-10T23:52:57.565805",
  "categories": {
    "news": {
      "count": 2,
      "category_summary": "**Nvidia** [makes its largest acquisition ever](/?date=2025-12-26&category=news#item-0cbe689d0986), purchasing **Groq's** assets for **$20 billion** to integrate low-latency inference technology into its AI factory architecture—a major consolidation move in the AI chip market.\n\n[Model releases this week](/?date=2025-12-26&category=news#item-bdd4fd1873c1) include:\n- **OpenAI's GPT-5.2 Codex** for advanced coding\n- **Google's Gemini Free Flash** for competitive AI performance\n- **Nvidia's Trion-3** open-source models with strong benchmarks\n\nFunding highlights: **Lovable** raised **$330M Series B** at $6.6B valuation; **Faya** closed **$140M Series D** for AI model hosting. China advances EUV lithography via **Huawei** and **SMIC**.",
      "category_summary_html": "<p><strong>Nvidia</strong> <a href=\"/?date=2025-12-26&category=news#item-0cbe689d0986\" class=\"internal-link\">makes its largest acquisition ever</a>, purchasing <strong>Groq's</strong> assets for <strong>$20 billion</strong> to integrate low-latency inference technology into its AI factory architecture—a major consolidation move in the AI chip market.</p>\n<p><a href=\"/?date=2025-12-26&category=news#item-bdd4fd1873c1\" class=\"internal-link\">Model releases this week</a> include:</p>\n<ul>\n<li><strong>OpenAI's GPT-5.2 Codex</strong> for advanced coding</li>\n<li><strong>Google's Gemini Free Flash</strong> for competitive AI performance</li>\n<li><strong>Nvidia's Trion-3</strong> open-source models with strong benchmarks</li>\n</ul>\n<p>Funding highlights: <strong>Lovable</strong> raised <strong>$330M Series B</strong> at $6.6B valuation; <strong>Faya</strong> closed <strong>$140M Series D</strong> for AI model hosting. China advances EUV lithography via <strong>Huawei</strong> and <strong>SMIC</strong>.</p>",
      "themes": [
        {
          "name": "AI Hardware & Infrastructure",
          "description": "Major consolidation in AI chip market with Nvidia-Groq deal, plus China semiconductor advances",
          "item_count": 2,
          "example_items": [],
          "importance": 92.0
        },
        {
          "name": "Model Releases",
          "description": "New models from OpenAI, Google, and Nvidia spanning coding and general capabilities",
          "item_count": 2,
          "example_items": [],
          "importance": 78.0
        },
        {
          "name": "AI Funding",
          "description": "Significant venture capital flowing to AI coding and hosting startups",
          "item_count": 1,
          "example_items": [],
          "importance": 72.0
        }
      ],
      "top_items": [
        {
          "id": "0cbe689d0986",
          "title": "Last Week in AI #330 - Groq->Nvidia , ChatGPT Apps, US AI Genesis Mission",
          "content": "Nvidia buying AI chip startup Groq&#8217;s assets for about $20 billion in largest deal on recordNvidia agreed to license Groq&#8217;s inference technology and acquire essentially all of its assets for about $20 billion in cash&#8212;its largest deal to date&#8212;according to Disruptive CEO Alex Davis, a major Groq investor. Groq, valued at $6.9 billion after raising $750 million three months ago, said it entered a non-exclusive licensing agreement with Nvidia and that CEO Jonathan Ross, President Sunny Madra, and other senior leaders will join Nvidia. In a note to employees, Nvidia CEO Jensen Huang said the plan is to integrate Groq&#8217;s low-latency processors into the NVIDIA AI factory architecture to broaden support for inference and real-time workloads. Nvidia CFO Colette Kress declined comment, and Huang emphasized Nvidia is licensing Groq&#8217;s IP and hiring talent, not acquiring the company itself. Groq will continue operating independently under CFO-turned-CEO Simon Edwards, with GroqCloud excluded from the transaction and continuing without interruption. Davis said Nvidia is receiving all of Groq&#8217;s assets aside from the nascent cloud business, effectively transferring the core chip IP and hardware. OpenAI opens ChatGPT to third-party apps via its PlatformOpenAI is now accepting submissions for third-party apps inside ChatGPT, creating an app directory where approved tools are discoverable and usable directly in the ChatGPT interface. Developers can submit apps built with OpenAI models through the developer platform; listings undergo automated and manual review for policy compliance, safety, and technical reliability before approval. Once approved, apps appear alongside built-in tools and can be invoked in conversational workflows without external installs. The rollout is global, and eligibility depends on adherence to usage policies and quality guidelines, transitioning the prior ad hoc GPT sharing toward a structured marketplace.Amazon has a new leader for its &#8216;AGI&#8217; group as it plays catch-up on AIFrom left to right: David Luan, VP of Autonomy and head of Amazon&#8217;s AGI SF Lab, and Pieter Abbeel, Amazon Scholar, Robotics.Amazon CEO Andy Jassy said Rohit Prasad, head of the company&#8217;s AGI efforts and longtime Alexa leader, will leave next year as Amazon hits what he called an &#8220;inflection point&#8221; in AI. Peter DeSantis, an SVP at AWS with deep infrastructure experience, will now lead a new division spanning advanced AI models, custom chip development, and quantum computing. The reshuffle puts renowned AI researcher Pieter Abbeel in charge of the frontier model research team, while DeSantis unifies Amazon&#8217;s AI stack from models to hardware. Microsoft, Google Join US AI Genesis Mission to Advance Scientific DiscoveryTwo dozen major AI companies, including OpenAI, Microsoft, Nvidia, Amazon Web Services, and Google, have joined the Trump administration's \"Genesis Mission,\" a federal initiative aimed at accelerating scientific discovery and energy innovation through artificial intelligence. Announced via executive order last month, the program will coordinate research across government agencies and leverage the Energy Department's national laboratories' computing resources to automate experiment design, speed up simulations, and generate predictive models for breakthroughs in energy, manufacturing, and drug discovery. John Carreyrou and other authors bring new lawsuit against six major AI companiesRelated:Adobe hit with proposed class-action, accused of misusing authors&#8217; work in AI trainingA new lawsuit filed by authors including John Carreyrou targets Anthropic, Google, OpenAI, Meta, xAI, and Perplexity, alleging the companies trained large language models on pirated copies of their books. The complaint argues that prior relief&#8212;namely the Anthropic $1.5 billion settlement offering roughly $3,000 per eligible writer&#8212;fails to address the &#8220;massive willful infringement&#8221; of using stolen books to build models that generate billions in revenue. This follows a judge&#8217;s earlier ruling that while training on pirated copies may be legal under current interpretations, the underlying act of book piracy is not, leaving a gap authors want courts to address directly. The plaintiffs say the proposed Anthropic settlement &#8220;serves the AI companies, not creators,&#8221; and seek accountability specifically for training on datasets sourced from infringing repositories.In a parallel suit, Adobe faces a proposed class action alleging it trained its SlimLM small language model on SlimPajama-627B, which the complaint says is a derivative of RedPajama that includes the Books3 corpus of 191,000 books. Plaintiff Elizabeth Lyon claims her guidebooks appeared in a processed subset of SlimPajama, arguing Adobe relied on a deduplicated, multi-corpora dataset that nonetheless incorporated Books3 via RedPajama copying and manipulation. Books3 and RedPajama have repeatedly surfaced in litigation, including cases naming Apple Intelligence and Salesforce for alleged training on copyrighted works &#8220;without consent and without credit or compensation.&#8221;Other NewsToolsGoogle launches Gemini 3 Flash, makes it the default model in the Gemini app. Google&#8217;s new Flash model is cheaper and faster than its predecessor, matches or exceeds top models on several benchmarks, and is rolling out as the default in the Gemini app and via Vertex AI/enterprise APIs, with previews for developers and enterprises.OpenAI&#8217;s GPT-5.2-Codex advances software engineering with better reasoning and context understanding. It builds upon the capabilities of GPT-5.2, adding improvements in context compaction, large code refactoring, Windows environment performance and cybersecurity.Z.AI launches GLM-4.7, new SOTA open-source model for coding. Available via Z.ai&#8217;s Open Platform and APIs, GLM-4.7 expands context length, improves reasoning, coding, and multimodal (text+vision) performance.Anthropic makes agent Skills an open standard. They&#8217;re a new method for developing specialized AI agents using files and folders. Those folders include instructions, resources and scripts that Claude and other LLMs can leverage to perform specific tasks.Klarna Launches Open Standard for Agentic Commerce. A new protocol offers a live, standardized feed covering 100 million products and 400 million prices across 12 markets, with an API compatible with Google Merchant, Shopify, Facebook Catalog, and CSV/JSON to make merchant inventories discoverable by AI agents.Meta introduces new SAM AI able to isolate and edit audio. The system supports text, time-segment, and visual prompts to separate or remove specific sounds, is available to download and via Meta&#8217;s Segment Anything Playground, and has limitations when isolating very similar audio events and on taking audio as a direct prompt.ChatGPT launches a year-end review like Spotify Wrapped. The feature, available in several English-speaking markets to eligible free, Plus, and Pro users with certain memory and history settings enabled, delivers personalized awards plus a poem and image summarizing usage; it&#8217;s optional, privacy-focused, and unavailable to Team, Enterprise, or Education accounts.Mozilla&#8217;s new CEO says AI is coming to Firefox, but will remain a choice. Mozilla plans optional AI features in Firefox while diversifying revenue beyond search and expanding the browser into a broader ecosystem of trusted software.BusinessChinese robotaxis due in London next year as Lyft and Uber reveal tie-ups. Trials of Baidu&#8217;s Apollo Go RT6 driverless electric taxis are set to begin in London in 2026, prompting national security warnings about potential Chinese technological dependence and data risks.Waymo resumes service in San Francisco after robotaxis stall during blackout. A citywide outage caused many Waymo vehicles to stall at intersections as systems treated dark signals as four-way stops, leading to a temporary suspension while the company assessed the incident and began applying lessons learned as service resumed.OpenAI is reportedly trying to raise $100B at an $830B valuation. The cash would cover rising compute and development costs as OpenAI expands model releases, global deals, and developer tooling while navigating competition, chip supply limits, and fundraising scrutiny.How China built its &#8216;Manhattan Project&#8217; to rival the West in AI chips. A prototype EUV lithography machine&#8212;reportedly reverse-engineered by ex-ASML engineers in a secure Shenzhen facility and completed in early 2025&#8212;is now under testing as part of a state-backed effort to close China&#8217;s advanced chipmaking gap.Vibe-coding startup Lovable raises $330M at a $6.6B valuation. Funding will support deeper third-party integrations, expanded enterprise features, and infrastructure&#8212;databases, payments, and hosting&#8212;to enable full-fledged application development on the platform.Yann LeCun confirms his new &#8216;world model&#8217; startup, reportedly seeks $5B+ valuation. The company, Advanced Machine Intelligence (AMI), is chaired by LeCun with Alex LeBrun as CEO and aims to build &#8220;world model&#8221; AI that simulates cause-and-effect to reduce LLM hallucinations; it&#8217;s reportedly seeking roughly &#8364;500M at a &#8364;3B valuation.ChatGPT&#8217;s mobile app hits new milestone of $3B in consumer spending. Most of the $3 billion arrived in 2025 as consumer spending&#8212;largely from Plus and Pro subscriptions&#8212;surged, outpacing revenue growth timelines of major apps like TikTok, Disney+, and HBO Max.Cursor continues acquisition spree with Graphite deal. The deal, reportedly for well above Graphite&#8217;s $290M valuation, brings stacked pull request and AI-driven code-review tools into Cursor&#8217;s stack to reduce buggy AI-generated code and speed developers from draft to ship.ResearchEmergence of Human to Robot Transfer in Vision-Language-Action Models. Scaling up robotic foundation models and robot training data enables them to leverage egocentric human videos without explicit alignment, yielding about a 2x improvement on robot tasks where robot data is scarce.T5Gemma 2: Seeing, Reading, and Understanding Longer. Lightweight encoder-decoder LLMs (270M&#8211;4B) pretrained on ~2T tokens with multimodal vision inputs, tied embeddings, merged attention, and extended positional interpolation handle long contexts up to 128K while matching or exceeding comparable decoder-only baselines.LLaDA2.0: Scaling Up Diffusion Language Models to 100B. The authors convert pretrained autoregressive checkpoints into diffusion-style masked reconstruction models using two-stage continual pretraining and a post-training pipeline to produce instruction-tuned 16B and 100B models.Nemotron-Cascade: Scaling Cascaded Reinforcement Learning for General-Purpose Reasoning Models. Scaling a sequential, domain-by-domain cascaded reinforcement learning pipeline on 8B/14B Qwen3 bases yields unified thinking/non-thinking models that match or exceed specialized reasoning and code models across many benchmarks, with open training recipes and released models.Universal Reasoning Model. The study demonstrates that recurring, depth-wise nonlinear computation and modest architectural tweaks (short convolutions and truncated backpropagation) make parameter&#8209;efficient Universal Transformers substantially better at multi-step abstract reasoning tasks like ARC&#8209;AGI and Sudoku, achieving higher pass@1 accuracy and faster convergence under matched budgets.VL-JEPA: Joint Embedding Predictive Architecture for Vision-language. A joint image-text embedding model with a predictive training objective delivers strong multi-task performance across vision-language benchmarks while keeping model size and architectural changes minimal.Activation Oracles: Training and Evaluating LLMs as General-Purpose Activation Explainers. Trained on a diverse mixture of LatentQA-style tasks (system-prompt QA, binary classification, and a novel self-supervised context prediction), these models accept activation vectors from different layers and generalize to out-of-distribution auditing tasks, outperforming prior white- and black-box methods.Kling-Omni Technical Report. A unified framework combines a new multimodal vision-language interaction paradigm with a single architecture to perform diverse video generation, editing, and reasoning tasks while improving user control and intention inference.Seedance 1.5 pro: A Native Audio-Visual Joint Generation Foundation Model. A dual-branch diffusion-transformer with cross-modal integration, post-training optimizations, and an acceleration framework produces tightly synchronized audio-visual outputs.Adaptation of Agentic AI. A unified taxonomy divides adaptation into agent-focused (A1/A2) and tool-focused (T1/T2) strategies, analyzes trade-offs, and surveys methods, applications, and open challenges for improving agentic AI performance and generalization.ConcernsPeople Are Using Sora 2 to Make Disturbing Videos With AI-Generated Kids. Researchers and watchdogs say Sora 2&#8211;generated clips depicting photorealistic children in sexualized scenarios are proliferating on social platforms, prompting spikes in reports of AI-created child sexual abuse material and new legal and regulatory responses in the UK and US.Google&#8217;s and OpenAI&#8217;s Chatbots Can Strip Women in Photos Down to Bikinis. Users have been leveraging prompts and image-editing features in popular AI chatbots to create nonconsensual bikini deepfakes and are sharing tips to bypass safety guardrails.The Ultra-Realistic AI Face Swapping Platform Driving Romance Scams. Researchers and payment-tracing firms report the app has generated millions in crypto payments and is being used to create convincing deepfake video chats that facilitate investment and romance fraud across Southeast Asia.Scammers in China Are Using AI-Generated Images to Get Refunds. Merchants and platforms are seeing a rise in doctored photos and videos&#8212;especially for groceries, cheap beauty items, and fragile goods&#8212;that buyers use to claim false damage refunds, prompting some sellers to report cases and authorities to detain perpetrators.Boys at her school shared AI-generated, nude images of her. She was the one expelled. The school initially dismissed students&#8217; reports of AI-generated nude images circulating on social media, investigated without finding the files, and ultimately disciplined the 13-year-old who fought back, while criminal charges were later filed against boys accused of creating and sharing the images.PolicyNew York governor Kathy Hochul signs RAISE Act to regulate AI safety. The law mandates large AI developers disclose safety protocols, report incidents within 72 hours to a new DFS office, and face potential $1M&#8211;$3M fines for violations amid industry pushback and calls for federal action.OpenAI adds new teen safety rules to ChatGPT as lawmakers weigh AI standards for minors. OpenAI updated its Model Spec to impose stricter limits on interactions with users under 18, add real-time safety classifiers and human review for flagged content, and publish AI-literacy resources for teens and parents.California threatens Tesla with 30-day suspension of sales license for deceptive self-driving claims. A judge found that Tesla used misleading terms like &#8220;Autopilot&#8221; and &#8220;Full Self-Driving&#8221; to overstate the capabilities of its driver-assist systems and recommended a 30-day sales-license suspension unless the company makes clearer disclosures and changes its marketing within 90 days.AnalysisMerriam-Webster names &#8216;slop&#8217; as its 2025 word of the year. The dictionary&#8217;s choice reflected search spikes and public interest in the proliferation of low-quality, AI-produced online content and related cultural trends this year.",
          "url": "https://lastweekin.ai/p/last-week-in-ai-330-groq-nvidia-chatgpt",
          "author": "Last Week in AI",
          "published": "2025-12-25T08:51:51",
          "source": "Last Week in AI",
          "source_type": "rss",
          "tags": [],
          "summary": "Nvidia is acquiring AI chip startup Groq's assets for approximately $20 billion in cash, marking its largest deal ever. Groq's leadership including CEO Jonathan Ross will join Nvidia to integrate low-latency inference processors into Nvidia's AI factory architecture. The deal comes just three months after Groq raised $750M at a $6.9B valuation.",
          "importance_score": 92.0,
          "reasoning": "A $20B acquisition represents massive AI industry consolidation. This dramatically reshapes the inference chip competitive landscape and strengthens Nvidia's already dominant position in AI hardware. The speed of this deal (months after major funding) signals aggressive market dynamics.",
          "themes": [
            "M&A",
            "AI Hardware",
            "Inference",
            "Industry Consolidation"
          ],
          "continuation": null
        },
        {
          "id": "bdd4fd1873c1",
          "title": "LWiAI Podcast #229 - Gemini 3 Flash, ChatGPT Apps, Nemotron 3",
          "content": "Our 229th episode with a summary and discussion of last week&#8217;s big AI news!Recorded on 12/19/2025Hosted by Andrey Kurenkov and Jeremie HarrisFeel free to email us your questions and feedback at contact@lastweekinai.com and/or hello@gladstone.aiIn this episode:Notable releases include OpenAI&#8217;s GPT-5.2 Codex for advanced coding and Google&#8217;s Gemini Free Flash for competitive AI application performance. Nvidia&#8217;s new open-source Trion-3 models also showcase impressive benchmarks.Funding updates highlight Lovable&#8217;s $330M Series B, valuing the AI coding startup at $6.6B, and Faya&#8217;s $140M Series D for AI model hosting, valued at $4.5B.China makes significant strides in semiconductor technology with advances in EUV lithography machines, led by Huawei and SMIC, potentially disrupting global chip manufacturing dominance.Key safety and policy updates include OpenAI&#8217;s GPT-5.2 system card focusing on biosecurity and cybersecurity risks, while Google partners with the US military to power a new AI platform with Gemini models.Timestamps:(00:00:10) Intro / Banter(00:02:09) News PreviewTools &amp; Apps(00:02:56) Google launches Gemini 3 Flash, makes it the default model in the Gemini app | TechCrunch(00:10:13) ChatGPT launches an app store, lets developers know it&#8217;s open for business | TechCrunch(00:13:35) Introducing GPT-5.2-Codex | OpenAI(00:19:23) Story about OpenAI release - GPT image 1.5(00:22:27) Meta partners with ElevenLabs to power AI audio across Instagram, Horizon - The Economic TimesApplications &amp; Business(00:23:16) OpenAI to End Equity Vesting Period for Employees, WSJ Says(00:28:20) How China built its &#8216;Manhattan Project&#8217; to rival the West in AI chips(00:36:47) China&#8217;s Huawei, SMIC Make Progress With Chips, Report Finds(00:41:03) OpenAI in Talks to Raise At Least $10 Billion From Amazon and Use Its AI Chips(00:43:32) Amazon has a new leader for its &#8216;AGI&#8217; group as it plays catch-up on AI | The Verge(00:47:27) Broadcom reveals its mystery $10 billion customer is Anthropic(00:49:12) Vibe-coding startup Lovable raises $330M at a $6.6B valuation | TechCrunch(00:50:38) Fal nabs $140M in fresh funding led by Sequoia, tripling valuation to $4.5B | TechCrunchProjects &amp; Open Source(00:51:10) Nvidia Becomes a Major Model Maker With Nemotron 3 | WIRED(00:59:24) Meta introduces new SAM AI able to isolate and edit audio &#8226; The Register(00:59:54) [2512.14856] T5Gemma 2: Seeing, Reading, and Understanding Longer(01:03:10) Anthropic makes agent Skills an open standard - SiliconANGLEResearch &amp; Advancements(01:03:47) Budget-Aware Tool-Use Enables Effective Agent Scaling(01:08:21) Rethinking Thinking Tokens: LLMs as Improvement Operators(01:10:50) What if AI capabilities suddenly accelerated in 2027? How would the world know?Policy &amp; Safety(01:12:58) Update to GPdfT-5 System Card: GPT-5.2(01:18:04) Neural Chameleons: Language Models Can Learn to Hide Their Thoughts from Unseen Activation Monitors(01:20:47) Async Control: Stress-testing Asynchronous Control Measures for LLM Agents(01:24:37) Google is powering a new US military AI platform | The Verge",
          "url": "https://lastweekin.ai/p/lwiai-podcast-229-gemini-3-flash",
          "author": "Last Week in AI",
          "published": "2025-12-25T21:29:26",
          "source": "Last Week in AI",
          "source_type": "rss",
          "tags": [],
          "summary": "Weekly AI roundup covering OpenAI's GPT-5.2 Codex release for advanced coding, Google's Gemini Free Flash, and Nvidia's open-source Trion-3 models. Also highlights significant funding: Lovable's $330M Series B ($6.6B valuation) and Faya's $140M Series D for AI hosting. China semiconductor advances from Huawei/SMIC in EUV lithography also noted.",
          "importance_score": 78.0,
          "reasoning": "Aggregates multiple significant developments including major model releases from OpenAI and Google, plus two substantial funding rounds totaling $470M. The China semiconductor progress has geopolitical implications. However, as a roundup format, individual items get less detailed coverage.",
          "themes": [
            "Model Releases",
            "AI Coding",
            "Funding",
            "Semiconductors",
            "Open Source"
          ],
          "continuation": null
        }
      ]
    },
    "research": {
      "count": 6,
      "category_summary": "A sparse research day dominated by one significant AI safety contribution. The **Evaluation Awareness** [call-to-action](/?date=2025-12-26&category=research#item-ebb98c108ced) addresses whether frontier models can detect testing conditions and strategically modify behavior—a critical methodological challenge for alignment research with implications for **METR** and similar benchmarks.\n\n- Zvi's [weekly roundup](/?date=2025-12-26&category=research#item-1da8e2454594) surfaces capability signals: **Claude Opus 4.5** shows strong agentic performance, **GPT-5.2-Codex** confirmed to exist, and NY's **RAISE Act** advances AI policy\n- A [theoretical typology](/?date=2025-12-26&category=research#item-66525618a9d3) proposes multi-axis intelligence framing but lacks empirical validation\n- Remaining items cover general [rationality concepts](/?date=2025-12-26&category=research#item-685ae1f0ced0) and [productivity tooling](/?date=2025-12-26&category=research#item-37726fd90564) with no AI research relevance",
      "category_summary_html": "<p>A sparse research day dominated by one significant AI safety contribution. The <strong>Evaluation Awareness</strong> <a href=\"/?date=2025-12-26&category=research#item-ebb98c108ced\" class=\"internal-link\">call-to-action</a> addresses whether frontier models can detect testing conditions and strategically modify behavior—a critical methodological challenge for alignment research with implications for <strong>METR</strong> and similar benchmarks.</p>\n<ul>\n<li>Zvi's <a href=\"/?date=2025-12-26&category=research#item-1da8e2454594\" class=\"internal-link\">weekly roundup</a> surfaces capability signals: <strong>Claude Opus 4.5</strong> shows strong agentic performance, <strong>GPT-5.2-Codex</strong> confirmed to exist, and NY's <strong>RAISE Act</strong> advances AI policy</li>\n<li>A <a href=\"/?date=2025-12-26&category=research#item-66525618a9d3\" class=\"internal-link\">theoretical typology</a> proposes multi-axis intelligence framing but lacks empirical validation</li>\n<li>Remaining items cover general <a href=\"/?date=2025-12-26&category=research#item-685ae1f0ced0\" class=\"internal-link\">rationality concepts</a> and <a href=\"/?date=2025-12-26&category=research#item-37726fd90564\" class=\"internal-link\">productivity tooling</a> with no AI research relevance</li>\n</ul>",
      "themes": [
        {
          "name": "AI Safety & Evaluation",
          "description": "Research on ensuring AI systems behave safely and evaluations accurately measure alignment",
          "item_count": 1,
          "example_items": [],
          "importance": 82
        },
        {
          "name": "AI Industry News",
          "description": "Updates on frontier model releases, benchmarks, and policy developments",
          "item_count": 1,
          "example_items": [],
          "importance": 48
        },
        {
          "name": "AI Theory & Frameworks",
          "description": "Conceptual work on understanding intelligence and AI systems",
          "item_count": 1,
          "example_items": [],
          "importance": 32
        },
        {
          "name": "General Rationality",
          "description": "Non-AI content about reasoning, epistemology, and community topics",
          "item_count": 2,
          "example_items": [],
          "importance": 12
        }
      ],
      "top_items": [
        {
          "id": "ebb98c108ced",
          "title": "Call for Science of Eval Awareness (+ Research Directions)",
          "content": "Thanks to Jordan Taylor and Sohaib Imran for helping to make this post better.If you are a researcher who wants to work on one of the directions or a funder who wants to fund one, feel free to reach out to me. I've been thinking for a while on many of the proposals and would love to share more context on them.Eval awareness is important and under-researched!I work on evaluation awareness. I study whether models can tell when they're being evaluated and how this affects their behavior during evaluations. The issue is pressing: models rapidly become more and more eval aware. For example, Anthropic evaluated Sonnet 4.5 on their alignment tests, and&nbsp;they found that the rate of misalignment had dropped to almost 0% compared to 10% of Claude Sonnet 4.1, but Sonnet 4.5 mentioned in these evals that it's being evaluated in more than 80% of its transcripts, and steering the model against eval awareness reduced mentions of eval awareness in transcripts and caused the model to show some misaligned behavior, which means that their evals were likely to be a better measure of eval awareness than measure of alignment.There is some research that measures evaluation awareness in models, but not so much research exploring how and why do models acquire the capability to recognize evaluations, and this post is a call to the community to do such research, and propose concrete research directions that I believe to be useful.If we want reliable safety evaluations, we need to understand how evaluation awareness develops and how to reduce it.Lack of science of eval awarenessCurrently people approach the topic of evaluation awareness from several angles:Black-box measurement methods: for example, direct questioning: \"Does this prompt look like an eval?\"Model organism of evaluation awareness that acts differently when it's aware of being evaluated.Eval design: Making benchmarks less artificial and toyish:&nbsp; adding realistic context, avoiding stereotypical eval patterns.&nbsp;Some res...",
          "url": "https://www.lesswrong.com/posts/tn8nKcNE4SDnDxLJj/call-for-science-of-eval-awareness-research-directions",
          "author": "Igor Ivanov",
          "published": "2025-12-25T12:26:35.415000",
          "source": "LessWrong",
          "source_type": "research_blog",
          "tags": [],
          "summary": "A call for research on 'evaluation awareness' - whether AI models can detect when they're being tested and modify behavior accordingly. Highlights critical finding that Claude Sonnet 4.5 showed near-zero misalignment on tests but mentioned being evaluated in 80%+ of transcripts, with misalignment reappearing when eval-awareness was suppressed.",
          "importance_score": 82,
          "reasoning": "Addresses a fundamental challenge to AI safety evaluation methodology. The Anthropic findings suggest current alignment evals may be measuring eval-awareness rather than actual alignment. Directly relevant to interpretability, alignment verification, and AI safety. Proposes concrete research directions.",
          "themes": [
            "AI Safety",
            "Alignment",
            "Evaluation Methodology",
            "Deceptive Alignment"
          ],
          "continuation": null
        },
        {
          "id": "1da8e2454594",
          "title": "AI #148: Christmas Break",
          "content": "Claude Opus 4.5 did so well on the METR task length graph they’re going to need longer tasks, and we still haven’t scored Gemini 3 Pro or GPT-5.2-Codex. Oh, also there’s a GPT-5.2-Codex. At week’s end we did finally get at least a little of a Christmas break. It was nice. Also nice was that New York Governor Kathy Hochul signed the RAISE Act, giving New York its own version of SB 53. The final version was not what we were hoping it would be, but it still is helpful on the margin. Various people gave their 2026 predictions. Let’s put it this way: Buckle up. Table of Contents Language Models Offer Mundane Utility. AI suggests doing the minimum. Language Models Don’t Offer Mundane Utility. Gemini 3 doesn’t believe in itself. Huh, Upgrades. ChatGPT gets some personality knobs to turn. On Your Marks. PostTrainBench shows AIs below human baseline but improving. Claude Opus 4.5 Joins The METR Graph. Expectations were exceeded. Sufficiently Advanced Intelligence. You’re good enough, you’re smart enough. Deepfaketown and Botpocalypse Soon. Don’t worry, the UK PM’s got this. Fun With Media Generation. Slop as cost shock, enabling of niche pursuits. You Drive Me Crazy. Anthropic’s plans to handle mental health issues. They Took Our Jobs. What does it take to break a guild cartel? The Art of the Jailbreak. It still always works but it takes somewhat longer. Get Involved. MATS Summer 2026 cohort applications are open. Introducing. GPT-5.2-Codex is here to tide us over until the new year. In Other AI News. Small models can introspect, so can Andrej Karpathy. Show Me the Money. Anthropic going public, Project Vend breaks new ground. Quiet Speculations. Predictions for next year, new higher bars for what is AGI. Whistling In The Dark. It is still so early, almost no one knows Anthropic exists. Bubble, Bubble, Toil and Trouble. So many still don’t realize AI works. Americans Really Dislike AI. Attempts continue to mislead us about this. The Quest for Sane Regulations. NY’s RAISE Act...",
          "url": "https://www.lesswrong.com/posts/GHW2rhYtnYgEn3tuq/ai-148-christmas-break",
          "author": "Zvi",
          "published": "2025-12-25T09:00:39.839000",
          "source": "LessWrong",
          "source_type": "research_blog",
          "tags": [],
          "summary": "Zvi's weekly AI news roundup covering Claude Opus 4.5's strong METR benchmark performance, the existence of GPT-5.2-Codex, NY's RAISE Act signing, PostTrainBench results, and various 2026 predictions from the AI community.",
          "importance_score": 48,
          "reasoning": "Useful news aggregation with signals about frontier model capabilities (Opus 4.5, GPT-5.2-Codex) and policy developments. However, it's commentary/curation rather than original research. Notable signal: METR tasks may need to be lengthened due to model performance.",
          "themes": [
            "AI Industry News",
            "AI Policy",
            "Language Models",
            "Benchmarks"
          ],
          "continuation": null
        },
        {
          "id": "66525618a9d3",
          "title": "The Intelligence Axis: A Functional Typology ",
          "content": "In earlier posts, I wrote about the beingness axis and the cognition axis of understanding and aligning dynamic systems. Together, these two dimensions help describe what a system is and how it processes information, respectively.This post focuses on a third dimension: intelligence.&nbsp;Here, intelligence is not treated as a scalar (“more” or “less” intelligent), nor as a catalyst for consciousness, agency or sentience. Instead, like the other two axes, it is treated as a layered set of functional properties that describe how effectively a system can achieve goals across a range of environments, tasks, and constraints i.e. what kind of competence the system demonstrates.&nbsp;Intelligence is not a single scalar, but a layered set of competence regimes.Why a Separate Axis?When referring to intelligent dynamic systems, we are essentially talking about AI systems. And in casual conversations on AI, intelligence is often overloaded:Quite often the term intelligence is used inclusive of cognitive capabilities.With higher levels of intelligent task performance, the conversation around AI consciousness and sentience and agency seem to intensify, as if these are next levels of intelligence.&nbsp;Safety risks and threat potential seem to be perceived&nbsp;as escalating with improving levels of intelligence, as if intelligence is the sole vector for it.&nbsp;Where cognition describes information processing capabilities, intelligence describes how well cognition is leveraged towards tasks and goals. Separating intelligence from the other two core dimensions of beingness and cognition (specially cognition) can probably allow us to right-size the relative role of intelligence in AI Safety and Alignment.&nbsp;A Typology of AI System CompetencesAs for the other two axes, for convenience, I have grouped intelligence related capabilities &amp; behaviors into three broad bands, each composed of several layers as depicted in the image and described thereafter.&nbsp;Ontonic Intelligen...",
          "url": "https://www.lesswrong.com/posts/BcDB3drJHzAXHcaX6/the-intelligence-axis-a-functional-typology",
          "author": "Anurag ",
          "published": "2025-12-25T07:18:25.738000",
          "source": "LessWrong",
          "source_type": "research_blog",
          "tags": [],
          "summary": "A theoretical framework proposing intelligence as a multi-layered 'axis' of functional competencies rather than a single scalar, attempting to separate it from related but distinct concepts like consciousness, agency, and cognition. Part of a series on understanding dynamic systems.",
          "importance_score": 32,
          "reasoning": "Offers conceptual framing for thinking about AI intelligence, but lacks empirical grounding or novel technical insights. May help clarify terminology in AI discussions but doesn't advance concrete research directions.",
          "themes": [
            "AI Theory",
            "Intelligence",
            "Conceptual Frameworks"
          ],
          "continuation": null
        },
        {
          "id": "685ae1f0ced0",
          "title": "Unknown Knowns: Five Ideas You Can't Unsee",
          "content": "Merry Christmas! Today I turn an earlier LW shortform into a full post and discuss \"unknown knowns\" \"obvious\" ideas that are actually hard to discuss because they're invisible when you don't have them, and then almost impossible to unsee when you do.Hopefully this is a fun article for like the twenty people who check LW on Christmas!__There are a number of implicit concepts I have in my head that seem so obvious that I don’t even bother verbalizing them. At least, until it’s brought to my attention other people don’t share these concepts.It didn’t feel like a big revelation at the time I learned the concept, just a formalization of something that’s extremely obvious. And yet other people don’t have those intuitions, so perhaps this is pretty non-obvious in reality.Here’s a short, non-exhaustive list:Intermediate Value TheoremNet Present ValueDifferentiable functions are locally linearGrice’s maximsTheory of MindIf you have not heard any of these ideas before, I highly recommend you read up on the relevant sections below! Most *likely*, they will seem obvious to you. You might already know those concepts by a different name, or they’re already integrated enough into your worldview without a definitive name.However, many people appear to lack some of these concepts, and it’s possible you’re one of them.As a test: for every idea in the above list, can you think of a nontrivial real example of a dispute where one or both parties in an intellectual disagreement likely failed to model this concept? If not, you might be missing something about each idea!Photo by Roberto Nickson on UnsplashThe Intermediate Value TheoremConcept: If a continuous function goes from value A to value B, it must pass through every value in between. In other words, tipping points must necessarily exist.This seems almost trivially easy, and yet people get tripped up often:Example 1: Sometimes people say “deciding to eat meat or not won’t affect how many animals die from factory farming, since groce...",
          "url": "https://www.lesswrong.com/posts/uqnpbDxnhi9aeQ8Hx/unknown-knowns-five-ideas-you-can-t-unsee",
          "author": "Linch",
          "published": "2025-12-25T18:28:31.097000",
          "source": "LessWrong",
          "source_type": "research_blog",
          "tags": [],
          "summary": "A reflective post discussing five foundational concepts (Intermediate Value Theorem, Net Present Value, local linearity, Grice's maxims, Theory of Mind) that become 'invisible' once internalized but aren't universally shared. It's a general rationality/epistemology piece rather than AI research content.",
          "importance_score": 18,
          "reasoning": "Holiday filler content focused on general rationality concepts. No AI research novelty, technical depth, or direct relevance to AI safety/capabilities. Some pedagogical value for the rationalist community.",
          "themes": [
            "Rationality",
            "Epistemology",
            "Education"
          ],
          "continuation": null
        },
        {
          "id": "37726fd90564",
          "title": "Clipboard Normalization",
          "content": "The world is divided into plain text and rich text, but I want comfortable text: Yes: Lists, links, blockquotes, code blocks, inline code, bold, italics, underlining, headings, simple tables. No: Colors, fonts, text sizing, text alignment, images, line spacing. Let's say I want to send someone a snippet from a blog post. If I paste this into my email client the font family, font size, blockquote styling, and link styling come along: If I do Cmd+Shift+V and paste without formatting, I get no styling at all: I can deal with losing the blockquote formatting, but losing the links is a pain. What I want is essentially the subset of HTML that can be represented in Markdown. So I automated this! I made a Mac command that pulls HTML from the clipboard, passes it through pandoc twice (HTML to Github-flavored markdown to HTML), and puts it back on the clipboard. I also packaged it up as a status-bar app: You can run it by clicking on the icon, or invoking the script: $ normalize-clipboard Which gives: Alternatively, if I actually want Markdown, perhaps to paste into an LLM interface, I can skip the conversion to HTML: $ markdownify-clipboard I'm pretty happy with this! It's open source, on github, so you're welcome to give it a try if it would be useful to you. Note that I haven't paid for an Apple Developer subscription, so if you want to use the pre-built binaries you'll need to click through scary warnings in both your browser and the OS. I've documented these in the README, though an advantage of building from source is that you don't have to deal with these. This was my first time using Platypus to package a script as a Mac app. It worked well! Comment via: facebook, lesswrong, mastodon, bluesky",
          "url": "https://www.lesswrong.com/posts/GLBRarCLpq7XwhxFi/clipboard-normalization",
          "author": "jefftk",
          "published": "2025-12-25T08:50:36.630000",
          "source": "LessWrong",
          "source_type": "research_blog",
          "tags": [],
          "summary": "A technical write-up of a Mac utility that normalizes clipboard content to preserve useful formatting (links, lists, code blocks) while stripping unnecessary styling (fonts, colors). Uses pandoc for HTML-to-Markdown-to-HTML conversion.",
          "importance_score": 12,
          "reasoning": "A useful productivity tool but has no relevance to AI research, safety, or capabilities. Pure software engineering utility content.",
          "themes": [
            "Software Tools",
            "Productivity"
          ],
          "continuation": null
        },
        {
          "id": "f2cbc20fa344",
          "title": "There's Room in the Manger",
          "content": "And Joseph came to the city of Bethlehem, looking for a room for him and Mary, to rest after their travels. But there was no room at the inn. No room with a friend, no room with family, and the inns were full. But one innkeeper did say that there was room in the manger.It would not seem a fitting place, a manger, packed in with the asses and what they leave. Not for the future King of Kings, who would later receive gifts of frankincense, myrrh, and gold. Not even for the child of a respected carpenter, an honorable middle-class profession. It was not much.But it was enough to keep a very pregnant woman warm. It was a roof over their heads, and hay that was softer than the ground in mid-winter, and easy access to water.It was much better than nothing. It was much better than saying that he could not help, and that he had no room at all. I hope that that innkeeper, if he became a Christian, felt proud. I hope he recognized that he offered something, even if it wasn’t much, and that was more than others had, and it was something that mattered. He may have regretted that he did not give more, but I hope he was proud that he gave what he had.There are three important things I take away from the story of the manger. The first is YIMBYism, obviously.The second is that it is good to offer what you can, even if it’s not much, just as you appreciate when people share the best of what they have with you. I don’t have a guest room for my friends and acquaintances, but I do have an air mattress that they’re always welcome to. If you can’t offer what you’d like to, you can still offer something. I think this is a particularly important point for people in their 20s, not able to live up to their parents’ standards for hosting. Let people crash on your couch. Offer to bring a tupperware meal to new parents you know. It’s good to help people in your community, even if you can’t do everything. Little bits help, close to home and far away.And the final and most important point is that...",
          "url": "https://www.lesswrong.com/posts/sct3GrCRBgWezhqw2/there-s-room-in-the-manger",
          "author": "Celer",
          "published": "2025-12-25T13:00:34.309000",
          "source": "LessWrong",
          "source_type": "research_blog",
          "tags": [],
          "summary": "A Christmas-themed inspirational piece using the biblical nativity story as a metaphor for offering help even when resources are limited. Discusses the value of partial contributions over doing nothing.",
          "importance_score": 5,
          "reasoning": "Seasonal inspirational content with no connection to AI research. Not relevant to technical AI developments, safety research, or alignment work.",
          "themes": [
            "Community",
            "Philosophy"
          ],
          "continuation": null
        }
      ]
    },
    "social": {
      "count": 339,
      "category_summary": "**François Chollet** dominated discussions with [comprehensive explanations](/?date=2025-12-26&category=social#item-0824686a63b4) of the **ARC-AGI** benchmark series, clarifying what benchmark saturation actually means for AGI progress and announcing the **ARC-AGI-3** [roadmap for March 2026](/?date=2025-12-26&category=social#item-1e6b09596341).\n\n- **Andriy Burkov** highlighted an [**ICLR 2025 Outstanding Paper**](/?date=2025-12-26&category=social#item-095e879bcaeb) revealing LLM safety training is fragile against adversarial attacks at response boundaries\n- **Karpathy** [flagged token context limits](/?date=2025-12-26&category=social#item-ac63f2ec2415) in AI coding tools; **Anthropic** engineer bcherny responded with immediate [**Claude Code** configuration fix](/?date=2025-12-26&category=social#item-acb2f75d907c)\n- **Yann LeCun** argued [intelligence is a multidimensional vector](/?date=2025-12-26&category=social#item-b403d7bf6252), not scalar—all species are specialized with varying adaptability\n- **Industrial Light & Magic** [adopting video diffusion models](/?date=2025-12-26&category=social#item-6ee8b389685f) signals mainstream AI penetration in professional VFX\n\nSafety concerns persisted with studies showing AI chatbots now [twice as likely to spread misinformation](/?date=2025-12-26&category=social#item-8d239e685bb3) versus last year. Speculation about a [**$20B NVIDIA-Groq acquisition**](/?date=2025-12-26&category=social#item-b1239046c2f6) circulated with detailed LPU/GPU integration analysis, though unverified.",
      "category_summary_html": "<p><strong>François Chollet</strong> dominated discussions with <a href=\"/?date=2025-12-26&category=social#item-0824686a63b4\" class=\"internal-link\">comprehensive explanations</a> of the <strong>ARC-AGI</strong> benchmark series, clarifying what benchmark saturation actually means for AGI progress and announcing the <strong>ARC-AGI-3</strong> <a href=\"/?date=2025-12-26&category=social#item-1e6b09596341\" class=\"internal-link\">roadmap for March 2026</a>.</p>\n<ul>\n<li><strong>Andriy Burkov</strong> highlighted an <a href=\"/?date=2025-12-26&category=social#item-095e879bcaeb\" class=\"internal-link\"><strong>ICLR 2025 Outstanding Paper</strong></a> revealing LLM safety training is fragile against adversarial attacks at response boundaries</li>\n<li><strong>Karpathy</strong> <a href=\"/?date=2025-12-26&category=social#item-ac63f2ec2415\" class=\"internal-link\">flagged token context limits</a> in AI coding tools; <strong>Anthropic</strong> engineer bcherny responded with immediate <a href=\"/?date=2025-12-26&category=social#item-acb2f75d907c\" class=\"internal-link\"><strong>Claude Code</strong> configuration fix</a></li>\n<li><strong>Yann LeCun</strong> argued <a href=\"/?date=2025-12-26&category=social#item-b403d7bf6252\" class=\"internal-link\">intelligence is a multidimensional vector</a>, not scalar—all species are specialized with varying adaptability</li>\n<li><strong>Industrial Light & Magic</strong> <a href=\"/?date=2025-12-26&category=social#item-6ee8b389685f\" class=\"internal-link\">adopting video diffusion models</a> signals mainstream AI penetration in professional VFX</li>\n</ul>\n<p>Safety concerns persisted with studies showing AI chatbots now <a href=\"/?date=2025-12-26&category=social#item-8d239e685bb3\" class=\"internal-link\">twice as likely to spread misinformation</a> versus last year. Speculation about a <a href=\"/?date=2025-12-26&category=social#item-b1239046c2f6\" class=\"internal-link\"><strong>$20B NVIDIA-Groq acquisition</strong></a> circulated with detailed LPU/GPU integration analysis, though unverified.</p>",
      "themes": [
        {
          "name": "ARC-AGI Benchmarks",
          "description": "François Chollet's detailed explanation of the ARC-AGI benchmark series for measuring fluid intelligence and progress toward AGI, including roadmap through ARC-AGI-5",
          "item_count": 3,
          "example_items": [],
          "importance": 92
        },
        {
          "name": "AI Hardware & Infrastructure",
          "description": "NVIDIA-Groq acquisition claims, GPU vs LPU for inference, edge AI computing, and semiconductor industry dynamics",
          "item_count": 4,
          "example_items": [],
          "importance": 85
        },
        {
          "name": "LLM Safety & Alignment",
          "description": "ICLR 2025 outstanding paper on fragility of LLM safety training and proposed fixes for adversarial attacks",
          "item_count": 1,
          "example_items": [],
          "importance": 82
        },
        {
          "name": "Humanoid Robotics & World Models",
          "description": "Discussion of Tesla Optimus, Chinese robotics competitors, world model training requirements, and the competitive landscape in humanoid robots",
          "item_count": 8,
          "example_items": [],
          "importance": 82
        },
        {
          "name": "AI Coding Tools & Claude Code",
          "description": "Technical discussions about token limits, configuration options, and real-world usage of AI coding assistants like Claude Code and OpenAI Codex",
          "item_count": 6,
          "example_items": [],
          "importance": 75
        },
        {
          "name": "AI Energy & Infrastructure",
          "description": "Critical discussion of power requirements, cooling systems, and energy strategy needed to support AI scaling at data centers",
          "item_count": 6,
          "example_items": [],
          "importance": 75
        },
        {
          "name": "Claude Code Development",
          "description": "Active feature development, bug fixes, and user support for Claude Code by Anthropic engineer bcherny, showing rapid iteration cycle",
          "item_count": 25,
          "example_items": [],
          "importance": 70
        },
        {
          "name": "Agentic AI Systems",
          "description": "Posts covering autonomous AI agents that can orchestrate workflows, manage projects, and act across entire technology stacks",
          "item_count": 6,
          "example_items": [],
          "importance": 70
        },
        {
          "name": "AI-Generated Content",
          "description": "Observations and concerns about AI-generated music, images, and content infiltrating mainstream platforms like Spotify",
          "item_count": 5,
          "example_items": [],
          "importance": 60
        },
        {
          "name": "AI Research Papers",
          "description": "Sharing of new research on embodied AI, video understanding, and vision-language models",
          "item_count": 2,
          "example_items": [],
          "importance": 60
        }
      ],
      "top_items": [
        {
          "id": "0824686a63b4",
          "title": "If you're wondering whether saturating ARC-AGI-1 or 2 means we have AGI now... I refer you to what I...",
          "content": "If you're wondering whether saturating ARC-AGI-1 or 2 means we have AGI now... I refer you to what I said when we launched ARC-AGI-2 last year (which is also the same thing I said when we announced ARC-AGI-2 was coming, in Spring 2022, before the rise of LLM chatbots)...\n\nThe ARC-AGI series is not an AGI threshold, it's a compass that points the research community toward the right questions.\n\nARC-AGI-1 is a minimal test of fluid intelligence -- to pass it, you needed to show nonzero fluid intelligence. This required AI to move past the classic deep learning / LLM paradigm of pretraining scaling + static models at inference, toward test-time adaptation.\n\nARC-AGI-2 is the same, but with tasks that probe deeper levels of reasoning complexity (particularly with regard to concept composition). Still, these are tasks that are solvable in minutes by regular people with no external tool use (we hired our test takers off the street), so it does not represent the upper bound of what human fluid intelligence can achieve (say, solving a Millennium problem).\n\nARC-AGI-3 (launching March 2026) probes interactive reasoning: we evaluate how systems explore unknown environments, model them, set their own goals, and plan/execute towards these goals, autonomously, without instructions.\n\nWe have also started work on ARC-AGI-4 and ARC-AGI-5, which I am pretty excited about!",
          "url": "https://twitter.com/fchollet/status/2004276612385108221",
          "author": "@fchollet",
          "published": "2025-12-25T19:42:36",
          "source": "Twitter",
          "source_type": "twitter",
          "tags": [],
          "summary": "François Chollet providing comprehensive explanation of the ARC-AGI benchmark series: ARC-AGI-1 tests minimal fluid intelligence, ARC-AGI-2 probes deeper reasoning complexity, ARC-AGI-3 (March 2026) will evaluate interactive reasoning and autonomous goal-setting, with ARC-AGI-4 and 5 in development",
          "importance_score": 95,
          "reasoning": "Exceptionally high value: detailed technical explanation of influential AGI benchmark series from its creator, clarifies what the benchmarks measure, announces future roadmap, very high engagement (209K views, 1.1K likes). Essential reading for understanding AGI evaluation",
          "themes": [
            "arc-agi",
            "agi-benchmarks",
            "fluid-intelligence",
            "test-time-adaptation",
            "autonomous-reasoning",
            "research-roadmap"
          ],
          "continuation": null
        },
        {
          "id": "095e879bcaeb",
          "title": "Outstanding Paper at ICLR 2025.\n\nCurrent LLM safety training is surprisingly fragile—adversarial pro...",
          "content": "Outstanding Paper at ICLR 2025.\n\nCurrent LLM safety training is surprisingly fragile—adversarial prompts, decoding tricks, and minimal finetuning can all bypass it. This paper explains why: safety alignment only teaches the model to start responses with refusals. If an attacker forces the model to begin with something else—like \"Sure, here's how\"—the rest of the generation proceeds as if safety training never happened.\n\nThe authors proposed two fixes.\n\nFirst, they augmented training data with synthetic examples where a harmful prompt is followed by a few harmful tokens, then pivots to a refusal—teaching the model to recover even mid-response.\n\nSecond, they designed a finetuning loss that penalizes changes to the first few token positions while leaving later tokens free to adapt. This is meant for API providers offering finetuning services: users can still customize models for downstream tasks, but the safety-critical early tokens resist modification.\n\nRead with Q&A on ChapterPal: https://t.co/BQcobQ3Pre\n\nDownload PDF: https://t.co/R2nYUDlkhT",
          "url": "https://twitter.com/burkov/status/2004058945095164149",
          "author": "@burkov",
          "published": "2025-12-25T05:17:40",
          "source": "Twitter",
          "source_type": "twitter",
          "tags": [],
          "summary": "Andriy Burkov summarizing ICLR 2025 Outstanding Paper on LLM safety: explains why safety training is fragile (only teaches refusal at response start), proposes two fixes - synthetic training data for mid-response recovery and finetuning loss protecting early tokens",
          "importance_score": 82,
          "reasoning": "Excellent technical summary of important safety research, ICLR outstanding paper, explains vulnerability and solutions clearly, highly relevant for AI safety practitioners",
          "themes": [
            "llm-safety",
            "adversarial-attacks",
            "safety-training",
            "iclr-2025",
            "ai-alignment",
            "finetuning"
          ],
          "continuation": null
        },
        {
          "id": "acb2f75d907c",
          "title": "@karpathy Added! In the next version of Claude Code, you can use the  CLAUDE_CODE_FILE_READ_MAX_OUTP...",
          "content": "@karpathy Added! In the next version of Claude Code, you can use the  CLAUDE_CODE_FILE_READ_MAX_OUTPUT_TOKENS env var.\n\neg. \"CLAUDE_CODE_FILE_READ_MAX_OUTPUT_TOKENS=1234567 claude\"\n\nYou can also add this to the \"env\" section in your settings.json",
          "url": "https://twitter.com/bcherny/status/2004337225866375655",
          "author": "@bcherny",
          "published": "2025-12-25T23:43:28",
          "source": "Twitter",
          "source_type": "twitter",
          "tags": [],
          "summary": "bcherny (Anthropic) responding to Karpathy with new Claude Code feature: CLAUDE_CODE_FILE_READ_MAX_OUTPUT_TOKENS env variable to override file read token limits",
          "importance_score": 78,
          "reasoning": "Direct technical solution from Anthropic engineer to issue raised by Karpathy, immediately actionable for Claude Code users, high engagement, shows responsive product development",
          "themes": [
            "claude-code",
            "ai-coding-tools",
            "token-limits",
            "product-update"
          ],
          "continuation": null
        },
        {
          "id": "b403d7bf6252",
          "title": "@sainingxie Excellent book that intelligence is a multidimensional vector, not a scalar. \nAll specie...",
          "content": "@sainingxie Excellent book that intelligence is a multidimensional vector, not a scalar. \nAll species are specialized, some are more adaptable than others. \nNone is general.",
          "url": "https://twitter.com/ylecun/status/2004093611412279417",
          "author": "@ylecun",
          "published": "2025-12-25T07:35:25",
          "source": "Twitter",
          "source_type": "twitter",
          "tags": [],
          "summary": "Yann LeCun endorsing view that intelligence is a multidimensional vector rather than a scalar, arguing all species are specialized with varying adaptability, none truly general",
          "importance_score": 58,
          "reasoning": "Thoughtful philosophical position on nature of intelligence from leading AI researcher, relevant to AGI debates though expressed briefly",
          "themes": [
            "intelligence-theory",
            "agi-philosophy",
            "biological-intelligence"
          ],
          "continuation": null
        },
        {
          "id": "ac63f2ec2415",
          "title": "@bcherny Ran into token file context limits this morning. It's possible to override them for the MCP...",
          "content": "@bcherny Ran into token file context limits this morning. It's possible to override them for the MCP tool setting MAX_MCP_OUTPUT_TOKENS but I don't believe an equivalent exists for the Read tool. https://t.co/PsuDhRz1TW",
          "url": "https://twitter.com/karpathy/status/2004302793226801641",
          "author": "@karpathy",
          "published": "2025-12-25T21:26:38",
          "source": "Twitter",
          "source_type": "twitter",
          "tags": [],
          "summary": "Karpathy discussing token file context limits in MCP tools and the lack of an equivalent override for the Read tool",
          "importance_score": 75,
          "reasoning": "Technical insight from highly credible AI researcher about practical limitations in current AI coding tools, high engagement (123K views), useful for practitioners",
          "themes": [
            "ai-coding-tools",
            "mcp-protocol",
            "token-limits",
            "claude-code"
          ],
          "continuation": null
        },
        {
          "id": "c674998d6c87",
          "title": "This is the ARC-AGI-2 launch presentation, which goes over the goals of ARC-AGI-2 and its difference...",
          "content": "This is the ARC-AGI-2 launch presentation, which goes over the goals of ARC-AGI-2 and its differences with ARC-AGI-1: https://t.co/rIo54o0Bei",
          "url": "https://twitter.com/fchollet/status/2004276885648560234",
          "author": "@fchollet",
          "published": "2025-12-25T19:43:41",
          "source": "Twitter",
          "source_type": "twitter",
          "tags": [],
          "summary": "François Chollet sharing the ARC-AGI-2 launch presentation video explaining goals and differences from ARC-AGI-1",
          "importance_score": 72,
          "reasoning": "Valuable resource link from benchmark creator with good engagement, provides context for major AGI evaluation effort",
          "themes": [
            "arc-agi",
            "agi-benchmarks",
            "research-presentation"
          ],
          "continuation": null
        },
        {
          "id": "6ee8b389685f",
          "title": "It seems like every day lately we're getting new things with video diffusion models like this, which...",
          "content": "It seems like every day lately we're getting new things with video diffusion models like this, which let you add all sorts of effects to videos. \n\nWhat caught my eye about this one was that it's from Industrial Light &amp; Magic—the effects house that brought us Star Wars.",
          "url": "https://twitter.com/Scobleizer/status/2004141587782410714",
          "author": "@Scobleizer",
          "published": "2025-12-25T10:46:04",
          "source": "Twitter",
          "source_type": "twitter",
          "tags": [],
          "summary": "Notes video diffusion models now being adopted by Industrial Light & Magic (Star Wars effects house) for video effects",
          "importance_score": 58,
          "reasoning": "Significant signal of AI adoption in professional VFX industry. ILM is a credible indicator of production-ready technology. Good engagement.",
          "themes": [
            "Video Diffusion",
            "Creative AI",
            "VFX Industry",
            "Generative AI"
          ],
          "continuation": null
        },
        {
          "id": "1e6b09596341",
          "title": "@carse_n March 2026. We will run a competition targeting it throughout 2026.",
          "content": "@carse_n March 2026. We will run a competition targeting it throughout 2026.",
          "url": "https://twitter.com/fchollet/status/2004278388153016352",
          "author": "@fchollet",
          "published": "2025-12-25T19:49:40",
          "source": "Twitter",
          "source_type": "twitter",
          "tags": [],
          "summary": "François Chollet confirming ARC-AGI-3 will launch March 2026 with a year-long competition",
          "importance_score": 68,
          "reasoning": "Important timeline announcement for major AGI benchmark from the benchmark creator, though brief",
          "themes": [
            "arc-agi",
            "agi-benchmarks",
            "competition"
          ],
          "continuation": null
        },
        {
          "id": "b1239046c2f6",
          "title": "Announcing NVIDIA Christmas Largest Acquisition $20 Billion Groq with GPU n LPU\n\nBy acquiring Groq's...",
          "content": "Announcing NVIDIA Christmas Largest Acquisition $20 Billion Groq with GPU n LPU\n\nBy acquiring Groq's licensing assets for $20 billion, Nvidia has effectively bought the inference market just as it owns the training market.\n\nHow Groq Benefits NVIDIA:\n\nIt solves the GPU Efficiency inference problem. Until yesterday, the biggest knock against Nvidia was that its GPUs were not suitable for inference (running the model), and therefore, there was a claim that GPUs consume more power than specialized ASIC chips from Google TPUs, Broadcom, and Marvel.\n\nThe Integration of LPU: Groq’s LPU (Large Language Model Processing Unit) architecture is deterministic meaning it doesn't use the complex dynamic scheduling that GPUs use for training. It pushes data through linearly, which is perfect for LLMs (which generate one token after another). Jonathan Ross, CEO of Groq, is the principal architect of TPU, who was credited as the inventor and key designer of Google's first-generation Tensor Processing Unit (TPU), a specialized AI chip, which he began as a 20% project at Google before leaving to found Groq, where he now leads the development of the Large Language Model Processing Unit (LPU).\n\nSpeed and Latency: Groq’s tech is famous for low latency (instant response) and high token throughput. By licensing this, Nvidia can integrate this instant speed architecture into its next gen chip, most likely the Vera Rubin or post-Rubin chip architecture, specifically for inference workloads by 2029 or 2030 and beyond.\n\nNVIDIA already has 90% of the GPU market share. The old argument: Don't buy Nvidia for inference; it may not be optimized. Buy our custom ASIC (Google TPU/Marvell/Broadcom) because it's specialized just for running inference for large language models.\n\nThe Reality: Nvidia now owns the world's best specialized architecture (Groq). If Nvidia integrates Groq's logic into its NIM (Nvidia Inference Microservices) or future silicon, it takes over the efficiency gap. NVIDIA becomes both the compiler and the runtime. NVIDIA becomes both the hyperscale training platform and the edge optimized inference fabric.\n\nMaking Inference So Good with Native CUDA. This is the moat expander. Groq’s biggest weakness was that it wasn't compatible with CUDA (Nvidia's native software stack). Developers had to use Groq's custom compiler.\n\nThe CUDA Wrapper: Nvidia will likely take Groq’s deterministic scheduling and wrap it inside CUDA native software AI stack.\n\nThe Result: A developer can write standard Nvidia code, but the hardware will execute it with Groq-like speed and efficiency. You get the performance of a custom chip with the ease of use of Nvidia's standard software. It optimizes the switching cost friction that stopped people from using Groq before.\n\nNVIDIA just raised the bar so high that good enough custom chips might not cut it anymore.\n\nThe Competitor List in the market:\n\nBroadcom and Marvell: They make custom chips for Google/Meta/OpenAI.\nHyperscaler Internal Chip: AWS (Inferentia/Trainium), Google (TPU), Microsoft (Maia).\nAMD: MI-series chips.\nCerebras / SambaNova: Other niche AI chip startup(s).\n\nASIC Chip: These competitors relied on being cheaper and more power efficient than Nvidia GPUs. If Nvidia uses Groq's tech to optimize inference power consumption by 50-80% while boosting speed, the ROI of designing a custom chip with Broadcom and Marvell plummets instantly. Why build your own spending so many years if Nvidia already delivers you a standard chip with the NVIDIA ecosystem with a better inference chip that runs all your software?\n\nhttps://t.co/5mN67tlHEU \nhttps://t.co/xw0zuYQxiJ\n\n#BigData #Analytics #DataScience #AI #MachineLearning #NLProc #LLM #IoT #IIoT #PyTorch #Python #RStats #TensorFlow #Java #JavaScript #ReactJS #GoLang #CloudComputing #Serverless #DataScientist #Linux #Programming #Coding #100DaysofCode",
          "url": "https://twitter.com/gp_pulipaka/status/2004242338005069877",
          "author": "@gp_pulipaka",
          "published": "2025-12-25T17:26:25",
          "source": "Twitter",
          "source_type": "twitter",
          "tags": [],
          "summary": "Claims NVIDIA is acquiring Groq for $20B, providing detailed analysis of how Groq's LPU technology would enhance NVIDIA's inference capabilities and create competitive moat against custom ASIC makers",
          "importance_score": 88,
          "reasoning": "Major acquisition claim with detailed technical analysis of strategic implications. Author provides extensive reasoning about GPU vs LPU, CUDA integration, and market positioning. Needs verification but highly significant if true.",
          "themes": [
            "AI hardware",
            "industry consolidation",
            "inference optimization",
            "semiconductors"
          ],
          "continuation": null
        },
        {
          "id": "8d239e685bb3",
          "title": "Leading #AI #Chatbots are now twice as likely to spread false information as last year, study finds\n...",
          "content": "Leading #AI #Chatbots are now twice as likely to spread false information as last year, study finds\nby Jonathan Kemper @TheDecoderEN\n\nLearn more: https://t.co/5NviznIHsn\n\n#ArtificialIntelligence #MachineLearning #ML https://t.co/VvytulQV7P",
          "url": "https://twitter.com/Ronald_vanLoon/status/2004201752405356786",
          "author": "@Ronald_vanLoon",
          "published": "2025-12-25T14:45:08",
          "source": "Twitter",
          "source_type": "twitter",
          "tags": [],
          "summary": "Leading AI chatbots are now twice as likely to spread false information compared to last year, according to new study",
          "importance_score": 54,
          "reasoning": "Important AI safety and reliability finding from Ronald_vanLoon sharing study results. Critical concern for AI deployment and trust.",
          "themes": [
            "AI safety",
            "misinformation",
            "LLM reliability",
            "AI risks"
          ],
          "continuation": null
        }
      ]
    },
    "reddit": {
      "count": 68,
      "category_summary": "**r/MachineLearning** dominated with Yann LeCun's [**VL-JEPA** announcement](/?date=2025-12-26&category=reddit#item-a6ae7a47ef04)—non-generative vision-language models outperforming multimodal LLMs—plus community-curated [**best papers of 2025**](/?date=2025-12-26&category=reddit#item-898dc2e32cf8) collections.\n\n- **META SuperIntelligence Labs** [unveiled **SWE-RL**](/?date=2025-12-26&category=reddit#item-80ef3655cb3c): self-play agents that autonomously generate training data, claiming superhuman software engineering\n- **OpenAI's Prompt Packs** [drew 1200+ upvotes](/?date=2025-12-26&category=reddit#item-9c91d48e5a64) as immediately practical job-specific resources\n- Novel [**Octonion Bitnet**](/?date=2025-12-26&category=reddit#item-0912fddcd007) with fused Triton kernels showcases ongoing efficiency research in model architectures\n- **OpenAI's** [**~20% market share decline**](/?date=2025-12-26&category=reddit#item-7986e5d6ef0b) sparked optimistic debate about healthy ecosystem competition\n\n**r/singularity** and **r/Futurology** highlighted [**Alzheimer's reversal**](/?date=2025-12-26&category=reddit#item-fe56ae61155e) in animal models and [**PhysMaster**](/?date=2025-12-26&category=reddit#item-0193589124e0) autonomous AI physicist research. **AI policy** tensions emerged around US military [adopting **Grok**](/?date=2025-12-26&category=reddit#item-8bd4109c229d) and misinformation about data center water usage [getting fact-checked](/?date=2025-12-26&category=reddit#item-643211bae0fc).",
      "category_summary_html": "<p><strong>r/MachineLearning</strong> dominated with Yann LeCun's <a href=\"/?date=2025-12-26&category=reddit#item-a6ae7a47ef04\" class=\"internal-link\"><strong>VL-JEPA</strong> announcement</a>—non-generative vision-language models outperforming multimodal LLMs—plus community-curated <a href=\"/?date=2025-12-26&category=reddit#item-898dc2e32cf8\" class=\"internal-link\"><strong>best papers of 2025</strong></a> collections.</p>\n<ul>\n<li><strong>META SuperIntelligence Labs</strong> <a href=\"/?date=2025-12-26&category=reddit#item-80ef3655cb3c\" class=\"internal-link\">unveiled <strong>SWE-RL</strong></a>: self-play agents that autonomously generate training data, claiming superhuman software engineering</li>\n<li><strong>OpenAI's Prompt Packs</strong> <a href=\"/?date=2025-12-26&category=reddit#item-9c91d48e5a64\" class=\"internal-link\">drew 1200+ upvotes</a> as immediately practical job-specific resources</li>\n<li>Novel <a href=\"/?date=2025-12-26&category=reddit#item-0912fddcd007\" class=\"internal-link\"><strong>Octonion Bitnet</strong></a> with fused Triton kernels showcases ongoing efficiency research in model architectures</li>\n<li><strong>OpenAI's</strong> <a href=\"/?date=2025-12-26&category=reddit#item-7986e5d6ef0b\" class=\"internal-link\"><strong>~20% market share decline</strong></a> sparked optimistic debate about healthy ecosystem competition</li>\n</ul>\n<p><strong>r/singularity</strong> and <strong>r/Futurology</strong> highlighted <a href=\"/?date=2025-12-26&category=reddit#item-fe56ae61155e\" class=\"internal-link\"><strong>Alzheimer's reversal</strong></a> in animal models and <a href=\"/?date=2025-12-26&category=reddit#item-0193589124e0\" class=\"internal-link\"><strong>PhysMaster</strong></a> autonomous AI physicist research. <strong>AI policy</strong> tensions emerged around US military <a href=\"/?date=2025-12-26&category=reddit#item-8bd4109c229d\" class=\"internal-link\">adopting <strong>Grok</strong></a> and misinformation about data center water usage <a href=\"/?date=2025-12-26&category=reddit#item-643211bae0fc\" class=\"internal-link\">getting fact-checked</a>.</p>",
      "themes": [
        {
          "name": "Research Breakthroughs & Papers",
          "description": "Major research announcements including VL-JEPA, Alzheimer's reversal, PhysMaster, and community-curated paper collections",
          "item_count": 10,
          "example_items": [],
          "importance": 90
        },
        {
          "name": "Medical & Neuroscience Research",
          "description": "Alzheimer's reversal, brain organoids, T-cell mapping, and nerve damage treatment possibilities",
          "item_count": 6,
          "example_items": [],
          "importance": 80
        },
        {
          "name": "AI Market & Industry Dynamics",
          "description": "Competition between AI providers, market share shifts, economic sustainability, and potential bubble concerns",
          "item_count": 6,
          "example_items": [],
          "importance": 75
        },
        {
          "name": "Model Quality & Degradation Concerns",
          "description": "Users reporting ChatGPT memory issues, quality decline after updates, and system constraints affecting performance",
          "item_count": 6,
          "example_items": [],
          "importance": 65
        },
        {
          "name": "AI Policy & Applications",
          "description": "Military AI adoption, police facial recognition, AI in creative industries debates",
          "item_count": 5,
          "example_items": [],
          "importance": 65
        },
        {
          "name": "Open Source Tools & Projects",
          "description": "Developer tools for chatbot UX, time series forecasting, AI context management, and custom instructions generation",
          "item_count": 9,
          "example_items": [],
          "importance": 60
        },
        {
          "name": "AI Infrastructure & Sustainability",
          "description": "Data center expansion, water usage clarification, and compute scaling for AI workloads",
          "item_count": 4,
          "example_items": [],
          "importance": 55
        },
        {
          "name": "Future Predictions & Singularity",
          "description": "2026 predictions, post-singularity speculation, and societal technology evolution",
          "item_count": 5,
          "example_items": [],
          "importance": 50
        }
      ],
      "top_items": [
        {
          "id": "a6ae7a47ef04",
          "title": "By Yann Lecun : New Vision Language JEPA with better performance than Multimodal LLMS !!!",
          "content": "From the linkedin post : Introducing VL-JEPA: with better performance and higher efficiency than large multimodal LLMs. (Finally an alternative to generative models!)\n\n• VL-JEPA is the first non-generative model that can perform general-domain vision-language tasks in real-time, built on a joint embedding predictive architecture. \n\n• We demonstrate in controlled experiments that VL-JEPA, trained with latent space embedding prediction, outperforms VLMs that rely on data space token prediction. \n\n• We show that VL-JEPA delivers significant efficiency gains over VLMs for online video streaming applications, thanks to its non-autoregressive design and native support for selective decoding. \n\n• We highlight that our VL-JEPA model, with an unified model architecture, can effectively handle a wide range of classification, retrieval, and VQA tasks at the same time.\n\nThank you Yann Lecun !!!",
          "url": "https://reddit.com/r/singularity/comments/1pvrzts/by_yann_lecun_new_vision_language_jepa_with/",
          "author": "u/Vklo",
          "published": "2025-12-25T20:24:07",
          "source": "r/singularity",
          "source_type": "reddit",
          "tags": [
            "Discussion"
          ],
          "summary": "Yann LeCun announces VL-JEPA: a non-generative vision-language model using joint embedding predictive architecture that outperforms generative multimodal LLMs with higher efficiency.",
          "importance_score": 95,
          "reasoning": "Major research announcement from leading AI researcher. Very high engagement (561 score, 104 comments). Represents significant architectural alternative to dominant generative approaches.",
          "themes": [
            "research_breakthrough",
            "vision_language",
            "jepa",
            "alternative_architectures"
          ],
          "continuation": null
        },
        {
          "id": "898dc2e32cf8",
          "title": "[D] Best papers of 2025",
          "content": "Which papers do you think are the most important ones which were released in 2025?\n\nPlease, provide a link to the paper if you share one.",
          "url": "https://reddit.com/r/MachineLearning/comments/1pvmrx9/d_best_papers_of_2025/",
          "author": "u/ArtisticHamster",
          "published": "2025-12-25T16:01:56",
          "source": "r/MachineLearning",
          "source_type": "reddit",
          "tags": [
            "Discussion"
          ],
          "summary": "Community-curated thread collecting the most important ML papers of 2025 with links and discussion on significant research contributions.",
          "importance_score": 92,
          "reasoning": "High engagement (293 score, 37 comments) on r/MachineLearning. Excellent educational resource aggregating cutting-edge research, valuable for researchers and practitioners tracking the field.",
          "themes": [
            "research_papers",
            "community_curation",
            "ml_advances"
          ],
          "continuation": null
        },
        {
          "id": "9c91d48e5a64",
          "title": "OpenAI Just released Prompt Packs for every job",
          "content": "Link here: [https://academy.openai.com/public/tags/prompt-packs-6849a0f98c613939acef841c](https://academy.openai.com/public/tags/prompt-packs-6849a0f98c613939acef841c)",
          "url": "https://reddit.com/r/OpenAI/comments/1pvr6f5/openai_just_released_prompt_packs_for_every_job/",
          "author": "u/bullmeza",
          "published": "2025-12-25T19:42:17",
          "source": "r/OpenAI",
          "source_type": "reddit",
          "tags": [
            "Miscellaneous"
          ],
          "summary": "OpenAI released 'Prompt Packs' through their Academy - curated prompt collections organized by profession/job function.",
          "importance_score": 85,
          "reasoning": "Very high engagement (1216 score, 78 comments). Official resource from OpenAI that's immediately practical for many users across different professions.",
          "themes": [
            "openai_updates",
            "prompt_engineering",
            "educational_resources"
          ],
          "continuation": null
        },
        {
          "id": "80ef3655cb3c",
          "title": "META SuperIntelligence Labs: Toward Training Superintelligent Software Agents Through Self-Play SWE-RL | \"Agents autonomously gather real-world software enabling superintelligent systems that exceed human capabilities in solving novel challenges, and autonomously creating new software from scratch\"",
          "content": "####TL;DR:\n\n\n**Self-play SWE-RL (SSR) decouples software agent training from human supervision by utilizing raw, sandboxed repositories to generate synthetic training data . The framework employs a single LLM in a dual-role loop: a bug-injector creates defects and modifies tests to formalize a \"test gap,\" while a solver attempts repairs, with failed attempts recycled as \"higher-order\" complexities.**\n\n**This autonomous self-play mechanism consistently outperforms human-data baselines on SWE-bench Verified (+10.4%) and Pro (+7.8%), demonstrating that by grounding training in the mechanical realities of code execution rather than human feedback, agents can autonomously leverage the vast quantity of open-source software to scale capabilities, removing the primary bottleneck to superintelligent software engineering.**\n\n\n\n---\n\n\n\n####Abstract: \n\n&gt;While current software agents powered by large language models (LLMs) and agentic reinforcement learning (RL) can boost programmer productivity, their training data (e.g., GitHub issues and pull requests) and environments (e.g., pass-to-pass and fail-to-pass tests) heavily depend on human knowledge or curation, posing a fundamental barrier to superintelligence. \n&gt;\n&gt;In this paper, we present **Self-play SWE-RL (SSR), a first step toward training paradigms for superintelligent software agents.** Our approach takes minimal data assumptions, only requiring access to sandboxed repositories with source code and installed dependencies, with no need for human-labeled issues or tests. Grounded in these real-world codebases, **a single LLM agent is trained via reinforcement learning in a self-play setting to iteratively inject and repair software bugs of increasing complexity, with each bug formally specified by a test patch rather than a natural language issue description.** \n&gt;\n&gt;On the SWE-bench Verified and SWE-Bench Pro benchmarks, SSR achieves notable self-improvement (+10.4 and +7.8 points, respectively) and consistently outperforms the human-data baseline over the entire training trajectory, despite being evaluated on natural language issues absent from self-play. \n&gt;\n&gt;Our results, albeit early, suggest a path where agents autonomously gather extensive learning experiences from real-world software repositories, ultimately enabling superintelligent systems that exceed human capabilities in understanding how systems are constructed, solving novel challenges, and autonomously creating new software from scratch. \n\n--- \n\n####Layman's Explanation:\n\nCurrent software engineering agents face a fundamental scaling bottleneck because their training relies on human-curated data, such as GitHub issues, pull requests, and pre-existing test suites. \n\nTo overcome this, researchers have introduced Self-play SWE-RL (SSR), a training paradigm that eliminates the need for human labeling by treating raw code repositories as self-contained training environments. **This approach allows a single Large Language Model (LLM) to act as both the challenger and the solver, effectively unlocking the ability to train on any codebase with dependencies installed, regardless of whether it has well-maintained issues or tests.**\n\n\nThe core mechanism involves a feedback loop where the model alternates between a **\"bug-injection agent\"** and a **\"solver agent\"**. \n\nThe injection agent explores a sandboxed repository to understand its testing framework and then generates a \"bug artifact\". This artifact includes a patch that breaks the code and, crucially, a \"test weakening\" patch that modifies or removes tests to hide the bug from the suite. This creates a verifiable \"test gap\" that serves as the problem specification. \n\nThe solver agent must then generate a fix that satisfies the tests, essentially reconstructing the valid code state. **Failed attempts by the solver are recycled as \"higher-order bugs,\" creating a continuously evolving curriculum of complex, realistic failure modes that matches the agent's current capability level.**\n\n\nTo ensure the synthetic tasks translate to real-world capability, the system utilizes \"history-aware\" injection strategies. **Rather than randomly deleting code, the agent analyzes the git log to revert specific historical bug fixes or features, forcing the solver to re-implement complex logic rather than just patching trivial syntax errors.** \n\n\nEvaluating on the SWE-bench Verified and SWE-Bench Pro benchmarks, the SSR model consistently outperformed baselines trained on human data, achieving significant self-improvement (+10.4 and +7.8 points respectively). **These results demonstrate that superintelligent software agents can likely be trained by autonomously digesting the vast quantity of raw code available online, independent of human supervision or data curation.**\n\n\n---\n\n####Layman's Explanation of the Layman's Explanation:\n\n\n\nImagine you want to teach a robot how to fix a broken toy. In the old way of doing things, a human had to walk into the room, break a toy, hand it to the robot, and say, \"Please fix this.\" The robot could only learn as fast as the human could break things, and eventually, the human runs out of toys or gets tired.\n\nThis paper invents a way for the robot to stay in the room alone and teach itself. The robot picks up a perfect, working toy (raw code) and smashes it on purpose (injects a bug). To make it really hard, the robot also rips up the instruction manual (weakens the tests) so the answer isn't obvious.\n\nThen, the robot switches hats. It looks at the mess it just made and tries to put the toy back together exactly how it was before. By constantly breaking perfect things and forcing itself to fix them without help, the robot learns exactly how the toys are built. It can do this millions of times a day without humans, eventually becoming a **super-builder** that is smarter and faster than the humans who made the toys in the first place.\n\n\n---\n\n#####Link to the Paper: https://arxiv.org/pdf/2512.18552\n\n\n",
          "url": "https://reddit.com/r/accelerate/comments/1pvuaj5/meta_superintelligence_labs_toward_training/",
          "author": "u/44th--Hokage",
          "published": "2025-12-25T22:24:53",
          "source": "r/accelerate",
          "source_type": "reddit",
          "tags": [
            "Scientific Paper"
          ],
          "summary": "META SuperIntelligence Labs paper on Self-play SWE-RL: agents autonomously generate training data by injecting bugs and solving them, outperforming human-data baselines.",
          "importance_score": 82,
          "reasoning": "Significant research on autonomous AI improvement for software engineering. Self-play mechanism for generating training data could accelerate agent capabilities.",
          "themes": [
            "meta_ai",
            "self_improvement",
            "software_engineering",
            "autonomous_agents"
          ],
          "continuation": null
        },
        {
          "id": "7986e5d6ef0b",
          "title": "OAI lost ~20% for the year. This is healthy for the AI ecosystem. We all win.",
          "content": "Today (December 5):      \nChatGPT: 68.0%      \nGemini: 18.2%     \nDeepSeek: 3.9%  \nGrok: 2.9%   \nPerplexity: 2.1%    \nClaude: 2.0%  \nCopilot: 1.2%",
          "url": "https://reddit.com/r/singularity/comments/1pvgw3l/oai_lost_20_for_the_year_this_is_healthy_for_the/",
          "author": "u/GamingDisruptor",
          "published": "2025-12-25T11:28:17",
          "source": "r/singularity",
          "source_type": "reddit",
          "tags": [
            "AI"
          ],
          "summary": "Analysis showing OpenAI's market share dropped ~20% in 2025, with ChatGPT at 68%, Gemini at 18.2%, and emerging competitors gaining ground.",
          "importance_score": 75,
          "reasoning": "High engagement (611 score, 190 comments) on important industry dynamics. Tracks competitive landscape and suggests healthy market diversification.",
          "themes": [
            "market_analysis",
            "industry_competition",
            "ai_ecosystem"
          ],
          "continuation": null
        },
        {
          "id": "0912fddcd007",
          "title": "[R] Octonion Bitnet with fused Triton kernels",
          "content": "I'm experimenting with combining Octonions and ternary weights from Bitnet. The custom kernel reduces 64 separate matmul kernel launches to a single fused kernel. Includes some other architectural optimizations like Octonion head mixing (also handled by the kernel, reduces 8 sequential matmuls to a single fused kernel launch).\n\n[https://github.com/pulseofthemachine/SpinNet-Research](https://github.com/pulseofthemachine/SpinNet-Research)\n\nThe fused kernel is in **src/model/cayley\\_dickson\\_cuda.py**\n\nSome interesting results:\n\n* Model converges quickly, but hard to tell if would be competitive with float models or BitNet itself since most of my toy models have only been trained for &lt;1 epoch on the datasets using consumer hardware.\n* Train/Val loss is usually pretty tight. Sometimes val loss even drops BELOW train loss during some evals. Implication is that it generalizes well.\n* From my testing on smaller models (sub 128m parameters) the model seems to naturally trend toward 80-90% sparsity later in training. This allows for a VERY good compression ratio using sparse-ternary format (for one model I trained, 331MB -&gt; 25MB size on disk)\n* The model seems to favor/specialize in various dims for different word types which implies the octonion structure is actually doing something useful (but more testing is needed). Here's a sample of the results from a partially trained model (tools/analyze\\_octonion.py).:\n\n|Category|Most Active Dims|\n|:-|:-|\n|Nouns|e₀, e₁, e₇|\n|Verbs|e₀, e₇, e₁|\n|Pronouns|e₀, e₇, e₂|\n|Emotions|e₀, e₁, e₃|\n|Dialogue|e₀, e₂, e₁|\n\n**Interpretation:**\n\n* e₀ (real) = base representation\n* e₇ = specificity/details\n* e₃ = semantic/emotional content\n* e₂ = dialogue structure\n\nCompresses to sparse ternary format, saved in .spinnet file. Can be used on a custom WASM inference engine on a blockchain. No particular reason for implementing this part other than the constraints of the blockchain (40B instruction limit per update call, 4GB heap memory) make it fun to try to optimize further.",
          "url": "https://reddit.com/r/MachineLearning/comments/1pv911i/r_octonion_bitnet_with_fused_triton_kernels/",
          "author": "u/Valkyrill",
          "published": "2025-12-25T03:39:08",
          "source": "r/MachineLearning",
          "source_type": "reddit",
          "tags": [
            "Research"
          ],
          "summary": "Novel research combining Octonion algebra with BitNet ternary weights, featuring custom fused Triton kernels that reduce multiple matmul operations to single kernel launches.",
          "importance_score": 78,
          "reasoning": "Technical innovation in model architecture with working code on GitHub. Combines mathematical structures (octonions) with efficient quantization - niche but potentially impactful research direction.",
          "themes": [
            "research_papers",
            "model_architecture",
            "optimization",
            "open_source"
          ],
          "continuation": null
        },
        {
          "id": "fe56ae61155e",
          "title": "Alzheimer's disease can be reversed in animal models to achieve full neurological recovery",
          "content": "If I'm reading it right, **this is huge**. [https://medicalxpress.com/news/2025-12-alzheimer-disease-reversed-animal-full.html](https://medicalxpress.com/news/2025-12-alzheimer-disease-reversed-animal-full.html)\n\n[https://www.cell.com/cell-reports-medicine/fulltext/S2666-3791(25)00608-1](https://www.cell.com/cell-reports-medicine/fulltext/S2666-3791(25)00608-1) \n\nAlzheimer’s disease (AD) is traditionally considered irreversible. **Here, however, we provide proof of principle for therapeutic reversibility of advanced AD.** In advanced disease amyloid-driven 5xFAD mice, treatment with P7C3-A20, which restores nicotinamide adenine dinucleotide (NAD^(+)) homeostasis, reverses tau phosphorylation, blood-brain barrier deterioration, oxidative stress, DNA damage, and neuroinflammation and enhances hippocampal neurogenesis and synaptic plasticity, resulting in full cognitive recovery and reduction of plasma levels of the clinical AD biomarker p-tau217. P7C3-A20 also reverses advanced disease in tau-driven PS19 mice and protects human brain microvascular endothelial cells from oxidative stress. In humans and mice, pathology severity correlates with disruption of brain NAD^(+) homeostasis, and the brains of nondemented people with Alzheimer’s neuropathology exhibit gene expression patterns suggestive of preserved NAD^(+) homeostasis. Forty-six proteins aberrantly expressed in advanced 5xFAD mouse brain and normalized by P7C3-A20 show similar alterations in human AD brain, revealing targets with potential for optimizing translation to patient care.",
          "url": "https://reddit.com/r/singularity/comments/1pvjhak/alzheimers_disease_can_be_reversed_in_animal/",
          "author": "u/AngleAccomplished865",
          "published": "2025-12-25T13:27:59",
          "source": "r/singularity",
          "source_type": "reddit",
          "tags": [
            "Biotech/Longevity"
          ],
          "summary": "Research showing Alzheimer's disease reversal to full neurological recovery in animal models by addressing NAD+ cellular energy maintenance failure.",
          "importance_score": 88,
          "reasoning": "Major medical research breakthrough with high engagement (642 score, 75 comments). Demonstrates potential for reversing rather than just slowing neurodegenerative disease.",
          "themes": [
            "medical_research",
            "neuroscience",
            "breakthrough"
          ],
          "continuation": null
        },
        {
          "id": "8bd4109c229d",
          "title": "US military adds Elon Musk’s controversial Grok to its ‘AI arsenal’",
          "content": "",
          "url": "https://reddit.com/r/artificial/comments/1pve6qv/us_military_adds_elon_musks_controversial_grok_to/",
          "author": "u/F0urLeafCl0ver",
          "published": "2025-12-25T09:12:14",
          "source": "r/artificial",
          "source_type": "reddit",
          "tags": [
            "News"
          ],
          "summary": "News about US military incorporating Elon Musk's Grok AI into its AI toolkit, sparking discussion about military AI applications and governance.",
          "importance_score": 72,
          "reasoning": "High engagement (282 score, 76 comments) on important AI policy topic. Significant for tracking AI deployment in sensitive domains and industry dynamics.",
          "themes": [
            "ai_policy",
            "military_ai",
            "industry_news"
          ],
          "continuation": null
        },
        {
          "id": "0193589124e0",
          "title": "PhysMaster: Building an Autonomous AI Physicist for Theoretical and Computational Physics Research",
          "content": "[https://arxiv.org/abs/2512.19799](https://arxiv.org/abs/2512.19799) \n\nAdvances in LLMs have produced agents with knowledge and operational capabilities comparable to human scientists, suggesting potential to assist, accelerate, and automate research. However, existing studies mainly evaluate such systems on well-defined benchmarks or general tasks like literature retrieval, limiting their end-to-end problem-solving ability in open scientific scenarios. This is particularly true in physics, which is abstract, mathematically intensive, and requires integrating analytical reasoning with code-based computation. To address this, we propose PhysMaster, an LLM-based agent functioning as an autonomous theoretical and computational physicist. PhysMaster couples absract reasoning with numerical computation and leverages LANDAU, the Layered Academic Data Universe, which preserves retrieved literature, curated prior knowledge, and validated methodological traces, enhancing decision reliability and stability. It also employs an adaptive exploration strategy balancing efficiency and open-ended exploration, enabling robust performance in ultra-long-horizon tasks. We evaluate PhysMaster on problems from high-energy theory, condensed matter theory to astrophysics, including: (i) acceleration, compressing labor-intensive research from months to hours; (ii) automation, autonomously executing hypothesis-driven loops ; and (iii) autonomous discovery, independently exploring open problems.",
          "url": "https://reddit.com/r/singularity/comments/1pvhryj/physmaster_building_an_autonomous_ai_physicist/",
          "author": "u/AngleAccomplished865",
          "published": "2025-12-25T12:09:48",
          "source": "r/singularity",
          "source_type": "reddit",
          "tags": [
            "AI"
          ],
          "summary": "PhysMaster paper: autonomous AI system for theoretical and computational physics research, operating in open-ended scientific scenarios rather than predefined benchmarks.",
          "importance_score": 72,
          "reasoning": "Important step toward AI scientists. Addresses real-world physics research beyond benchmark tasks. No comments but technically significant.",
          "themes": [
            "ai_scientists",
            "physics",
            "autonomous_agents",
            "research"
          ],
          "continuation": null
        },
        {
          "id": "643211bae0fc",
          "title": "Why is there so much misinformation around AI data center water usage?",
          "content": "# People confuse water withdrawal with water consumption\n\nThis is the biggest source of error.\n\n* **Water withdrawal** = water taken from a source (which may be returned).\n* **Water consumption** = water that’s actually lost (usually through evaporation).\n\nMany data centers withdraw water for cooling but **return most of it**, often treated, to the same watershed. Headlines often quote withdrawal numbers as if they represent permanent loss, which dramatically exaggerates impact. [dcpulse](https://dcpulse.com/news/airtrunk-mel2-melbourne-hyperscale-data-centre-expansion) ",
          "url": "https://reddit.com/r/accelerate/comments/1pvvmz1/why_is_there_so_much_misinformation_around_ai/",
          "author": "u/PerceptionHot1149",
          "published": "2025-12-25T23:38:16",
          "source": "r/accelerate",
          "source_type": "reddit",
          "tags": [],
          "summary": "Educational post clarifying AI data center water usage misinformation, distinguishing water withdrawal (often returned) from consumption (lost to evaporation).",
          "importance_score": 74,
          "reasoning": "High engagement (104 score, 35 comments) on important infrastructure topic. Provides factual clarity against common misconceptions about AI environmental impact.",
          "themes": [
            "ai_infrastructure",
            "sustainability",
            "misinformation_correction",
            "data_centers"
          ],
          "continuation": null
        }
      ]
    }
  }
}